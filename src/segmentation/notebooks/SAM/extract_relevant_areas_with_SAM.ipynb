{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyP4U4lQr4ryruXc2XhfrN67"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Utils"],"metadata":{"id":"jfzcWoUUs1Y-"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":30422,"status":"ok","timestamp":1690636199400,"user":{"displayName":"Etay Arie Lorberboym","userId":"09023793730623968875"},"user_tz":-180},"id":"0xkSn-LANMW5","outputId":"374184be-7656-4bcf-e71d-1edeff2fe7a2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["def extract_file_name(file_path):\n","  \"\"\"\n","  Extracts the file name from a file path.\n","\n","  Args:\n","    file_path (str): The file path.\n","\n","  Returns:\n","    str: The file name without the extension.\n","  \"\"\"\n","  # Split the file path into a list of strings\n","  parts = file_path.split(\"/\")\n","  # Get the last element in the list (the file name)\n","  file_name = parts[-1]\n","  # Split the file name into a list of strings\n","  parts = file_name.split(\".\")\n","  # Get the first element in the list (the file name without the extension)\n","  file_name = parts[0]\n","\n","  return file_name\n","\n","def read_images_and_names(dir_path, func=None):\n","    \"\"\"\n","    Read all images and their corresponding names in a directory and return them as a list of tuples.\n","    Each tuple in the list contains a NumPy array representing the image and a string representing the name of the image.\n","\n","    Parameters:\n","        dir_path (str): The path to the directory containing the images and their names.\n","\n","    Returns:\n","        images_and_names: A list of tuples, where each tuple contains a NumPy array representing the image and a string representing the name of the image.\n","    \"\"\"\n","    images_and_names = []\n","    for filename in os.listdir(dir_path):\n","        # Check if file is an image\n","        if filename.endswith(\".png\") or filename.endswith(\".jpg\") or filename.endswith(\".PNG\") or filename.endswith(\n","                \".JPG\") or filename.endswith(\".jpeg\"):\n","            # Read image and store as NumPy array\n","            file_path = os.path.join(dir_path, filename)\n","            image = cv2.imread(file_path)\n","            if func is not None:\n","              image = func(image)\n","            image_name = extract_file_name(file_path)\n","            images_and_names.append((image, image_name))\n","    return images_and_names"],"metadata":{"id":"j1CrSUjms3LX","executionInfo":{"status":"ok","timestamp":1690636199400,"user_tz":-180,"elapsed":9,"user":{"displayName":"Etay Arie Lorberboym","userId":"09023793730623968875"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","execution_count":3,"metadata":{"id":"O8XD_zYG6day","executionInfo":{"status":"ok","timestamp":1690636205078,"user_tz":-180,"elapsed":5685,"user":{"displayName":"Etay Arie Lorberboym","userId":"09023793730623968875"}}},"outputs":[],"source":["import numpy as np\n","import torch\n","import matplotlib.pyplot as plt\n","import cv2\n","import os\n","import pickle\n","import json\n","import pandas as pd"]},{"cell_type":"markdown","source":["# Read Images"],"metadata":{"id":"L01fpoUU5vcK"}},{"cell_type":"code","source":["patches_path = \"/content/drive/MyDrive/Thesis: Cannabis maturity assessment project/experiments/filter relevant areas using SAM\"\n","images_names = read_images_and_names(patches_path)\n","images, names = zip(*images_names)"],"metadata":{"id":"ugtYhIko5xZQ","executionInfo":{"status":"ok","timestamp":1690636208811,"user_tz":-180,"elapsed":3745,"user":{"displayName":"Etay Arie Lorberboym","userId":"09023793730623968875"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["# SAM"],"metadata":{"id":"wPomE6u75L0k"}},{"cell_type":"code","execution_count":5,"metadata":{"id":"4fe300fb","executionInfo":{"status":"ok","timestamp":1690636208812,"user_tz":-180,"elapsed":6,"user":{"displayName":"Etay Arie Lorberboym","userId":"09023793730623968875"}}},"outputs":[],"source":["using_colab = True"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"0685a2f5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1690636239619,"user_tz":-180,"elapsed":30812,"user":{"displayName":"Etay Arie Lorberboym","userId":"09023793730623968875"}},"outputId":"40e64373-8e37-49bd-f49c-595311522fda"},"outputs":[{"output_type":"stream","name":"stdout","text":["PyTorch version: 2.0.1+cu118\n","Torchvision version: 0.15.2+cu118\n","CUDA is available: True\n","Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.7.0.72)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n","Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.22.4)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.1.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.11.0)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.41.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (23.1)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.0)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n","Collecting git+https://github.com/facebookresearch/segment-anything.git\n","  Cloning https://github.com/facebookresearch/segment-anything.git to /tmp/pip-req-build-dd717jy5\n","  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/segment-anything.git /tmp/pip-req-build-dd717jy5\n","  Resolved https://github.com/facebookresearch/segment-anything.git to commit 6fdee8f2727f4506cfbbe553e23b895e27956588\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Building wheels for collected packages: segment-anything\n","  Building wheel for segment-anything (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for segment-anything: filename=segment_anything-1.0-py3-none-any.whl size=36588 sha256=f9584d1f27dc1032f9b4538d273528949f65d0632292890dfe21e57573e761f9\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-23q2npjk/wheels/10/cf/59/9ccb2f0a1bcc81d4fbd0e501680b5d088d690c6cfbc02dc99d\n","Successfully built segment-anything\n","Installing collected packages: segment-anything\n","Successfully installed segment-anything-1.0\n","--2023-07-29 13:10:21--  https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth\n","Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 13.224.249.94, 13.224.249.63, 13.224.249.83, ...\n","Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|13.224.249.94|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 2564550879 (2.4G) [binary/octet-stream]\n","Saving to: ‘sam_vit_h_4b8939.pth’\n","\n","sam_vit_h_4b8939.pt 100%[===================>]   2.39G   183MB/s    in 17s     \n","\n","2023-07-29 13:10:38 (143 MB/s) - ‘sam_vit_h_4b8939.pth’ saved [2564550879/2564550879]\n","\n"]}],"source":["if using_colab:\n","    import torch\n","    import torchvision\n","    print(\"PyTorch version:\", torch.__version__)\n","    print(\"Torchvision version:\", torchvision.__version__)\n","    print(\"CUDA is available:\", torch.cuda.is_available())\n","    import sys\n","    !{sys.executable} -m pip install opencv-python matplotlib\n","    !{sys.executable} -m pip install 'git+https://github.com/facebookresearch/segment-anything.git'\n","\n","    !wget https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"560725a2","executionInfo":{"status":"ok","timestamp":1690636239620,"user_tz":-180,"elapsed":7,"user":{"displayName":"Etay Arie Lorberboym","userId":"09023793730623968875"}}},"outputs":[],"source":["import numpy as np\n","import torch\n","import matplotlib.pyplot as plt\n","import cv2\n","import os"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"74b6e5f0","executionInfo":{"status":"ok","timestamp":1690636239620,"user_tz":-180,"elapsed":6,"user":{"displayName":"Etay Arie Lorberboym","userId":"09023793730623968875"}}},"outputs":[],"source":["def show_anns(anns):\n","    # If there are no annotations, exit the function early\n","    if len(anns) == 0:\n","        return\n","\n","    # Sort the annotations by area in descending order\n","    sorted_anns = sorted(anns, key=(lambda x: x['area']), reverse=True)\n","\n","    # Get the current axis (plot) on which to draw\n","    ax = plt.gca()\n","    # Disable autoscaling of the axis\n","    ax.set_autoscale_on(False)\n","\n","    # Create a transparent image of the same size as the first (largest) annotation\n","    img = np.ones((sorted_anns[0]['segmentation'].shape[0], sorted_anns[0]['segmentation'].shape[1], 4))\n","    img[:,:,3] = 0\n","\n","    # Loop over each annotation\n","    for ann in sorted_anns:\n","        # Get the mask for this annotation\n","        m = ann['segmentation']\n","\n","        # Generate a random color for this mask (RGB + alpha, where alpha is 0.35)\n","        color_mask = np.concatenate([np.random.random(3), [0.35]])\n","\n","        # Apply the color to the mask on the image\n","        img[m] = color_mask\n","\n","    # Display the image with the colored masks\n","    ax.imshow(img)"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"1848a108","executionInfo":{"status":"ok","timestamp":1690636257153,"user_tz":-180,"elapsed":17539,"user":{"displayName":"Etay Arie Lorberboym","userId":"09023793730623968875"}}},"outputs":[],"source":["import sys\n","sys.path.append(\"..\")\n","from segment_anything import sam_model_registry, SamAutomaticMaskGenerator, SamPredictor\n","\n","sam_checkpoint = \"sam_vit_h_4b8939.pth\"\n","model_type = \"vit_h\"\n","\n","device = \"cuda\"\n","\n","sam = sam_model_registry[model_type](checkpoint=sam_checkpoint)\n","sam.to(device=device)\n","\n","mask_generator = SamAutomaticMaskGenerator(sam)"]},{"cell_type":"code","source":["def segments_with_SAM(images_names):\n","    segmentation_dict = {}\n","\n","    for image, name in images_names:\n","        mask = mask_generator.generate(image)\n","        num_segments = len(mask)\n","\n","        # Initialize an array of False with the same shape as the segment masks\n","        instance_bitmap = np.zeros_like(mask[0]['segmentation'], dtype=bool)\n","\n","        # create a single instance bitmap\n","        for seg in mask:\n","          instance_bitmap = np.logical_or(instance_bitmap, seg['segmentation'])\n","\n","\n","        segmentation_dict[name] = {\n","            'mask': mask,\n","            'num_segments': num_segments,\n","            \"instance_bitmap\": instance_bitmap,\n","        }\n","\n","    return segmentation_dict"],"metadata":{"id":"eIiwSOGwcIrC","executionInfo":{"status":"ok","timestamp":1690636257154,"user_tz":-180,"elapsed":15,"user":{"displayName":"Etay Arie Lorberboym","userId":"09023793730623968875"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":["Run the SAM model on the image"],"metadata":{"id":"jEXEIe8lP1z2"}},{"cell_type":"code","source":["mask = mask_generator.generate(images_names[0][0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":398},"id":"RGv-n-Ooc7kv","executionInfo":{"status":"error","timestamp":1690636268661,"user_tz":-180,"elapsed":11521,"user":{"displayName":"Etay Arie Lorberboym","userId":"09023793730623968875"}},"outputId":"a973836a-415d-4f2d-9579-8fb9f1ee16d5"},"execution_count":11,"outputs":[{"output_type":"error","ename":"OutOfMemoryError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-8a2ed94ee3e2>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmask_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/segment_anything/automatic_mask_generator.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, image)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0;31m# Generate masks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m         \u001b[0mmask_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_generate_masks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0;31m# Filter small disconnected regions and holes in masks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/segment_anything/automatic_mask_generator.py\u001b[0m in \u001b[0;36m_generate_masks\u001b[0;34m(self, image)\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMaskData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcrop_box\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_idx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcrop_boxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_idxs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m             \u001b[0mcrop_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_crop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcrop_box\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcrop_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/segment_anything/automatic_mask_generator.py\u001b[0m in \u001b[0;36m_process_crop\u001b[0;34m(self, image, crop_box, crop_layer_idx, orig_size)\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMaskData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpoints\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoints_per_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpoints_for_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m             \u001b[0mbatch_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoints\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcropped_im_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcrop_box\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mbatch_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/segment_anything/automatic_mask_generator.py\u001b[0m in \u001b[0;36m_process_batch\u001b[0;34m(self, points, im_size, crop_box, orig_size)\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpred_iou_thresh\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m             \u001b[0mkeep_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"iou_preds\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpred_iou_thresh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeep_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m         \u001b[0;31m# Calculate stability score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/segment_anything/utils/amg.py\u001b[0m in \u001b[0;36mfilter\u001b[0;34m(self, keep)\u001b[0m\n\u001b[1;32m     47\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkeep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 5.50 GiB (GPU 0; 14.75 GiB total capacity; 11.25 GiB already allocated; 2.41 GiB free; 11.33 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"]}]},{"cell_type":"code","source":["SAM_pred = segments_with_SAM(images_names)"],"metadata":{"id":"fuka7M4y7K6k","executionInfo":{"status":"aborted","timestamp":1690636268662,"user_tz":-180,"elapsed":6,"user":{"displayName":"Etay Arie Lorberboym","userId":"09023793730623968875"}}},"execution_count":null,"outputs":[]}]}