{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Logger detectron2 (DEBUG)>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This notebook have built from this tutorial: https://github.com/bnsreenu/python_for_microscopists/blob/master/330_Detectron2_Instance_3D_EM_Platelet.ipynb\n",
    "import os\n",
    "\n",
    "# Setup detectron2 logger\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing dataset...\n",
      "Preloading all samples. This may take a while...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[38;2;255;153;0m██████████\u001b[0m| 115/115 [00:00<00:00, 1574.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized dataset with 115 images.\n",
      "Exporting dataset. This may take a while...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[38;2;255;153;0m██████████\u001b[0m| 115/115 [00:52<00:00,  2.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported to ./export_coco-instance_etaylor_stigmas_dataset_v0.2.json. Images in segments/etaylor_stigmas_dataset/v0.2\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[01/03 17:56:48 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[01/03 17:56:48 d2.data.datasets.coco]: \u001b[0mLoaded 115 images in COCO format from segments/etaylor_stigmas_dataset/annotations/export_coco-instance_etaylor_stigmas_dataset_v0.2.json\n",
      "Train dataset: 92 samples\n",
      "Test dataset: 23 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from src.segmentation.framework_handlers.detectron2_handler import register_and_split_dataset\n",
    "\n",
    "segments_dataset_name = \"etaylor/stigmas_dataset\"\n",
    "release = \"v0.2\"\n",
    "\n",
    "train_metadata, train_dataset_dicts, test_metadata, test_dataset_dicts = register_and_split_dataset(\n",
    "    dataset_name=segments_dataset_name,\n",
    "    release_version=release,\n",
    "    train_ratio=0.8,  # 80% for training, 20% for testing\n",
    ")\n",
    "\n",
    "print(f\"Train dataset: {len(train_dataset_dicts)} samples\")\n",
    "print(f\"Test dataset: {len(test_dataset_dicts)} samples\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training mask_rcnn_R_50_FPN_3x...\n",
      "\u001b[32m[01/03 20:12:07 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=2, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[01/03 20:12:07 d2.data.build]: \u001b[0mRemoved 3 images with no usable annotations. 89 images left.\n",
      "\u001b[32m[01/03 20:12:07 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[01/03 20:12:07 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[01/03 20:12:07 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[01/03 20:12:07 d2.data.common]: \u001b[0mSerializing 89 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/03 20:12:07 d2.data.common]: \u001b[0mSerialized dataset takes 1.27 MiB\n",
      "\u001b[32m[01/03 20:12:07 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from https://dl.fbaipublicfiles.com/detectron2/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x/137849600/model_final_f10217.pkl ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (2, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (2,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (4, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (4,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (1, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (1,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.mask_head.predictor.{bias, weight}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[01/03 20:12:07 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/etaylor/.conda/envs/detectron_fastai/lib/python3.9/site-packages/detectron2/data/detection_utils.py:446: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)\n",
      "  torch.stack([torch.from_numpy(np.ascontiguousarray(x)) for x in masks])\n",
      "/home/etaylor/.conda/envs/detectron_fastai/lib/python3.9/site-packages/detectron2/data/detection_utils.py:446: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)\n",
      "  torch.stack([torch.from_numpy(np.ascontiguousarray(x)) for x in masks])\n",
      "/home/etaylor/.conda/envs/detectron_fastai/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
      "/home/etaylor/.conda/envs/detectron_fastai/lib/python3.9/site-packages/detectron2/data/detection_utils.py:446: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)\n",
      "  torch.stack([torch.from_numpy(np.ascontiguousarray(x)) for x in masks])\n",
      "/home/etaylor/.conda/envs/detectron_fastai/lib/python3.9/site-packages/detectron2/data/detection_utils.py:446: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)\n",
      "  torch.stack([torch.from_numpy(np.ascontiguousarray(x)) for x in masks])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[01/03 20:12:26 d2.utils.events]: \u001b[0m eta: 0:08:29  iter: 19  total_loss: 2.488  loss_cls: 0.6364  loss_box_reg: 0.2086  loss_mask: 0.6899  loss_rpn_cls: 0.8348  loss_rpn_loc: 0.08507    time: 0.8381  last_time: 1.3471  data_time: 0.6107  last_data_time: 0.9915   lr: 4.9953e-06  max_mem: 9964M\n",
      "\u001b[32m[01/03 20:12:41 d2.utils.events]: \u001b[0m eta: 0:09:15  iter: 39  total_loss: 2.151  loss_cls: 0.5511  loss_box_reg: 0.2729  loss_mask: 0.6846  loss_rpn_cls: 0.5684  loss_rpn_loc: 0.06239    time: 0.7950  last_time: 0.6646  data_time: 0.4098  last_data_time: 0.3433   lr: 9.9902e-06  max_mem: 9964M\n",
      "\u001b[32m[01/03 20:12:55 d2.utils.events]: \u001b[0m eta: 0:08:16  iter: 59  total_loss: 1.816  loss_cls: 0.4438  loss_box_reg: 0.2936  loss_mask: 0.6736  loss_rpn_cls: 0.2916  loss_rpn_loc: 0.05652    time: 0.7610  last_time: 1.1993  data_time: 0.3559  last_data_time: 0.8587   lr: 1.4985e-05  max_mem: 9964M\n",
      "\u001b[32m[01/03 20:13:10 d2.utils.events]: \u001b[0m eta: 0:09:00  iter: 79  total_loss: 1.756  loss_cls: 0.3901  loss_box_reg: 0.4066  loss_mask: 0.6566  loss_rpn_cls: 0.1835  loss_rpn_loc: 0.06286    time: 0.7592  last_time: 0.9164  data_time: 0.3993  last_data_time: 0.5788   lr: 1.998e-05  max_mem: 9964M\n",
      "\u001b[32m[01/03 20:13:26 d2.utils.events]: \u001b[0m eta: 0:08:48  iter: 99  total_loss: 1.645  loss_cls: 0.3405  loss_box_reg: 0.3756  loss_mask: 0.6427  loss_rpn_cls: 0.1937  loss_rpn_loc: 0.07342    time: 0.7674  last_time: 0.8464  data_time: 0.4497  last_data_time: 0.4589   lr: 2.4975e-05  max_mem: 9964M\n",
      "\u001b[32m[01/03 20:13:39 d2.utils.events]: \u001b[0m eta: 0:08:31  iter: 119  total_loss: 1.554  loss_cls: 0.3405  loss_box_reg: 0.4276  loss_mask: 0.6157  loss_rpn_cls: 0.1144  loss_rpn_loc: 0.0496    time: 0.7495  last_time: 1.3205  data_time: 0.3048  last_data_time: 0.9374   lr: 2.997e-05  max_mem: 9964M\n",
      "\u001b[32m[01/03 20:13:53 d2.utils.events]: \u001b[0m eta: 0:08:19  iter: 139  total_loss: 1.575  loss_cls: 0.3332  loss_box_reg: 0.4342  loss_mask: 0.5825  loss_rpn_cls: 0.09583  loss_rpn_loc: 0.06894    time: 0.7416  last_time: 0.5524  data_time: 0.3421  last_data_time: 0.2065   lr: 3.4965e-05  max_mem: 9964M\n",
      "\u001b[32m[01/03 20:14:08 d2.utils.events]: \u001b[0m eta: 0:08:32  iter: 159  total_loss: 1.448  loss_cls: 0.3126  loss_box_reg: 0.4084  loss_mask: 0.5796  loss_rpn_cls: 0.07656  loss_rpn_loc: 0.05685    time: 0.7428  last_time: 0.3396  data_time: 0.3858  last_data_time: 0.0030   lr: 3.996e-05  max_mem: 9964M\n",
      "\u001b[32m[01/03 20:14:22 d2.utils.events]: \u001b[0m eta: 0:08:20  iter: 179  total_loss: 1.51  loss_cls: 0.3476  loss_box_reg: 0.4986  loss_mask: 0.5539  loss_rpn_cls: 0.07377  loss_rpn_loc: 0.06604    time: 0.7369  last_time: 0.8048  data_time: 0.3176  last_data_time: 0.3953   lr: 4.4955e-05  max_mem: 9964M\n",
      "\u001b[32m[01/03 20:14:37 d2.utils.events]: \u001b[0m eta: 0:08:07  iter: 199  total_loss: 1.552  loss_cls: 0.3482  loss_box_reg: 0.5492  loss_mask: 0.5281  loss_rpn_cls: 0.0756  loss_rpn_loc: 0.05931    time: 0.7363  last_time: 0.3562  data_time: 0.3659  last_data_time: 0.0028   lr: 4.995e-05  max_mem: 9964M\n",
      "\u001b[32m[01/03 20:14:51 d2.utils.events]: \u001b[0m eta: 0:07:53  iter: 219  total_loss: 1.496  loss_cls: 0.3321  loss_box_reg: 0.4938  loss_mask: 0.5105  loss_rpn_cls: 0.06824  loss_rpn_loc: 0.05293    time: 0.7360  last_time: 0.8382  data_time: 0.3635  last_data_time: 0.4733   lr: 5.4945e-05  max_mem: 9964M\n",
      "\u001b[32m[01/03 20:15:06 d2.utils.events]: \u001b[0m eta: 0:07:12  iter: 239  total_loss: 1.392  loss_cls: 0.3237  loss_box_reg: 0.4873  loss_mask: 0.4875  loss_rpn_cls: 0.04479  loss_rpn_loc: 0.04983    time: 0.7358  last_time: 0.3453  data_time: 0.3700  last_data_time: 0.0023   lr: 5.994e-05  max_mem: 9964M\n",
      "\u001b[32m[01/03 20:15:19 d2.utils.events]: \u001b[0m eta: 0:06:48  iter: 259  total_loss: 1.443  loss_cls: 0.3194  loss_box_reg: 0.5022  loss_mask: 0.4665  loss_rpn_cls: 0.0621  loss_rpn_loc: 0.04119    time: 0.7280  last_time: 0.3896  data_time: 0.2591  last_data_time: 0.0028   lr: 6.4935e-05  max_mem: 9964M\n",
      "\u001b[32m[01/03 20:15:33 d2.utils.events]: \u001b[0m eta: 0:06:44  iter: 279  total_loss: 1.536  loss_cls: 0.3556  loss_box_reg: 0.6365  loss_mask: 0.4866  loss_rpn_cls: 0.05485  loss_rpn_loc: 0.06512    time: 0.7277  last_time: 0.6328  data_time: 0.3608  last_data_time: 0.2454   lr: 6.993e-05  max_mem: 9964M\n",
      "\u001b[32m[01/03 20:15:49 d2.utils.events]: \u001b[0m eta: 0:06:33  iter: 299  total_loss: 1.565  loss_cls: 0.3448  loss_box_reg: 0.6179  loss_mask: 0.4476  loss_rpn_cls: 0.05768  loss_rpn_loc: 0.06369    time: 0.7316  last_time: 1.4478  data_time: 0.4155  last_data_time: 1.0848   lr: 7.4925e-05  max_mem: 9964M\n",
      "\u001b[32m[01/03 20:16:02 d2.utils.events]: \u001b[0m eta: 0:06:21  iter: 319  total_loss: 1.328  loss_cls: 0.3159  loss_box_reg: 0.5269  loss_mask: 0.4399  loss_rpn_cls: 0.04649  loss_rpn_loc: 0.0402    time: 0.7265  last_time: 0.5668  data_time: 0.2855  last_data_time: 0.1543   lr: 7.992e-05  max_mem: 9964M\n",
      "\u001b[32m[01/03 20:16:16 d2.utils.events]: \u001b[0m eta: 0:06:19  iter: 339  total_loss: 1.456  loss_cls: 0.3345  loss_box_reg: 0.6193  loss_mask: 0.4119  loss_rpn_cls: 0.04193  loss_rpn_loc: 0.04814    time: 0.7251  last_time: 0.9263  data_time: 0.3209  last_data_time: 0.5474   lr: 8.4915e-05  max_mem: 9964M\n",
      "\u001b[32m[01/03 20:16:31 d2.utils.events]: \u001b[0m eta: 0:06:07  iter: 359  total_loss: 1.528  loss_cls: 0.3484  loss_box_reg: 0.6524  loss_mask: 0.4299  loss_rpn_cls: 0.04828  loss_rpn_loc: 0.06154    time: 0.7262  last_time: 1.2779  data_time: 0.3586  last_data_time: 0.9343   lr: 8.991e-05  max_mem: 9964M\n",
      "\u001b[32m[01/03 20:16:45 d2.utils.events]: \u001b[0m eta: 0:05:51  iter: 379  total_loss: 1.547  loss_cls: 0.3548  loss_box_reg: 0.6535  loss_mask: 0.3953  loss_rpn_cls: 0.03641  loss_rpn_loc: 0.05269    time: 0.7259  last_time: 0.7397  data_time: 0.3463  last_data_time: 0.4009   lr: 9.4905e-05  max_mem: 9964M\n",
      "\u001b[32m[01/03 20:17:00 d2.utils.events]: \u001b[0m eta: 0:05:40  iter: 399  total_loss: 1.267  loss_cls: 0.2996  loss_box_reg: 0.5285  loss_mask: 0.3966  loss_rpn_cls: 0.03174  loss_rpn_loc: 0.04985    time: 0.7249  last_time: 0.3897  data_time: 0.3243  last_data_time: 0.0028   lr: 9.99e-05  max_mem: 9964M\n",
      "\u001b[32m[01/03 20:17:13 d2.utils.events]: \u001b[0m eta: 0:05:29  iter: 419  total_loss: 1.298  loss_cls: 0.2843  loss_box_reg: 0.5618  loss_mask: 0.3806  loss_rpn_cls: 0.03217  loss_rpn_loc: 0.04857    time: 0.7231  last_time: 0.3279  data_time: 0.3182  last_data_time: 0.0013   lr: 0.0001049  max_mem: 9964M\n",
      "\u001b[32m[01/03 20:17:28 d2.utils.events]: \u001b[0m eta: 0:05:15  iter: 439  total_loss: 1.395  loss_cls: 0.308  loss_box_reg: 0.6205  loss_mask: 0.3806  loss_rpn_cls: 0.02984  loss_rpn_loc: 0.05154    time: 0.7247  last_time: 1.0362  data_time: 0.3770  last_data_time: 0.6541   lr: 0.00010989  max_mem: 9964M\n",
      "\u001b[32m[01/03 20:17:43 d2.utils.events]: \u001b[0m eta: 0:04:59  iter: 459  total_loss: 1.354  loss_cls: 0.3228  loss_box_reg: 0.5622  loss_mask: 0.3693  loss_rpn_cls: 0.03175  loss_rpn_loc: 0.06235    time: 0.7246  last_time: 1.1002  data_time: 0.3213  last_data_time: 0.6952   lr: 0.00011489  max_mem: 9964M\n",
      "\u001b[32m[01/03 20:17:57 d2.utils.events]: \u001b[0m eta: 0:04:48  iter: 479  total_loss: 1.383  loss_cls: 0.3156  loss_box_reg: 0.598  loss_mask: 0.3666  loss_rpn_cls: 0.02593  loss_rpn_loc: 0.0499    time: 0.7231  last_time: 0.8853  data_time: 0.3130  last_data_time: 0.5085   lr: 0.00011988  max_mem: 9964M\n",
      "\u001b[32m[01/03 20:18:11 d2.utils.events]: \u001b[0m eta: 0:04:37  iter: 499  total_loss: 1.355  loss_cls: 0.2996  loss_box_reg: 0.5771  loss_mask: 0.3533  loss_rpn_cls: 0.03123  loss_rpn_loc: 0.05705    time: 0.7228  last_time: 0.4408  data_time: 0.3409  last_data_time: 0.1398   lr: 0.00012488  max_mem: 9964M\n",
      "\u001b[32m[01/03 20:18:24 d2.utils.events]: \u001b[0m eta: 0:04:27  iter: 519  total_loss: 1.16  loss_cls: 0.2912  loss_box_reg: 0.4992  loss_mask: 0.3463  loss_rpn_cls: 0.0251  loss_rpn_loc: 0.04495    time: 0.7198  last_time: 0.4096  data_time: 0.2647  last_data_time: 0.0329   lr: 0.00012987  max_mem: 9964M\n",
      "\u001b[32m[01/03 20:18:39 d2.utils.events]: \u001b[0m eta: 0:04:16  iter: 539  total_loss: 1.325  loss_cls: 0.3002  loss_box_reg: 0.5691  loss_mask: 0.3617  loss_rpn_cls: 0.02815  loss_rpn_loc: 0.05469    time: 0.7215  last_time: 1.6232  data_time: 0.3819  last_data_time: 1.2365   lr: 0.00013487  max_mem: 9964M\n",
      "\u001b[32m[01/03 20:18:53 d2.utils.events]: \u001b[0m eta: 0:04:04  iter: 559  total_loss: 1.251  loss_cls: 0.2941  loss_box_reg: 0.539  loss_mask: 0.3446  loss_rpn_cls: 0.02469  loss_rpn_loc: 0.05139    time: 0.7201  last_time: 0.3461  data_time: 0.3087  last_data_time: 0.0010   lr: 0.00013986  max_mem: 9964M\n",
      "\u001b[32m[01/03 20:19:08 d2.utils.events]: \u001b[0m eta: 0:03:53  iter: 579  total_loss: 1.245  loss_cls: 0.2988  loss_box_reg: 0.5113  loss_mask: 0.352  loss_rpn_cls: 0.03065  loss_rpn_loc: 0.05785    time: 0.7207  last_time: 0.3611  data_time: 0.3637  last_data_time: 0.0018   lr: 0.00014486  max_mem: 9964M\n",
      "\u001b[32m[01/03 20:19:21 d2.utils.events]: \u001b[0m eta: 0:03:42  iter: 599  total_loss: 1.221  loss_cls: 0.2941  loss_box_reg: 0.523  loss_mask: 0.3346  loss_rpn_cls: 0.0222  loss_rpn_loc: 0.04832    time: 0.7195  last_time: 1.8916  data_time: 0.3045  last_data_time: 1.4444   lr: 0.00014985  max_mem: 9964M\n",
      "\u001b[32m[01/03 20:19:34 d2.utils.events]: \u001b[0m eta: 0:03:30  iter: 619  total_loss: 1.151  loss_cls: 0.2735  loss_box_reg: 0.4468  loss_mask: 0.3355  loss_rpn_cls: 0.01816  loss_rpn_loc: 0.04049    time: 0.7171  last_time: 0.4424  data_time: 0.2579  last_data_time: 0.0023   lr: 0.00015485  max_mem: 9964M\n",
      "\u001b[32m[01/03 20:19:48 d2.utils.events]: \u001b[0m eta: 0:03:19  iter: 639  total_loss: 1.197  loss_cls: 0.2731  loss_box_reg: 0.5056  loss_mask: 0.3431  loss_rpn_cls: 0.02094  loss_rpn_loc: 0.04548    time: 0.7164  last_time: 0.6871  data_time: 0.3019  last_data_time: 0.3200   lr: 0.00015984  max_mem: 9964M\n",
      "\u001b[32m[01/03 20:20:03 d2.utils.events]: \u001b[0m eta: 0:03:07  iter: 659  total_loss: 1.195  loss_cls: 0.2746  loss_box_reg: 0.4849  loss_mask: 0.3528  loss_rpn_cls: 0.02814  loss_rpn_loc: 0.05472    time: 0.7166  last_time: 1.0664  data_time: 0.3409  last_data_time: 0.6948   lr: 0.00016484  max_mem: 9964M\n",
      "\u001b[32m[01/03 20:20:18 d2.utils.events]: \u001b[0m eta: 0:02:55  iter: 679  total_loss: 1.206  loss_cls: 0.282  loss_box_reg: 0.5008  loss_mask: 0.3501  loss_rpn_cls: 0.02056  loss_rpn_loc: 0.0553    time: 0.7183  last_time: 1.5332  data_time: 0.3981  last_data_time: 1.1596   lr: 0.00016983  max_mem: 9964M\n",
      "\u001b[32m[01/03 20:20:31 d2.utils.events]: \u001b[0m eta: 0:02:44  iter: 699  total_loss: 1.187  loss_cls: 0.2919  loss_box_reg: 0.4926  loss_mask: 0.3189  loss_rpn_cls: 0.0248  loss_rpn_loc: 0.03945    time: 0.7163  last_time: 0.3565  data_time: 0.2710  last_data_time: 0.0023   lr: 0.00017483  max_mem: 9964M\n",
      "\u001b[32m[01/03 20:20:44 d2.utils.events]: \u001b[0m eta: 0:02:33  iter: 719  total_loss: 0.9252  loss_cls: 0.2333  loss_box_reg: 0.3801  loss_mask: 0.2925  loss_rpn_cls: 0.01261  loss_rpn_loc: 0.03083    time: 0.7145  last_time: 0.7164  data_time: 0.2662  last_data_time: 0.3556   lr: 0.00017982  max_mem: 9964M\n",
      "\u001b[32m[01/03 20:20:59 d2.utils.events]: \u001b[0m eta: 0:02:22  iter: 739  total_loss: 1.163  loss_cls: 0.2733  loss_box_reg: 0.4812  loss_mask: 0.3426  loss_rpn_cls: 0.01937  loss_rpn_loc: 0.05269    time: 0.7145  last_time: 0.4013  data_time: 0.3247  last_data_time: 0.0030   lr: 0.00018482  max_mem: 9964M\n",
      "\u001b[32m[01/03 20:21:13 d2.utils.events]: \u001b[0m eta: 0:02:10  iter: 759  total_loss: 1.133  loss_cls: 0.2562  loss_box_reg: 0.4677  loss_mask: 0.3279  loss_rpn_cls: 0.0217  loss_rpn_loc: 0.04401    time: 0.7142  last_time: 0.3247  data_time: 0.3277  last_data_time: 0.0055   lr: 0.00018981  max_mem: 9964M\n",
      "\u001b[32m[01/03 20:21:27 d2.utils.events]: \u001b[0m eta: 0:01:59  iter: 779  total_loss: 1.165  loss_cls: 0.2588  loss_box_reg: 0.4672  loss_mask: 0.3198  loss_rpn_cls: 0.01864  loss_rpn_loc: 0.04636    time: 0.7143  last_time: 1.3690  data_time: 0.3247  last_data_time: 0.9475   lr: 0.00019481  max_mem: 9964M\n",
      "\u001b[32m[01/03 20:21:39 d2.utils.events]: \u001b[0m eta: 0:01:49  iter: 799  total_loss: 1.07  loss_cls: 0.2498  loss_box_reg: 0.4408  loss_mask: 0.3098  loss_rpn_cls: 0.01916  loss_rpn_loc: 0.03667    time: 0.7116  last_time: 0.6900  data_time: 0.2174  last_data_time: 0.2582   lr: 0.0001998  max_mem: 9964M\n",
      "\u001b[32m[01/03 20:21:55 d2.utils.events]: \u001b[0m eta: 0:01:38  iter: 819  total_loss: 1.124  loss_cls: 0.2515  loss_box_reg: 0.4446  loss_mask: 0.3122  loss_rpn_cls: 0.0164  loss_rpn_loc: 0.04912    time: 0.7133  last_time: 0.6440  data_time: 0.4033  last_data_time: 0.2928   lr: 0.0002048  max_mem: 9964M\n",
      "\u001b[32m[01/03 20:22:08 d2.utils.events]: \u001b[0m eta: 0:01:27  iter: 839  total_loss: 1.048  loss_cls: 0.2633  loss_box_reg: 0.3948  loss_mask: 0.2999  loss_rpn_cls: 0.01715  loss_rpn_loc: 0.03305    time: 0.7117  last_time: 0.4434  data_time: 0.2673  last_data_time: 0.0820   lr: 0.00020979  max_mem: 9964M\n",
      "\u001b[32m[01/03 20:22:21 d2.utils.events]: \u001b[0m eta: 0:01:16  iter: 859  total_loss: 1.093  loss_cls: 0.2665  loss_box_reg: 0.442  loss_mask: 0.3171  loss_rpn_cls: 0.01576  loss_rpn_loc: 0.04114    time: 0.7100  last_time: 0.8535  data_time: 0.2626  last_data_time: 0.4722   lr: 0.00021479  max_mem: 9964M\n",
      "\u001b[32m[01/03 20:22:36 d2.utils.events]: \u001b[0m eta: 0:01:05  iter: 879  total_loss: 1.093  loss_cls: 0.2665  loss_box_reg: 0.4335  loss_mask: 0.3299  loss_rpn_cls: 0.01827  loss_rpn_loc: 0.04771    time: 0.7116  last_time: 0.4833  data_time: 0.4003  last_data_time: 0.1129   lr: 0.00021978  max_mem: 9964M\n",
      "\u001b[32m[01/03 20:22:49 d2.utils.events]: \u001b[0m eta: 0:00:54  iter: 899  total_loss: 0.9114  loss_cls: 0.2166  loss_box_reg: 0.3446  loss_mask: 0.2862  loss_rpn_cls: 0.01545  loss_rpn_loc: 0.03284    time: 0.7098  last_time: 0.5307  data_time: 0.2515  last_data_time: 0.1656   lr: 0.00022478  max_mem: 9964M\n",
      "\u001b[32m[01/03 20:23:05 d2.utils.events]: \u001b[0m eta: 0:00:43  iter: 919  total_loss: 1.129  loss_cls: 0.2651  loss_box_reg: 0.4657  loss_mask: 0.2988  loss_rpn_cls: 0.01304  loss_rpn_loc: 0.04685    time: 0.7115  last_time: 0.6716  data_time: 0.4026  last_data_time: 0.2641   lr: 0.00022977  max_mem: 9964M\n",
      "\u001b[32m[01/03 20:23:19 d2.utils.events]: \u001b[0m eta: 0:00:32  iter: 939  total_loss: 1.034  loss_cls: 0.2352  loss_box_reg: 0.4101  loss_mask: 0.3121  loss_rpn_cls: 0.01257  loss_rpn_loc: 0.03506    time: 0.7113  last_time: 1.5425  data_time: 0.3062  last_data_time: 1.1100   lr: 0.00023477  max_mem: 9964M\n",
      "\u001b[32m[01/03 20:23:31 d2.utils.events]: \u001b[0m eta: 0:00:21  iter: 959  total_loss: 0.845  loss_cls: 0.2161  loss_box_reg: 0.3374  loss_mask: 0.283  loss_rpn_cls: 0.008483  loss_rpn_loc: 0.03109    time: 0.7095  last_time: 0.3531  data_time: 0.2502  last_data_time: 0.0024   lr: 0.00023976  max_mem: 9964M\n",
      "\u001b[32m[01/03 20:23:46 d2.utils.events]: \u001b[0m eta: 0:00:10  iter: 979  total_loss: 1.125  loss_cls: 0.2464  loss_box_reg: 0.4791  loss_mask: 0.3281  loss_rpn_cls: 0.02019  loss_rpn_loc: 0.04258    time: 0.7105  last_time: 0.7795  data_time: 0.3742  last_data_time: 0.4461   lr: 0.00024476  max_mem: 9964M\n",
      "\u001b[32m[01/03 20:24:03 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 999  total_loss: 1.066  loss_cls: 0.2584  loss_box_reg: 0.446  loss_mask: 0.3021  loss_rpn_cls: 0.01189  loss_rpn_loc: 0.04234    time: 0.7125  last_time: 1.7637  data_time: 0.4342  last_data_time: 1.4021   lr: 0.00024975  max_mem: 9964M\n",
      "\u001b[32m[01/03 20:24:03 d2.engine.hooks]: \u001b[0mOverall training speed: 998 iterations in 0:11:51 (0.7125 s / it)\n",
      "\u001b[32m[01/03 20:24:03 d2.engine.hooks]: \u001b[0mTotal training time: 0:11:52 (0:00:01 on hooks)\n",
      "\u001b[32m[01/03 20:24:03 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/03 20:24:03 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[01/03 20:24:03 d2.data.common]: \u001b[0mSerializing 23 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/03 20:24:03 d2.data.common]: \u001b[0mSerialized dataset takes 0.37 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[01/03 20:24:03 d2.engine.defaults]: \u001b[0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.\n",
      "Finished training mask_rcnn_R_50_FPN_3x. Model saved in /home/etaylor/code_projects/thesis/checkpoints/stigmas_segmentation/detectron2/fine_tuned/mask_rcnn_R_50_FPN_3x\n",
      "Training mask_rcnn_R_101_FPN_3x...\n",
      "\u001b[32m[01/03 20:24:05 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (6): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (7): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (8): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (9): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (10): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (11): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (12): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (13): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (14): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (15): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (16): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (17): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (18): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (19): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (20): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (21): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (22): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=2, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[01/03 20:24:05 d2.data.build]: \u001b[0mRemoved 3 images with no usable annotations. 89 images left.\n",
      "\u001b[32m[01/03 20:24:05 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[01/03 20:24:05 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[01/03 20:24:05 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[01/03 20:24:05 d2.data.common]: \u001b[0mSerializing 89 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/03 20:24:05 d2.data.common]: \u001b[0mSerialized dataset takes 1.27 MiB\n",
      "\u001b[32m[01/03 20:24:05 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from https://dl.fbaipublicfiles.com/detectron2/COCO-InstanceSegmentation/mask_rcnn_R_101_FPN_3x/138205316/model_final_a3ec72.pkl ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (2, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (2,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (4, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (4,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (1, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (1,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.mask_head.predictor.{bias, weight}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[01/03 20:24:05 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/etaylor/.conda/envs/detectron_fastai/lib/python3.9/site-packages/detectron2/data/detection_utils.py:446: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)\n",
      "  torch.stack([torch.from_numpy(np.ascontiguousarray(x)) for x in masks])\n",
      "/home/etaylor/.conda/envs/detectron_fastai/lib/python3.9/site-packages/detectron2/data/detection_utils.py:446: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)\n",
      "  torch.stack([torch.from_numpy(np.ascontiguousarray(x)) for x in masks])\n",
      "/home/etaylor/.conda/envs/detectron_fastai/lib/python3.9/site-packages/detectron2/data/detection_utils.py:446: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)\n",
      "  torch.stack([torch.from_numpy(np.ascontiguousarray(x)) for x in masks])\n",
      "/home/etaylor/.conda/envs/detectron_fastai/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
      "/home/etaylor/.conda/envs/detectron_fastai/lib/python3.9/site-packages/detectron2/data/detection_utils.py:446: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)\n",
      "  torch.stack([torch.from_numpy(np.ascontiguousarray(x)) for x in masks])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[01/03 20:24:22 d2.utils.events]: \u001b[0m eta: 0:10:16  iter: 19  total_loss: 2.58  loss_cls: 0.582  loss_box_reg: 0.2593  loss_mask: 0.6913  loss_rpn_cls: 0.942  loss_rpn_loc: 0.08704    time: 0.7807  last_time: 1.1767  data_time: 0.3960  last_data_time: 0.6739   lr: 4.9953e-06  max_mem: 9964M\n",
      "\u001b[32m[01/03 20:24:36 d2.utils.events]: \u001b[0m eta: 0:09:13  iter: 39  total_loss: 2.045  loss_cls: 0.5044  loss_box_reg: 0.2072  loss_mask: 0.6863  loss_rpn_cls: 0.5813  loss_rpn_loc: 0.05334    time: 0.7206  last_time: 1.8116  data_time: 0.1993  last_data_time: 1.3618   lr: 9.9902e-06  max_mem: 9964M\n",
      "\u001b[32m[01/03 20:24:52 d2.utils.events]: \u001b[0m eta: 0:09:01  iter: 59  total_loss: 1.982  loss_cls: 0.4258  loss_box_reg: 0.3035  loss_mask: 0.677  loss_rpn_cls: 0.5371  loss_rpn_loc: 0.07244    time: 0.7529  last_time: 0.4370  data_time: 0.3759  last_data_time: 0.0029   lr: 1.4985e-05  max_mem: 9964M\n",
      "\u001b[32m[01/03 20:25:06 d2.utils.events]: \u001b[0m eta: 0:08:45  iter: 79  total_loss: 1.649  loss_cls: 0.3681  loss_box_reg: 0.325  loss_mask: 0.6625  loss_rpn_cls: 0.1756  loss_rpn_loc: 0.05309    time: 0.7365  last_time: 0.4946  data_time: 0.2413  last_data_time: 0.0022   lr: 1.998e-05  max_mem: 9964M\n",
      "\u001b[32m[01/03 20:25:20 d2.utils.events]: \u001b[0m eta: 0:08:39  iter: 99  total_loss: 1.753  loss_cls: 0.3551  loss_box_reg: 0.3741  loss_mask: 0.6433  loss_rpn_cls: 0.1804  loss_rpn_loc: 0.06883    time: 0.7302  last_time: 0.4673  data_time: 0.2400  last_data_time: 0.0038   lr: 2.4975e-05  max_mem: 9964M\n",
      "\u001b[32m[01/03 20:25:35 d2.utils.events]: \u001b[0m eta: 0:08:29  iter: 119  total_loss: 1.516  loss_cls: 0.33  loss_box_reg: 0.3745  loss_mask: 0.6279  loss_rpn_cls: 0.1127  loss_rpn_loc: 0.06342    time: 0.7318  last_time: 0.5085  data_time: 0.2619  last_data_time: 0.0055   lr: 2.997e-05  max_mem: 9964M\n",
      "\u001b[32m[01/03 20:25:49 d2.utils.events]: \u001b[0m eta: 0:08:21  iter: 139  total_loss: 1.526  loss_cls: 0.3344  loss_box_reg: 0.4242  loss_mask: 0.6085  loss_rpn_cls: 0.09737  loss_rpn_loc: 0.05662    time: 0.7268  last_time: 0.8059  data_time: 0.2350  last_data_time: 0.3663   lr: 3.4965e-05  max_mem: 9964M\n",
      "\u001b[32m[01/03 20:26:03 d2.utils.events]: \u001b[0m eta: 0:08:09  iter: 159  total_loss: 1.49  loss_cls: 0.3378  loss_box_reg: 0.4312  loss_mask: 0.584  loss_rpn_cls: 0.08005  loss_rpn_loc: 0.04981    time: 0.7234  last_time: 1.2654  data_time: 0.2307  last_data_time: 0.7885   lr: 3.996e-05  max_mem: 9964M\n",
      "\u001b[32m[01/03 20:26:18 d2.utils.events]: \u001b[0m eta: 0:07:57  iter: 179  total_loss: 1.508  loss_cls: 0.324  loss_box_reg: 0.4485  loss_mask: 0.5562  loss_rpn_cls: 0.07644  loss_rpn_loc: 0.05435    time: 0.7271  last_time: 0.6862  data_time: 0.2695  last_data_time: 0.1875   lr: 4.4955e-05  max_mem: 9964M\n",
      "\u001b[32m[01/03 20:26:32 d2.utils.events]: \u001b[0m eta: 0:07:51  iter: 199  total_loss: 1.603  loss_cls: 0.361  loss_box_reg: 0.5119  loss_mask: 0.554  loss_rpn_cls: 0.06538  loss_rpn_loc: 0.06232    time: 0.7230  last_time: 0.4701  data_time: 0.2151  last_data_time: 0.0026   lr: 4.995e-05  max_mem: 9964M\n",
      "\u001b[32m[01/03 20:26:47 d2.utils.events]: \u001b[0m eta: 0:07:43  iter: 219  total_loss: 1.562  loss_cls: 0.367  loss_box_reg: 0.5885  loss_mask: 0.5156  loss_rpn_cls: 0.06654  loss_rpn_loc: 0.06743    time: 0.7281  last_time: 1.5878  data_time: 0.3010  last_data_time: 1.0877   lr: 5.4945e-05  max_mem: 9964M\n",
      "\u001b[32m[01/03 20:27:02 d2.utils.events]: \u001b[0m eta: 0:07:19  iter: 239  total_loss: 1.571  loss_cls: 0.352  loss_box_reg: 0.559  loss_mask: 0.4947  loss_rpn_cls: 0.06459  loss_rpn_loc: 0.05755    time: 0.7280  last_time: 0.4590  data_time: 0.2590  last_data_time: 0.0026   lr: 5.994e-05  max_mem: 9964M\n",
      "\u001b[32m[01/03 20:27:16 d2.utils.events]: \u001b[0m eta: 0:07:11  iter: 259  total_loss: 1.501  loss_cls: 0.3478  loss_box_reg: 0.5687  loss_mask: 0.482  loss_rpn_cls: 0.04925  loss_rpn_loc: 0.04959    time: 0.7245  last_time: 0.4361  data_time: 0.2122  last_data_time: 0.0034   lr: 6.4935e-05  max_mem: 9964M\n",
      "\u001b[32m[01/03 20:27:29 d2.utils.events]: \u001b[0m eta: 0:07:01  iter: 279  total_loss: 1.46  loss_cls: 0.3313  loss_box_reg: 0.5541  loss_mask: 0.4427  loss_rpn_cls: 0.05203  loss_rpn_loc: 0.04681    time: 0.7194  last_time: 0.6750  data_time: 0.1995  last_data_time: 0.1986   lr: 6.993e-05  max_mem: 9964M\n",
      "\u001b[32m[01/03 20:27:43 d2.utils.events]: \u001b[0m eta: 0:06:55  iter: 299  total_loss: 1.466  loss_cls: 0.3425  loss_box_reg: 0.5799  loss_mask: 0.4431  loss_rpn_cls: 0.04311  loss_rpn_loc: 0.05375    time: 0.7177  last_time: 0.6038  data_time: 0.2208  last_data_time: 0.1045   lr: 7.4925e-05  max_mem: 9964M\n",
      "\u001b[32m[01/03 20:27:57 d2.utils.events]: \u001b[0m eta: 0:06:42  iter: 319  total_loss: 1.508  loss_cls: 0.3531  loss_box_reg: 0.6014  loss_mask: 0.4475  loss_rpn_cls: 0.04629  loss_rpn_loc: 0.05386    time: 0.7179  last_time: 0.6025  data_time: 0.2410  last_data_time: 0.0831   lr: 7.992e-05  max_mem: 9964M\n",
      "\u001b[32m[01/03 20:28:11 d2.utils.events]: \u001b[0m eta: 0:06:33  iter: 339  total_loss: 1.416  loss_cls: 0.3279  loss_box_reg: 0.5522  loss_mask: 0.3965  loss_rpn_cls: 0.04178  loss_rpn_loc: 0.05614    time: 0.7163  last_time: 0.4027  data_time: 0.2139  last_data_time: 0.0028   lr: 8.4915e-05  max_mem: 9964M\n",
      "\u001b[32m[01/03 20:28:25 d2.utils.events]: \u001b[0m eta: 0:06:22  iter: 359  total_loss: 1.542  loss_cls: 0.3599  loss_box_reg: 0.6976  loss_mask: 0.3955  loss_rpn_cls: 0.03398  loss_rpn_loc: 0.05673    time: 0.7163  last_time: 0.7260  data_time: 0.2260  last_data_time: 0.2596   lr: 8.991e-05  max_mem: 9964M\n",
      "\u001b[32m[01/03 20:28:40 d2.utils.events]: \u001b[0m eta: 0:06:09  iter: 379  total_loss: 1.443  loss_cls: 0.3462  loss_box_reg: 0.6447  loss_mask: 0.3894  loss_rpn_cls: 0.03423  loss_rpn_loc: 0.04496    time: 0.7186  last_time: 0.5596  data_time: 0.2534  last_data_time: 0.0117   lr: 9.4905e-05  max_mem: 9964M\n",
      "\u001b[32m[01/03 20:28:54 d2.utils.events]: \u001b[0m eta: 0:05:57  iter: 399  total_loss: 1.333  loss_cls: 0.2834  loss_box_reg: 0.5499  loss_mask: 0.3809  loss_rpn_cls: 0.02999  loss_rpn_loc: 0.04439    time: 0.7167  last_time: 0.4744  data_time: 0.1989  last_data_time: 0.0025   lr: 9.99e-05  max_mem: 9964M\n",
      "\u001b[32m[01/03 20:29:08 d2.utils.events]: \u001b[0m eta: 0:05:45  iter: 419  total_loss: 1.29  loss_cls: 0.2766  loss_box_reg: 0.5544  loss_mask: 0.3684  loss_rpn_cls: 0.03448  loss_rpn_loc: 0.05578    time: 0.7170  last_time: 0.5112  data_time: 0.2425  last_data_time: 0.0016   lr: 0.0001049  max_mem: 9964M\n",
      "\u001b[32m[01/03 20:29:23 d2.utils.events]: \u001b[0m eta: 0:05:33  iter: 439  total_loss: 1.194  loss_cls: 0.267  loss_box_reg: 0.5427  loss_mask: 0.3452  loss_rpn_cls: 0.02708  loss_rpn_loc: 0.03721    time: 0.7168  last_time: 0.5256  data_time: 0.2220  last_data_time: 0.0044   lr: 0.00010989  max_mem: 9964M\n",
      "\u001b[32m[01/03 20:29:37 d2.utils.events]: \u001b[0m eta: 0:05:20  iter: 459  total_loss: 1.336  loss_cls: 0.305  loss_box_reg: 0.5923  loss_mask: 0.3653  loss_rpn_cls: 0.03128  loss_rpn_loc: 0.0493    time: 0.7172  last_time: 0.5193  data_time: 0.2368  last_data_time: 0.0014   lr: 0.00011489  max_mem: 9964M\n",
      "\u001b[32m[01/03 20:29:52 d2.utils.events]: \u001b[0m eta: 0:05:09  iter: 479  total_loss: 1.231  loss_cls: 0.2919  loss_box_reg: 0.5756  loss_mask: 0.3124  loss_rpn_cls: 0.02263  loss_rpn_loc: 0.04922    time: 0.7179  last_time: 0.9742  data_time: 0.2457  last_data_time: 0.4263   lr: 0.00011988  max_mem: 9964M\n",
      "\u001b[32m[01/03 20:30:06 d2.utils.events]: \u001b[0m eta: 0:04:58  iter: 499  total_loss: 1.267  loss_cls: 0.2875  loss_box_reg: 0.5622  loss_mask: 0.3727  loss_rpn_cls: 0.02721  loss_rpn_loc: 0.03797    time: 0.7181  last_time: 0.6463  data_time: 0.2354  last_data_time: 0.2097   lr: 0.00012488  max_mem: 9964M\n",
      "\u001b[32m[01/03 20:30:22 d2.utils.events]: \u001b[0m eta: 0:04:48  iter: 519  total_loss: 1.166  loss_cls: 0.2613  loss_box_reg: 0.5181  loss_mask: 0.3345  loss_rpn_cls: 0.02928  loss_rpn_loc: 0.0532    time: 0.7199  last_time: 0.4644  data_time: 0.2730  last_data_time: 0.0057   lr: 0.00012987  max_mem: 9964M\n",
      "\u001b[32m[01/03 20:30:34 d2.utils.events]: \u001b[0m eta: 0:04:35  iter: 539  total_loss: 1.076  loss_cls: 0.2685  loss_box_reg: 0.4398  loss_mask: 0.3235  loss_rpn_cls: 0.01761  loss_rpn_loc: 0.03713    time: 0.7162  last_time: 0.7644  data_time: 0.1473  last_data_time: 0.2647   lr: 0.00013487  max_mem: 9964M\n",
      "\u001b[32m[01/03 20:30:49 d2.utils.events]: \u001b[0m eta: 0:04:24  iter: 559  total_loss: 1.128  loss_cls: 0.2585  loss_box_reg: 0.4734  loss_mask: 0.3216  loss_rpn_cls: 0.02124  loss_rpn_loc: 0.04064    time: 0.7162  last_time: 0.7180  data_time: 0.2366  last_data_time: 0.1877   lr: 0.00013986  max_mem: 9964M\n",
      "\u001b[32m[01/03 20:31:04 d2.utils.events]: \u001b[0m eta: 0:04:12  iter: 579  total_loss: 1.261  loss_cls: 0.3083  loss_box_reg: 0.5859  loss_mask: 0.3458  loss_rpn_cls: 0.0276  loss_rpn_loc: 0.05772    time: 0.7180  last_time: 0.8142  data_time: 0.2954  last_data_time: 0.3819   lr: 0.00014486  max_mem: 9964M\n",
      "\u001b[32m[01/03 20:31:19 d2.utils.events]: \u001b[0m eta: 0:04:00  iter: 599  total_loss: 1.094  loss_cls: 0.2602  loss_box_reg: 0.3878  loss_mask: 0.3355  loss_rpn_cls: 0.02127  loss_rpn_loc: 0.04203    time: 0.7186  last_time: 0.5404  data_time: 0.2539  last_data_time: 0.0825   lr: 0.00014985  max_mem: 9964M\n",
      "\u001b[32m[01/03 20:31:33 d2.utils.events]: \u001b[0m eta: 0:03:49  iter: 619  total_loss: 1.117  loss_cls: 0.2861  loss_box_reg: 0.4601  loss_mask: 0.312  loss_rpn_cls: 0.02139  loss_rpn_loc: 0.04122    time: 0.7193  last_time: 0.5583  data_time: 0.2440  last_data_time: 0.0057   lr: 0.00015485  max_mem: 9964M\n",
      "\u001b[32m[01/03 20:31:47 d2.utils.events]: \u001b[0m eta: 0:03:37  iter: 639  total_loss: 1.093  loss_cls: 0.2625  loss_box_reg: 0.454  loss_mask: 0.3214  loss_rpn_cls: 0.0173  loss_rpn_loc: 0.0402    time: 0.7182  last_time: 0.6590  data_time: 0.2076  last_data_time: 0.1595   lr: 0.00015984  max_mem: 9964M\n",
      "\u001b[32m[01/03 20:32:03 d2.utils.events]: \u001b[0m eta: 0:03:27  iter: 659  total_loss: 1.18  loss_cls: 0.2871  loss_box_reg: 0.4736  loss_mask: 0.3106  loss_rpn_cls: 0.02518  loss_rpn_loc: 0.05707    time: 0.7198  last_time: 0.5435  data_time: 0.2910  last_data_time: 0.0013   lr: 0.00016484  max_mem: 9964M\n",
      "\u001b[32m[01/03 20:32:17 d2.utils.events]: \u001b[0m eta: 0:03:13  iter: 679  total_loss: 0.9002  loss_cls: 0.2413  loss_box_reg: 0.3341  loss_mask: 0.2952  loss_rpn_cls: 0.01261  loss_rpn_loc: 0.0433    time: 0.7196  last_time: 0.4367  data_time: 0.2420  last_data_time: 0.0021   lr: 0.00016983  max_mem: 9964M\n",
      "\u001b[32m[01/03 20:32:34 d2.utils.events]: \u001b[0m eta: 0:03:03  iter: 699  total_loss: 1.179  loss_cls: 0.2835  loss_box_reg: 0.4806  loss_mask: 0.313  loss_rpn_cls: 0.01638  loss_rpn_loc: 0.05419    time: 0.7229  last_time: 1.3026  data_time: 0.3305  last_data_time: 0.7554   lr: 0.00017483  max_mem: 9964M\n",
      "\u001b[32m[01/03 20:32:47 d2.utils.events]: \u001b[0m eta: 0:02:49  iter: 719  total_loss: 0.8954  loss_cls: 0.2372  loss_box_reg: 0.3471  loss_mask: 0.2938  loss_rpn_cls: 0.01224  loss_rpn_loc: 0.03222    time: 0.7209  last_time: 0.5754  data_time: 0.1707  last_data_time: 0.1221   lr: 0.00017982  max_mem: 9964M\n",
      "\u001b[32m[01/03 20:33:01 d2.utils.events]: \u001b[0m eta: 0:02:38  iter: 739  total_loss: 1.078  loss_cls: 0.2583  loss_box_reg: 0.4449  loss_mask: 0.3134  loss_rpn_cls: 0.01679  loss_rpn_loc: 0.04099    time: 0.7213  last_time: 0.4994  data_time: 0.2552  last_data_time: 0.0044   lr: 0.00018482  max_mem: 9964M\n",
      "\u001b[32m[01/03 20:33:17 d2.utils.events]: \u001b[0m eta: 0:02:26  iter: 759  total_loss: 1.03  loss_cls: 0.2534  loss_box_reg: 0.4068  loss_mask: 0.3048  loss_rpn_cls: 0.01915  loss_rpn_loc: 0.04178    time: 0.7227  last_time: 0.7598  data_time: 0.3036  last_data_time: 0.2882   lr: 0.00018981  max_mem: 9964M\n",
      "\u001b[32m[01/03 20:33:30 d2.utils.events]: \u001b[0m eta: 0:02:14  iter: 779  total_loss: 1.009  loss_cls: 0.2399  loss_box_reg: 0.4102  loss_mask: 0.3061  loss_rpn_cls: 0.01138  loss_rpn_loc: 0.04078    time: 0.7214  last_time: 0.6970  data_time: 0.1848  last_data_time: 0.3093   lr: 0.00019481  max_mem: 9964M\n",
      "\u001b[32m[01/03 20:33:45 d2.utils.events]: \u001b[0m eta: 0:02:02  iter: 799  total_loss: 0.9693  loss_cls: 0.2363  loss_box_reg: 0.3885  loss_mask: 0.2978  loss_rpn_cls: 0.00954  loss_rpn_loc: 0.03206    time: 0.7215  last_time: 0.4109  data_time: 0.2483  last_data_time: 0.0023   lr: 0.0001998  max_mem: 9964M\n",
      "\u001b[32m[01/03 20:34:00 d2.utils.events]: \u001b[0m eta: 0:01:50  iter: 819  total_loss: 1.06  loss_cls: 0.2396  loss_box_reg: 0.4137  loss_mask: 0.2939  loss_rpn_cls: 0.01327  loss_rpn_loc: 0.03839    time: 0.7219  last_time: 0.4799  data_time: 0.2449  last_data_time: 0.0044   lr: 0.0002048  max_mem: 9964M\n",
      "\u001b[32m[01/03 20:34:15 d2.utils.events]: \u001b[0m eta: 0:01:37  iter: 839  total_loss: 0.9871  loss_cls: 0.2299  loss_box_reg: 0.4021  loss_mask: 0.2999  loss_rpn_cls: 0.01619  loss_rpn_loc: 0.04489    time: 0.7229  last_time: 0.6032  data_time: 0.2824  last_data_time: 0.1410   lr: 0.00020979  max_mem: 9964M\n",
      "\u001b[32m[01/03 20:34:28 d2.utils.events]: \u001b[0m eta: 0:01:25  iter: 859  total_loss: 0.8886  loss_cls: 0.2178  loss_box_reg: 0.335  loss_mask: 0.2699  loss_rpn_cls: 0.01049  loss_rpn_loc: 0.02907    time: 0.7219  last_time: 0.8499  data_time: 0.1903  last_data_time: 0.3307   lr: 0.00021479  max_mem: 9964M\n",
      "\u001b[32m[01/03 20:34:42 d2.utils.events]: \u001b[0m eta: 0:01:13  iter: 879  total_loss: 0.9216  loss_cls: 0.2193  loss_box_reg: 0.351  loss_mask: 0.3043  loss_rpn_cls: 0.01003  loss_rpn_loc: 0.03111    time: 0.7207  last_time: 0.4981  data_time: 0.1719  last_data_time: 0.0029   lr: 0.00021978  max_mem: 9964M\n",
      "\u001b[32m[01/03 20:34:57 d2.utils.events]: \u001b[0m eta: 0:01:01  iter: 899  total_loss: 1.081  loss_cls: 0.2369  loss_box_reg: 0.397  loss_mask: 0.3235  loss_rpn_cls: 0.01404  loss_rpn_loc: 0.04615    time: 0.7215  last_time: 0.6637  data_time: 0.2789  last_data_time: 0.1940   lr: 0.00022478  max_mem: 9964M\n",
      "\u001b[32m[01/03 20:35:11 d2.utils.events]: \u001b[0m eta: 0:00:48  iter: 919  total_loss: 0.8964  loss_cls: 0.2342  loss_box_reg: 0.3467  loss_mask: 0.2957  loss_rpn_cls: 0.008485  loss_rpn_loc: 0.02668    time: 0.7206  last_time: 0.6472  data_time: 0.1898  last_data_time: 0.1377   lr: 0.00022977  max_mem: 9964M\n",
      "\u001b[32m[01/03 20:35:27 d2.utils.events]: \u001b[0m eta: 0:00:36  iter: 939  total_loss: 0.9633  loss_cls: 0.2241  loss_box_reg: 0.3728  loss_mask: 0.2955  loss_rpn_cls: 0.009885  loss_rpn_loc: 0.04457    time: 0.7227  last_time: 0.5102  data_time: 0.3281  last_data_time: 0.0030   lr: 0.00023477  max_mem: 9964M\n",
      "\u001b[32m[01/03 20:35:40 d2.utils.events]: \u001b[0m eta: 0:00:24  iter: 959  total_loss: 0.8261  loss_cls: 0.1969  loss_box_reg: 0.3004  loss_mask: 0.287  loss_rpn_cls: 0.01147  loss_rpn_loc: 0.03831    time: 0.7211  last_time: 0.4393  data_time: 0.1498  last_data_time: 0.0026   lr: 0.00023976  max_mem: 9964M\n",
      "\u001b[32m[01/03 20:35:55 d2.utils.events]: \u001b[0m eta: 0:00:12  iter: 979  total_loss: 0.9297  loss_cls: 0.2319  loss_box_reg: 0.3833  loss_mask: 0.2779  loss_rpn_cls: 0.01307  loss_rpn_loc: 0.03679    time: 0.7220  last_time: 0.6064  data_time: 0.2882  last_data_time: 0.1010   lr: 0.00024476  max_mem: 9964M\n",
      "\u001b[32m[01/03 20:36:12 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 999  total_loss: 0.9221  loss_cls: 0.218  loss_box_reg: 0.3556  loss_mask: 0.2993  loss_rpn_cls: 0.01053  loss_rpn_loc: 0.04193    time: 0.7232  last_time: 0.8557  data_time: 0.2836  last_data_time: 0.3014   lr: 0.00024975  max_mem: 9964M\n",
      "\u001b[32m[01/03 20:36:12 d2.engine.hooks]: \u001b[0mOverall training speed: 998 iterations in 0:12:01 (0.7233 s / it)\n",
      "\u001b[32m[01/03 20:36:12 d2.engine.hooks]: \u001b[0mTotal training time: 0:12:03 (0:00:01 on hooks)\n",
      "\u001b[32m[01/03 20:36:12 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/03 20:36:12 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[01/03 20:36:12 d2.data.common]: \u001b[0mSerializing 23 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/03 20:36:12 d2.data.common]: \u001b[0mSerialized dataset takes 0.37 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[01/03 20:36:12 d2.engine.defaults]: \u001b[0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.\n",
      "Finished training mask_rcnn_R_101_FPN_3x. Model saved in /home/etaylor/code_projects/thesis/checkpoints/stigmas_segmentation/detectron2/fine_tuned/mask_rcnn_R_101_FPN_3x\n",
      "Training mask_rcnn_X_101_32x8d_FPN_3x...\n",
      "\u001b[32m[01/03 20:36:15 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (6): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (7): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (8): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (9): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (10): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (11): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (12): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (13): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (14): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (15): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (16): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (17): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (18): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (19): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (20): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (21): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (22): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            2048, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=2, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[01/03 20:36:15 d2.data.build]: \u001b[0mRemoved 3 images with no usable annotations. 89 images left.\n",
      "\u001b[32m[01/03 20:36:15 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[01/03 20:36:15 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[01/03 20:36:15 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[01/03 20:36:15 d2.data.common]: \u001b[0mSerializing 89 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/03 20:36:15 d2.data.common]: \u001b[0mSerialized dataset takes 1.27 MiB\n",
      "\u001b[32m[01/03 20:36:15 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from https://dl.fbaipublicfiles.com/detectron2/COCO-InstanceSegmentation/mask_rcnn_X_101_32x8d_FPN_3x/139653917/model_final_2d9806.pkl ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (2, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (2,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (4, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (4,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (1, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (1,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.mask_head.predictor.{bias, weight}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[01/03 20:36:15 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/etaylor/.conda/envs/detectron_fastai/lib/python3.9/site-packages/detectron2/data/detection_utils.py:446: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)\n",
      "  torch.stack([torch.from_numpy(np.ascontiguousarray(x)) for x in masks])\n",
      "/home/etaylor/.conda/envs/detectron_fastai/lib/python3.9/site-packages/detectron2/data/detection_utils.py:446: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)\n",
      "  torch.stack([torch.from_numpy(np.ascontiguousarray(x)) for x in masks])\n",
      "/home/etaylor/.conda/envs/detectron_fastai/lib/python3.9/site-packages/detectron2/data/detection_utils.py:446: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)\n",
      "  torch.stack([torch.from_numpy(np.ascontiguousarray(x)) for x in masks])\n",
      "/home/etaylor/.conda/envs/detectron_fastai/lib/python3.9/site-packages/detectron2/data/detection_utils.py:446: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)\n",
      "  torch.stack([torch.from_numpy(np.ascontiguousarray(x)) for x in masks])\n",
      "/home/etaylor/.conda/envs/detectron_fastai/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[01/03 20:36:43 d2.utils.events]: \u001b[0m eta: 0:22:12  iter: 19  total_loss: 3.098  loss_cls: 0.7635  loss_box_reg: 0.173  loss_mask: 0.6899  loss_rpn_cls: 1.36  loss_rpn_loc: 0.1042    time: 1.3558  last_time: 1.3052  data_time: 0.0920  last_data_time: 0.0042   lr: 4.9953e-06  max_mem: 9964M\n",
      "\u001b[32m[01/03 20:37:10 d2.utils.events]: \u001b[0m eta: 0:21:45  iter: 39  total_loss: 2.167  loss_cls: 0.6211  loss_box_reg: 0.1766  loss_mask: 0.6845  loss_rpn_cls: 0.5902  loss_rpn_loc: 0.05966    time: 1.3477  last_time: 1.4934  data_time: 0.0052  last_data_time: 0.0046   lr: 9.9902e-06  max_mem: 9964M\n",
      "\u001b[32m[01/03 20:37:38 d2.utils.events]: \u001b[0m eta: 0:21:21  iter: 59  total_loss: 1.758  loss_cls: 0.4639  loss_box_reg: 0.3179  loss_mask: 0.6737  loss_rpn_cls: 0.2908  loss_rpn_loc: 0.06431    time: 1.3544  last_time: 1.3812  data_time: 0.0082  last_data_time: 0.0048   lr: 1.4985e-05  max_mem: 9964M\n",
      "\u001b[32m[01/03 20:38:04 d2.utils.events]: \u001b[0m eta: 0:20:52  iter: 79  total_loss: 1.604  loss_cls: 0.3801  loss_box_reg: 0.3091  loss_mask: 0.6546  loss_rpn_cls: 0.2311  loss_rpn_loc: 0.07143    time: 1.3526  last_time: 1.3108  data_time: 0.0097  last_data_time: 0.0065   lr: 1.998e-05  max_mem: 9964M\n",
      "\u001b[32m[01/03 20:38:32 d2.utils.events]: \u001b[0m eta: 0:20:24  iter: 99  total_loss: 1.487  loss_cls: 0.3008  loss_box_reg: 0.2877  loss_mask: 0.6437  loss_rpn_cls: 0.1002  loss_rpn_loc: 0.07131    time: 1.3546  last_time: 1.2053  data_time: 0.0076  last_data_time: 0.0035   lr: 2.4975e-05  max_mem: 9964M\n",
      "\u001b[32m[01/03 20:39:00 d2.utils.events]: \u001b[0m eta: 0:19:57  iter: 119  total_loss: 1.566  loss_cls: 0.33  loss_box_reg: 0.3794  loss_mask: 0.6107  loss_rpn_cls: 0.1152  loss_rpn_loc: 0.05817    time: 1.3607  last_time: 1.4158  data_time: 0.0051  last_data_time: 0.0046   lr: 2.997e-05  max_mem: 9964M\n",
      "\u001b[32m[01/03 20:39:27 d2.utils.events]: \u001b[0m eta: 0:19:31  iter: 139  total_loss: 1.587  loss_cls: 0.3511  loss_box_reg: 0.4948  loss_mask: 0.6032  loss_rpn_cls: 0.1004  loss_rpn_loc: 0.05998    time: 1.3636  last_time: 1.4100  data_time: 0.0049  last_data_time: 0.0036   lr: 3.4965e-05  max_mem: 9964M\n",
      "\u001b[32m[01/03 20:39:55 d2.utils.events]: \u001b[0m eta: 0:19:07  iter: 159  total_loss: 1.527  loss_cls: 0.3268  loss_box_reg: 0.4649  loss_mask: 0.5715  loss_rpn_cls: 0.08709  loss_rpn_loc: 0.05413    time: 1.3652  last_time: 1.4087  data_time: 0.0063  last_data_time: 0.0046   lr: 3.996e-05  max_mem: 9964M\n",
      "\u001b[32m[01/03 20:40:22 d2.utils.events]: \u001b[0m eta: 0:18:38  iter: 179  total_loss: 1.511  loss_cls: 0.3461  loss_box_reg: 0.4816  loss_mask: 0.5355  loss_rpn_cls: 0.07167  loss_rpn_loc: 0.05612    time: 1.3642  last_time: 1.3274  data_time: 0.0048  last_data_time: 0.0046   lr: 4.4955e-05  max_mem: 9964M\n",
      "\u001b[32m[01/03 20:40:50 d2.utils.events]: \u001b[0m eta: 0:18:13  iter: 199  total_loss: 1.453  loss_cls: 0.328  loss_box_reg: 0.5189  loss_mask: 0.5251  loss_rpn_cls: 0.05903  loss_rpn_loc: 0.05569    time: 1.3696  last_time: 1.3899  data_time: 0.0050  last_data_time: 0.0042   lr: 4.995e-05  max_mem: 9964M\n",
      "\u001b[32m[01/03 20:41:18 d2.utils.events]: \u001b[0m eta: 0:17:46  iter: 219  total_loss: 1.578  loss_cls: 0.3726  loss_box_reg: 0.5783  loss_mask: 0.4904  loss_rpn_cls: 0.06095  loss_rpn_loc: 0.05425    time: 1.3705  last_time: 1.5388  data_time: 0.0047  last_data_time: 0.0046   lr: 5.4945e-05  max_mem: 9964M\n",
      "\u001b[32m[01/03 20:41:45 d2.utils.events]: \u001b[0m eta: 0:17:18  iter: 239  total_loss: 1.578  loss_cls: 0.3506  loss_box_reg: 0.577  loss_mask: 0.4716  loss_rpn_cls: 0.06937  loss_rpn_loc: 0.05101    time: 1.3715  last_time: 1.5514  data_time: 0.0049  last_data_time: 0.0050   lr: 5.994e-05  max_mem: 9964M\n",
      "\u001b[32m[01/03 20:42:13 d2.utils.events]: \u001b[0m eta: 0:16:51  iter: 259  total_loss: 1.429  loss_cls: 0.3219  loss_box_reg: 0.5314  loss_mask: 0.4783  loss_rpn_cls: 0.03591  loss_rpn_loc: 0.04983    time: 1.3718  last_time: 1.5616  data_time: 0.0045  last_data_time: 0.0031   lr: 6.4935e-05  max_mem: 9964M\n",
      "\u001b[32m[01/03 20:42:41 d2.utils.events]: \u001b[0m eta: 0:16:24  iter: 279  total_loss: 1.506  loss_cls: 0.3454  loss_box_reg: 0.6145  loss_mask: 0.4487  loss_rpn_cls: 0.04863  loss_rpn_loc: 0.05578    time: 1.3729  last_time: 1.5458  data_time: 0.0078  last_data_time: 0.0040   lr: 6.993e-05  max_mem: 9964M\n",
      "\u001b[32m[01/03 20:43:09 d2.utils.events]: \u001b[0m eta: 0:15:59  iter: 299  total_loss: 1.584  loss_cls: 0.3589  loss_box_reg: 0.6882  loss_mask: 0.4478  loss_rpn_cls: 0.04096  loss_rpn_loc: 0.05036    time: 1.3769  last_time: 1.3309  data_time: 0.0092  last_data_time: 0.0052   lr: 7.4925e-05  max_mem: 9964M\n",
      "\u001b[32m[01/03 20:43:36 d2.utils.events]: \u001b[0m eta: 0:15:32  iter: 319  total_loss: 1.476  loss_cls: 0.3439  loss_box_reg: 0.6395  loss_mask: 0.4175  loss_rpn_cls: 0.05313  loss_rpn_loc: 0.05524    time: 1.3738  last_time: 1.1628  data_time: 0.0046  last_data_time: 0.0056   lr: 7.992e-05  max_mem: 9964M\n",
      "\u001b[32m[01/03 20:44:03 d2.utils.events]: \u001b[0m eta: 0:15:05  iter: 339  total_loss: 1.54  loss_cls: 0.3419  loss_box_reg: 0.6434  loss_mask: 0.4144  loss_rpn_cls: 0.02954  loss_rpn_loc: 0.04638    time: 1.3722  last_time: 1.0942  data_time: 0.0064  last_data_time: 0.0065   lr: 8.4915e-05  max_mem: 9964M\n",
      "\u001b[32m[01/03 20:44:31 d2.utils.events]: \u001b[0m eta: 0:14:38  iter: 359  total_loss: 1.496  loss_cls: 0.3344  loss_box_reg: 0.6239  loss_mask: 0.3996  loss_rpn_cls: 0.04148  loss_rpn_loc: 0.05245    time: 1.3735  last_time: 1.5449  data_time: 0.0050  last_data_time: 0.0051   lr: 8.991e-05  max_mem: 9964M\n",
      "\u001b[32m[01/03 20:44:59 d2.utils.events]: \u001b[0m eta: 0:14:11  iter: 379  total_loss: 1.439  loss_cls: 0.3178  loss_box_reg: 0.6499  loss_mask: 0.3971  loss_rpn_cls: 0.02724  loss_rpn_loc: 0.05214    time: 1.3739  last_time: 1.4535  data_time: 0.0057  last_data_time: 0.0049   lr: 9.4905e-05  max_mem: 9964M\n",
      "\u001b[32m[01/03 20:45:27 d2.utils.events]: \u001b[0m eta: 0:13:44  iter: 399  total_loss: 1.37  loss_cls: 0.3096  loss_box_reg: 0.5927  loss_mask: 0.3799  loss_rpn_cls: 0.02392  loss_rpn_loc: 0.04633    time: 1.3764  last_time: 1.2783  data_time: 0.0049  last_data_time: 0.0051   lr: 9.99e-05  max_mem: 9964M\n",
      "\u001b[32m[01/03 20:45:56 d2.utils.events]: \u001b[0m eta: 0:13:18  iter: 419  total_loss: 1.319  loss_cls: 0.3064  loss_box_reg: 0.5979  loss_mask: 0.3602  loss_rpn_cls: 0.02389  loss_rpn_loc: 0.05469    time: 1.3786  last_time: 1.4505  data_time: 0.0088  last_data_time: 0.0052   lr: 0.0001049  max_mem: 9964M\n",
      "\u001b[32m[01/03 20:46:24 d2.utils.events]: \u001b[0m eta: 0:12:52  iter: 439  total_loss: 1.444  loss_cls: 0.3254  loss_box_reg: 0.6982  loss_mask: 0.3707  loss_rpn_cls: 0.0232  loss_rpn_loc: 0.04558    time: 1.3803  last_time: 1.4018  data_time: 0.0050  last_data_time: 0.0050   lr: 0.00010989  max_mem: 9964M\n",
      "\u001b[32m[01/03 20:46:51 d2.utils.events]: \u001b[0m eta: 0:12:23  iter: 459  total_loss: 1.252  loss_cls: 0.2997  loss_box_reg: 0.5484  loss_mask: 0.3404  loss_rpn_cls: 0.02649  loss_rpn_loc: 0.03979    time: 1.3785  last_time: 1.4173  data_time: 0.0063  last_data_time: 0.0051   lr: 0.00011489  max_mem: 9964M\n",
      "\u001b[32m[01/03 20:47:19 d2.utils.events]: \u001b[0m eta: 0:11:55  iter: 479  total_loss: 1.242  loss_cls: 0.2844  loss_box_reg: 0.5406  loss_mask: 0.3498  loss_rpn_cls: 0.02613  loss_rpn_loc: 0.04994    time: 1.3791  last_time: 1.5310  data_time: 0.0108  last_data_time: 0.0051   lr: 0.00011988  max_mem: 9964M\n",
      "\u001b[32m[01/03 20:47:46 d2.utils.events]: \u001b[0m eta: 0:11:27  iter: 499  total_loss: 1.171  loss_cls: 0.2705  loss_box_reg: 0.4941  loss_mask: 0.3421  loss_rpn_cls: 0.02548  loss_rpn_loc: 0.04215    time: 1.3781  last_time: 1.3402  data_time: 0.0046  last_data_time: 0.0044   lr: 0.00012488  max_mem: 9964M\n",
      "\u001b[32m[01/03 20:48:14 d2.utils.events]: \u001b[0m eta: 0:10:59  iter: 519  total_loss: 1.131  loss_cls: 0.2701  loss_box_reg: 0.5328  loss_mask: 0.3176  loss_rpn_cls: 0.01584  loss_rpn_loc: 0.05138    time: 1.3781  last_time: 1.0873  data_time: 0.0050  last_data_time: 0.0068   lr: 0.00012987  max_mem: 9964M\n",
      "\u001b[32m[01/03 20:48:42 d2.utils.events]: \u001b[0m eta: 0:10:32  iter: 539  total_loss: 1.167  loss_cls: 0.2884  loss_box_reg: 0.4851  loss_mask: 0.3478  loss_rpn_cls: 0.02025  loss_rpn_loc: 0.05052    time: 1.3787  last_time: 1.5473  data_time: 0.0073  last_data_time: 0.0042   lr: 0.00013487  max_mem: 9964M\n",
      "\u001b[32m[01/03 20:49:10 d2.utils.events]: \u001b[0m eta: 0:10:06  iter: 559  total_loss: 1.179  loss_cls: 0.2895  loss_box_reg: 0.4919  loss_mask: 0.3241  loss_rpn_cls: 0.0212  loss_rpn_loc: 0.04797    time: 1.3807  last_time: 1.3936  data_time: 0.0055  last_data_time: 0.0077   lr: 0.00013986  max_mem: 9964M\n",
      "\u001b[32m[01/03 20:49:37 d2.utils.events]: \u001b[0m eta: 0:09:39  iter: 579  total_loss: 1.157  loss_cls: 0.2779  loss_box_reg: 0.5082  loss_mask: 0.3234  loss_rpn_cls: 0.01062  loss_rpn_loc: 0.04566    time: 1.3800  last_time: 1.3612  data_time: 0.0082  last_data_time: 0.0048   lr: 0.00014486  max_mem: 9964M\n",
      "\u001b[32m[01/03 20:50:06 d2.utils.events]: \u001b[0m eta: 0:09:12  iter: 599  total_loss: 1.106  loss_cls: 0.2596  loss_box_reg: 0.4846  loss_mask: 0.3088  loss_rpn_cls: 0.01411  loss_rpn_loc: 0.04529    time: 1.3819  last_time: 1.5643  data_time: 0.0046  last_data_time: 0.0042   lr: 0.00014985  max_mem: 9964M\n",
      "\u001b[32m[01/03 20:50:34 d2.utils.events]: \u001b[0m eta: 0:08:45  iter: 619  total_loss: 0.9613  loss_cls: 0.2323  loss_box_reg: 0.3783  loss_mask: 0.3154  loss_rpn_cls: 0.01662  loss_rpn_loc: 0.0351    time: 1.3826  last_time: 1.5725  data_time: 0.0062  last_data_time: 0.0042   lr: 0.00015485  max_mem: 9964M\n",
      "\u001b[32m[01/03 20:51:01 d2.utils.events]: \u001b[0m eta: 0:08:17  iter: 639  total_loss: 1.071  loss_cls: 0.2606  loss_box_reg: 0.4304  loss_mask: 0.2959  loss_rpn_cls: 0.02117  loss_rpn_loc: 0.04171    time: 1.3809  last_time: 1.2756  data_time: 0.0190  last_data_time: 0.0039   lr: 0.00015984  max_mem: 9964M\n",
      "\u001b[32m[01/03 20:51:29 d2.utils.events]: \u001b[0m eta: 0:07:50  iter: 659  total_loss: 1.087  loss_cls: 0.2737  loss_box_reg: 0.4316  loss_mask: 0.3155  loss_rpn_cls: 0.01795  loss_rpn_loc: 0.03767    time: 1.3816  last_time: 1.3878  data_time: 0.0051  last_data_time: 0.0081   lr: 0.00016484  max_mem: 9964M\n",
      "\u001b[32m[01/03 20:51:57 d2.utils.events]: \u001b[0m eta: 0:07:22  iter: 679  total_loss: 1.017  loss_cls: 0.2536  loss_box_reg: 0.441  loss_mask: 0.2853  loss_rpn_cls: 0.01123  loss_rpn_loc: 0.03024    time: 1.3824  last_time: 1.2661  data_time: 0.0049  last_data_time: 0.0056   lr: 0.00016983  max_mem: 9964M\n",
      "\u001b[32m[01/03 20:52:26 d2.utils.events]: \u001b[0m eta: 0:06:55  iter: 699  total_loss: 0.9906  loss_cls: 0.2381  loss_box_reg: 0.3847  loss_mask: 0.3099  loss_rpn_cls: 0.01147  loss_rpn_loc: 0.03768    time: 1.3847  last_time: 1.5292  data_time: 0.0047  last_data_time: 0.0044   lr: 0.00017483  max_mem: 9964M\n",
      "\u001b[32m[01/03 20:52:55 d2.utils.events]: \u001b[0m eta: 0:06:27  iter: 719  total_loss: 0.953  loss_cls: 0.2232  loss_box_reg: 0.3598  loss_mask: 0.2927  loss_rpn_cls: 0.01506  loss_rpn_loc: 0.04121    time: 1.3853  last_time: 1.3432  data_time: 0.0047  last_data_time: 0.0047   lr: 0.00017982  max_mem: 9964M\n",
      "\u001b[32m[01/03 20:53:21 d2.utils.events]: \u001b[0m eta: 0:06:00  iter: 739  total_loss: 0.9354  loss_cls: 0.2274  loss_box_reg: 0.3616  loss_mask: 0.2756  loss_rpn_cls: 0.0123  loss_rpn_loc: 0.03432    time: 1.3843  last_time: 1.4088  data_time: 0.0047  last_data_time: 0.0052   lr: 0.00018482  max_mem: 9964M\n",
      "\u001b[32m[01/03 20:53:50 d2.utils.events]: \u001b[0m eta: 0:05:32  iter: 759  total_loss: 1.05  loss_cls: 0.2514  loss_box_reg: 0.4315  loss_mask: 0.31  loss_rpn_cls: 0.01023  loss_rpn_loc: 0.04175    time: 1.3848  last_time: 1.3582  data_time: 0.0145  last_data_time: 0.0062   lr: 0.00018981  max_mem: 9964M\n",
      "\u001b[32m[01/03 20:54:17 d2.utils.events]: \u001b[0m eta: 0:05:04  iter: 779  total_loss: 0.9206  loss_cls: 0.1982  loss_box_reg: 0.3842  loss_mask: 0.3024  loss_rpn_cls: 0.008837  loss_rpn_loc: 0.0373    time: 1.3846  last_time: 1.5571  data_time: 0.0047  last_data_time: 0.0046   lr: 0.00019481  max_mem: 9964M\n",
      "\u001b[32m[01/03 20:54:44 d2.utils.events]: \u001b[0m eta: 0:04:37  iter: 799  total_loss: 1.013  loss_cls: 0.2362  loss_box_reg: 0.4262  loss_mask: 0.2904  loss_rpn_cls: 0.01292  loss_rpn_loc: 0.03933    time: 1.3838  last_time: 1.1287  data_time: 0.0075  last_data_time: 0.0043   lr: 0.0001998  max_mem: 9964M\n",
      "\u001b[32m[01/03 20:55:11 d2.utils.events]: \u001b[0m eta: 0:04:09  iter: 819  total_loss: 0.9485  loss_cls: 0.2174  loss_box_reg: 0.3648  loss_mask: 0.2904  loss_rpn_cls: 0.008266  loss_rpn_loc: 0.03172    time: 1.3826  last_time: 1.3543  data_time: 0.0075  last_data_time: 0.0029   lr: 0.0002048  max_mem: 9964M\n",
      "\u001b[32m[01/03 20:55:39 d2.utils.events]: \u001b[0m eta: 0:03:41  iter: 839  total_loss: 0.831  loss_cls: 0.1814  loss_box_reg: 0.3258  loss_mask: 0.2985  loss_rpn_cls: 0.006538  loss_rpn_loc: 0.02991    time: 1.3834  last_time: 1.3816  data_time: 0.0048  last_data_time: 0.0039   lr: 0.00020979  max_mem: 9964M\n",
      "\u001b[32m[01/03 20:56:07 d2.utils.events]: \u001b[0m eta: 0:03:13  iter: 859  total_loss: 0.8698  loss_cls: 0.202  loss_box_reg: 0.35  loss_mask: 0.2871  loss_rpn_cls: 0.005449  loss_rpn_loc: 0.03546    time: 1.3838  last_time: 1.5600  data_time: 0.0049  last_data_time: 0.0041   lr: 0.00021479  max_mem: 9964M\n",
      "\u001b[32m[01/03 20:56:35 d2.utils.events]: \u001b[0m eta: 0:02:46  iter: 879  total_loss: 0.7759  loss_cls: 0.1755  loss_box_reg: 0.3074  loss_mask: 0.2663  loss_rpn_cls: 0.005565  loss_rpn_loc: 0.03466    time: 1.3837  last_time: 1.3445  data_time: 0.0049  last_data_time: 0.0046   lr: 0.00021978  max_mem: 9964M\n",
      "\u001b[32m[01/03 20:57:03 d2.utils.events]: \u001b[0m eta: 0:02:18  iter: 899  total_loss: 0.9186  loss_cls: 0.18  loss_box_reg: 0.3686  loss_mask: 0.2993  loss_rpn_cls: 0.005644  loss_rpn_loc: 0.04014    time: 1.3842  last_time: 1.5402  data_time: 0.0050  last_data_time: 0.0049   lr: 0.00022478  max_mem: 9964M\n",
      "\u001b[32m[01/03 20:57:31 d2.utils.events]: \u001b[0m eta: 0:01:50  iter: 919  total_loss: 0.846  loss_cls: 0.1918  loss_box_reg: 0.3235  loss_mask: 0.27  loss_rpn_cls: 0.006877  loss_rpn_loc: 0.03476    time: 1.3844  last_time: 1.3228  data_time: 0.0051  last_data_time: 0.0053   lr: 0.00022977  max_mem: 9964M\n",
      "\u001b[32m[01/03 20:57:58 d2.utils.events]: \u001b[0m eta: 0:01:23  iter: 939  total_loss: 0.8271  loss_cls: 0.1801  loss_box_reg: 0.3263  loss_mask: 0.2903  loss_rpn_cls: 0.004987  loss_rpn_loc: 0.03181    time: 1.3838  last_time: 1.1439  data_time: 0.0048  last_data_time: 0.0045   lr: 0.00023477  max_mem: 9964M\n",
      "\u001b[32m[01/03 20:58:26 d2.utils.events]: \u001b[0m eta: 0:00:55  iter: 959  total_loss: 0.7748  loss_cls: 0.1669  loss_box_reg: 0.311  loss_mask: 0.2769  loss_rpn_cls: 0.002717  loss_rpn_loc: 0.02957    time: 1.3837  last_time: 1.3936  data_time: 0.0052  last_data_time: 0.0051   lr: 0.00023976  max_mem: 9964M\n",
      "\u001b[32m[01/03 20:58:55 d2.utils.events]: \u001b[0m eta: 0:00:27  iter: 979  total_loss: 0.8478  loss_cls: 0.1631  loss_box_reg: 0.3378  loss_mask: 0.273  loss_rpn_cls: 0.005062  loss_rpn_loc: 0.04103    time: 1.3853  last_time: 1.5390  data_time: 0.0052  last_data_time: 0.0042   lr: 0.00024476  max_mem: 9964M\n",
      "\u001b[32m[01/03 20:59:24 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 999  total_loss: 0.781  loss_cls: 0.155  loss_box_reg: 0.3076  loss_mask: 0.2712  loss_rpn_cls: 0.002809  loss_rpn_loc: 0.03053    time: 1.3851  last_time: 1.1493  data_time: 0.0047  last_data_time: 0.0036   lr: 0.00024975  max_mem: 9964M\n",
      "\u001b[32m[01/03 20:59:24 d2.engine.hooks]: \u001b[0mOverall training speed: 998 iterations in 0:23:02 (1.3852 s / it)\n",
      "\u001b[32m[01/03 20:59:24 d2.engine.hooks]: \u001b[0mTotal training time: 0:23:05 (0:00:02 on hooks)\n",
      "\u001b[32m[01/03 20:59:24 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/03 20:59:24 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[01/03 20:59:24 d2.data.common]: \u001b[0mSerializing 23 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/03 20:59:24 d2.data.common]: \u001b[0mSerialized dataset takes 0.37 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[01/03 20:59:24 d2.engine.defaults]: \u001b[0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.\n",
      "Finished training mask_rcnn_X_101_32x8d_FPN_3x. Model saved in /home/etaylor/code_projects/thesis/checkpoints/stigmas_segmentation/detectron2/fine_tuned/mask_rcnn_X_101_32x8d_FPN_3x\n",
      "Training mask_rcnn_R_50_C4_3x...\n",
      "\u001b[32m[01/03 20:59:27 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): ResNet(\n",
      "    (stem): BasicStem(\n",
      "      (conv1): Conv2d(\n",
      "        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "      )\n",
      "    )\n",
      "    (res2): Sequential(\n",
      "      (0): BottleneckBlock(\n",
      "        (shortcut): Conv2d(\n",
      "          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv1): Conv2d(\n",
      "          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (1): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (2): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (res3): Sequential(\n",
      "      (0): BottleneckBlock(\n",
      "        (shortcut): Conv2d(\n",
      "          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "        (conv1): Conv2d(\n",
      "          256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (1): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (2): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (3): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (res4): Sequential(\n",
      "      (0): BottleneckBlock(\n",
      "        (shortcut): Conv2d(\n",
      "          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "        (conv1): Conv2d(\n",
      "          512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (1): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (2): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (3): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (4): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (5): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(1024, 15, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(1024, 60, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): Res5ROIHeads(\n",
      "    (pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (res5): Sequential(\n",
      "      (0): BottleneckBlock(\n",
      "        (shortcut): Conv2d(\n",
      "          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "        )\n",
      "        (conv1): Conv2d(\n",
      "          1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (1): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (2): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=2048, out_features=2, bias=True)\n",
      "      (bbox_pred): Linear(in_features=2048, out_features=4, bias=True)\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (deconv): ConvTranspose2d(2048, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[01/03 20:59:27 d2.data.build]: \u001b[0mRemoved 3 images with no usable annotations. 89 images left.\n",
      "\u001b[32m[01/03 20:59:27 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[01/03 20:59:27 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[01/03 20:59:27 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[01/03 20:59:27 d2.data.common]: \u001b[0mSerializing 89 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/03 20:59:27 d2.data.common]: \u001b[0mSerialized dataset takes 1.27 MiB\n",
      "\u001b[32m[01/03 20:59:27 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from https://dl.fbaipublicfiles.com/detectron2/COCO-InstanceSegmentation/mask_rcnn_R_50_C4_3x/137849525/model_final_4ce675.pkl ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 2048) in the checkpoint but (2, 2048) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (2,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 2048) in the checkpoint but (4, 2048) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (4,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (1, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (1,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.mask_head.predictor.{bias, weight}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[01/03 20:59:27 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/etaylor/.conda/envs/detectron_fastai/lib/python3.9/site-packages/detectron2/data/detection_utils.py:446: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)\n",
      "  torch.stack([torch.from_numpy(np.ascontiguousarray(x)) for x in masks])\n",
      "/home/etaylor/.conda/envs/detectron_fastai/lib/python3.9/site-packages/detectron2/data/detection_utils.py:446: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)\n",
      "  torch.stack([torch.from_numpy(np.ascontiguousarray(x)) for x in masks])\n",
      "/home/etaylor/.conda/envs/detectron_fastai/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
      "/home/etaylor/.conda/envs/detectron_fastai/lib/python3.9/site-packages/detectron2/data/detection_utils.py:446: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)\n",
      "  torch.stack([torch.from_numpy(np.ascontiguousarray(x)) for x in masks])\n",
      "/home/etaylor/.conda/envs/detectron_fastai/lib/python3.9/site-packages/detectron2/data/detection_utils.py:446: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)\n",
      "  torch.stack([torch.from_numpy(np.ascontiguousarray(x)) for x in masks])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[01/03 20:59:48 d2.utils.events]: \u001b[0m eta: 0:14:58  iter: 19  total_loss: 2.528  loss_cls: 0.731  loss_box_reg: 0.4247  loss_mask: 0.6913  loss_rpn_cls: 0.6863  loss_rpn_loc: 0.09599    time: 0.9382  last_time: 0.9118  data_time: 0.1506  last_data_time: 0.0045   lr: 4.9953e-06  max_mem: 9964M\n",
      "\u001b[32m[01/03 21:00:07 d2.utils.events]: \u001b[0m eta: 0:14:44  iter: 39  total_loss: 2.482  loss_cls: 0.6229  loss_box_reg: 0.3478  loss_mask: 0.6845  loss_rpn_cls: 0.7469  loss_rpn_loc: 0.09691    time: 0.9429  last_time: 0.9296  data_time: 0.0365  last_data_time: 0.0040   lr: 9.9902e-06  max_mem: 9964M\n",
      "\u001b[32m[01/03 21:00:26 d2.utils.events]: \u001b[0m eta: 0:14:30  iter: 59  total_loss: 2.254  loss_cls: 0.4737  loss_box_reg: 0.3626  loss_mask: 0.6722  loss_rpn_cls: 0.5972  loss_rpn_loc: 0.09126    time: 0.9473  last_time: 0.8912  data_time: 0.0382  last_data_time: 0.0048   lr: 1.4985e-05  max_mem: 9964M\n",
      "\u001b[32m[01/03 21:00:46 d2.utils.events]: \u001b[0m eta: 0:14:19  iter: 79  total_loss: 2.222  loss_cls: 0.435  loss_box_reg: 0.5188  loss_mask: 0.6525  loss_rpn_cls: 0.463  loss_rpn_loc: 0.1083    time: 0.9568  last_time: 0.9446  data_time: 0.0684  last_data_time: 0.0039   lr: 1.998e-05  max_mem: 9964M\n",
      "\u001b[32m[01/03 21:01:05 d2.utils.events]: \u001b[0m eta: 0:14:02  iter: 99  total_loss: 2.123  loss_cls: 0.4307  loss_box_reg: 0.5645  loss_mask: 0.6271  loss_rpn_cls: 0.3718  loss_rpn_loc: 0.1263    time: 0.9554  last_time: 0.8999  data_time: 0.0243  last_data_time: 0.0036   lr: 2.4975e-05  max_mem: 9964M\n",
      "\u001b[32m[01/03 21:01:24 d2.utils.events]: \u001b[0m eta: 0:13:45  iter: 119  total_loss: 2.123  loss_cls: 0.4566  loss_box_reg: 0.6637  loss_mask: 0.598  loss_rpn_cls: 0.2842  loss_rpn_loc: 0.1006    time: 0.9559  last_time: 0.9616  data_time: 0.0326  last_data_time: 0.0071   lr: 2.997e-05  max_mem: 9964M\n",
      "\u001b[32m[01/03 21:01:43 d2.utils.events]: \u001b[0m eta: 0:13:27  iter: 139  total_loss: 1.749  loss_cls: 0.3773  loss_box_reg: 0.552  loss_mask: 0.5809  loss_rpn_cls: 0.2313  loss_rpn_loc: 0.09635    time: 0.9568  last_time: 1.0593  data_time: 0.0334  last_data_time: 0.1687   lr: 3.4965e-05  max_mem: 9964M\n",
      "\u001b[32m[01/03 21:02:02 d2.utils.events]: \u001b[0m eta: 0:13:06  iter: 159  total_loss: 1.747  loss_cls: 0.3681  loss_box_reg: 0.5447  loss_mask: 0.547  loss_rpn_cls: 0.1859  loss_rpn_loc: 0.09308    time: 0.9537  last_time: 0.8907  data_time: 0.0169  last_data_time: 0.0047   lr: 3.996e-05  max_mem: 9964M\n",
      "\u001b[32m[01/03 21:02:21 d2.utils.events]: \u001b[0m eta: 0:12:47  iter: 179  total_loss: 1.812  loss_cls: 0.3768  loss_box_reg: 0.6768  loss_mask: 0.5216  loss_rpn_cls: 0.1724  loss_rpn_loc: 0.08461    time: 0.9533  last_time: 0.9460  data_time: 0.0296  last_data_time: 0.0051   lr: 4.4955e-05  max_mem: 9964M\n",
      "\u001b[32m[01/03 21:02:41 d2.utils.events]: \u001b[0m eta: 0:12:30  iter: 199  total_loss: 2.043  loss_cls: 0.3946  loss_box_reg: 0.7588  loss_mask: 0.5015  loss_rpn_cls: 0.1902  loss_rpn_loc: 0.1284    time: 0.9579  last_time: 1.1181  data_time: 0.0745  last_data_time: 0.2443   lr: 4.995e-05  max_mem: 9964M\n",
      "\u001b[32m[01/03 21:03:00 d2.utils.events]: \u001b[0m eta: 0:12:11  iter: 219  total_loss: 1.686  loss_cls: 0.3263  loss_box_reg: 0.6195  loss_mask: 0.4435  loss_rpn_cls: 0.1462  loss_rpn_loc: 0.07511    time: 0.9551  last_time: 0.9053  data_time: 0.0119  last_data_time: 0.0049   lr: 5.4945e-05  max_mem: 9964M\n",
      "\u001b[32m[01/03 21:03:19 d2.utils.events]: \u001b[0m eta: 0:11:51  iter: 239  total_loss: 1.644  loss_cls: 0.3408  loss_box_reg: 0.6726  loss_mask: 0.4233  loss_rpn_cls: 0.1239  loss_rpn_loc: 0.08414    time: 0.9548  last_time: 0.9805  data_time: 0.0406  last_data_time: 0.0335   lr: 5.994e-05  max_mem: 9964M\n",
      "\u001b[32m[01/03 21:03:37 d2.utils.events]: \u001b[0m eta: 0:11:32  iter: 259  total_loss: 1.628  loss_cls: 0.2979  loss_box_reg: 0.6499  loss_mask: 0.457  loss_rpn_cls: 0.1371  loss_rpn_loc: 0.09404    time: 0.9536  last_time: 0.9682  data_time: 0.0237  last_data_time: 0.0025   lr: 6.4935e-05  max_mem: 9964M\n",
      "\u001b[32m[01/03 21:03:56 d2.utils.events]: \u001b[0m eta: 0:11:13  iter: 279  total_loss: 1.74  loss_cls: 0.3243  loss_box_reg: 0.7157  loss_mask: 0.4114  loss_rpn_cls: 0.1647  loss_rpn_loc: 0.1227    time: 0.9536  last_time: 1.0011  data_time: 0.0319  last_data_time: 0.0633   lr: 6.993e-05  max_mem: 9964M\n",
      "\u001b[32m[01/03 21:04:16 d2.utils.events]: \u001b[0m eta: 0:10:55  iter: 299  total_loss: 1.565  loss_cls: 0.2992  loss_box_reg: 0.6296  loss_mask: 0.4077  loss_rpn_cls: 0.1302  loss_rpn_loc: 0.07658    time: 0.9536  last_time: 0.8812  data_time: 0.0356  last_data_time: 0.0047   lr: 7.4925e-05  max_mem: 9964M\n",
      "\u001b[32m[01/03 21:04:35 d2.utils.events]: \u001b[0m eta: 0:10:36  iter: 319  total_loss: 1.467  loss_cls: 0.2623  loss_box_reg: 0.651  loss_mask: 0.3902  loss_rpn_cls: 0.1134  loss_rpn_loc: 0.08073    time: 0.9534  last_time: 0.9256  data_time: 0.0401  last_data_time: 0.0047   lr: 7.992e-05  max_mem: 9964M\n",
      "\u001b[32m[01/03 21:04:54 d2.utils.events]: \u001b[0m eta: 0:10:17  iter: 339  total_loss: 1.64  loss_cls: 0.3021  loss_box_reg: 0.7309  loss_mask: 0.3933  loss_rpn_cls: 0.1296  loss_rpn_loc: 0.1118    time: 0.9542  last_time: 0.9281  data_time: 0.0517  last_data_time: 0.0044   lr: 8.4915e-05  max_mem: 9964M\n",
      "\u001b[32m[01/03 21:05:13 d2.utils.events]: \u001b[0m eta: 0:09:59  iter: 359  total_loss: 1.359  loss_cls: 0.2564  loss_box_reg: 0.6233  loss_mask: 0.3652  loss_rpn_cls: 0.09987  loss_rpn_loc: 0.07404    time: 0.9532  last_time: 0.9072  data_time: 0.0189  last_data_time: 0.0044   lr: 8.991e-05  max_mem: 9964M\n",
      "\u001b[32m[01/03 21:05:32 d2.utils.events]: \u001b[0m eta: 0:09:40  iter: 379  total_loss: 1.43  loss_cls: 0.2455  loss_box_reg: 0.6041  loss_mask: 0.352  loss_rpn_cls: 0.1356  loss_rpn_loc: 0.08929    time: 0.9533  last_time: 0.9163  data_time: 0.0397  last_data_time: 0.0043   lr: 9.4905e-05  max_mem: 9964M\n",
      "\u001b[32m[01/03 21:05:51 d2.utils.events]: \u001b[0m eta: 0:09:21  iter: 399  total_loss: 1.532  loss_cls: 0.276  loss_box_reg: 0.6914  loss_mask: 0.3526  loss_rpn_cls: 0.1007  loss_rpn_loc: 0.09048    time: 0.9533  last_time: 0.9201  data_time: 0.0298  last_data_time: 0.0037   lr: 9.99e-05  max_mem: 9964M\n",
      "\u001b[32m[01/03 21:06:10 d2.utils.events]: \u001b[0m eta: 0:09:03  iter: 419  total_loss: 1.475  loss_cls: 0.253  loss_box_reg: 0.5842  loss_mask: 0.3269  loss_rpn_cls: 0.1251  loss_rpn_loc: 0.09766    time: 0.9533  last_time: 0.8810  data_time: 0.0363  last_data_time: 0.0047   lr: 0.0001049  max_mem: 9964M\n",
      "\u001b[32m[01/03 21:06:29 d2.utils.events]: \u001b[0m eta: 0:08:44  iter: 439  total_loss: 1.43  loss_cls: 0.2459  loss_box_reg: 0.5898  loss_mask: 0.3539  loss_rpn_cls: 0.1017  loss_rpn_loc: 0.07151    time: 0.9535  last_time: 0.9159  data_time: 0.0357  last_data_time: 0.0039   lr: 0.00010989  max_mem: 9964M\n",
      "\u001b[32m[01/03 21:06:48 d2.utils.events]: \u001b[0m eta: 0:08:25  iter: 459  total_loss: 1.331  loss_cls: 0.2254  loss_box_reg: 0.5421  loss_mask: 0.3415  loss_rpn_cls: 0.1062  loss_rpn_loc: 0.07714    time: 0.9526  last_time: 0.9413  data_time: 0.0131  last_data_time: 0.0034   lr: 0.00011489  max_mem: 9964M\n",
      "\u001b[32m[01/03 21:07:08 d2.utils.events]: \u001b[0m eta: 0:08:06  iter: 479  total_loss: 1.352  loss_cls: 0.2628  loss_box_reg: 0.5558  loss_mask: 0.3294  loss_rpn_cls: 0.1123  loss_rpn_loc: 0.08881    time: 0.9540  last_time: 0.8823  data_time: 0.0571  last_data_time: 0.0066   lr: 0.00011988  max_mem: 9964M\n",
      "\u001b[32m[01/03 21:07:27 d2.utils.events]: \u001b[0m eta: 0:07:48  iter: 499  total_loss: 1.461  loss_cls: 0.2646  loss_box_reg: 0.5866  loss_mask: 0.3252  loss_rpn_cls: 0.1047  loss_rpn_loc: 0.1061    time: 0.9548  last_time: 1.0664  data_time: 0.0408  last_data_time: 0.1203   lr: 0.00012488  max_mem: 9964M\n",
      "\u001b[32m[01/03 21:07:46 d2.utils.events]: \u001b[0m eta: 0:07:29  iter: 519  total_loss: 1.194  loss_cls: 0.2174  loss_box_reg: 0.4932  loss_mask: 0.3054  loss_rpn_cls: 0.07849  loss_rpn_loc: 0.0679    time: 0.9538  last_time: 1.0110  data_time: 0.0166  last_data_time: 0.0663   lr: 0.00012987  max_mem: 9964M\n",
      "\u001b[32m[01/03 21:08:05 d2.utils.events]: \u001b[0m eta: 0:07:10  iter: 539  total_loss: 1.306  loss_cls: 0.2704  loss_box_reg: 0.5323  loss_mask: 0.3311  loss_rpn_cls: 0.1056  loss_rpn_loc: 0.07674    time: 0.9536  last_time: 0.9315  data_time: 0.0301  last_data_time: 0.0052   lr: 0.00013487  max_mem: 9964M\n",
      "\u001b[32m[01/03 21:08:23 d2.utils.events]: \u001b[0m eta: 0:06:51  iter: 559  total_loss: 1.2  loss_cls: 0.2164  loss_box_reg: 0.4677  loss_mask: 0.2907  loss_rpn_cls: 0.07652  loss_rpn_loc: 0.06444    time: 0.9530  last_time: 0.8972  data_time: 0.0281  last_data_time: 0.0057   lr: 0.00013986  max_mem: 9964M\n",
      "\u001b[32m[01/03 21:08:43 d2.utils.events]: \u001b[0m eta: 0:06:33  iter: 579  total_loss: 1.267  loss_cls: 0.2392  loss_box_reg: 0.5186  loss_mask: 0.3188  loss_rpn_cls: 0.09035  loss_rpn_loc: 0.07472    time: 0.9538  last_time: 0.9079  data_time: 0.0585  last_data_time: 0.0053   lr: 0.00014486  max_mem: 9964M\n",
      "\u001b[32m[01/03 21:09:02 d2.utils.events]: \u001b[0m eta: 0:06:14  iter: 599  total_loss: 1.186  loss_cls: 0.2313  loss_box_reg: 0.4864  loss_mask: 0.3161  loss_rpn_cls: 0.08938  loss_rpn_loc: 0.08824    time: 0.9543  last_time: 0.9265  data_time: 0.0437  last_data_time: 0.0042   lr: 0.00014985  max_mem: 9964M\n",
      "\u001b[32m[01/03 21:09:21 d2.utils.events]: \u001b[0m eta: 0:05:55  iter: 619  total_loss: 1.262  loss_cls: 0.2443  loss_box_reg: 0.5196  loss_mask: 0.3083  loss_rpn_cls: 0.08299  loss_rpn_loc: 0.09512    time: 0.9540  last_time: 0.9017  data_time: 0.0276  last_data_time: 0.0038   lr: 0.00015485  max_mem: 9964M\n",
      "\u001b[32m[01/03 21:09:40 d2.utils.events]: \u001b[0m eta: 0:05:37  iter: 639  total_loss: 1.203  loss_cls: 0.2474  loss_box_reg: 0.4563  loss_mask: 0.2896  loss_rpn_cls: 0.07945  loss_rpn_loc: 0.08052    time: 0.9541  last_time: 0.9038  data_time: 0.0324  last_data_time: 0.0042   lr: 0.00015984  max_mem: 9964M\n",
      "\u001b[32m[01/03 21:09:59 d2.utils.events]: \u001b[0m eta: 0:05:18  iter: 659  total_loss: 1.053  loss_cls: 0.2217  loss_box_reg: 0.3997  loss_mask: 0.2829  loss_rpn_cls: 0.06476  loss_rpn_loc: 0.06483    time: 0.9538  last_time: 1.0565  data_time: 0.0283  last_data_time: 0.1370   lr: 0.00016484  max_mem: 9964M\n",
      "\u001b[32m[01/03 21:10:18 d2.utils.events]: \u001b[0m eta: 0:04:59  iter: 679  total_loss: 1.206  loss_cls: 0.2558  loss_box_reg: 0.4526  loss_mask: 0.3195  loss_rpn_cls: 0.08265  loss_rpn_loc: 0.08764    time: 0.9535  last_time: 0.8853  data_time: 0.0353  last_data_time: 0.0042   lr: 0.00016983  max_mem: 9964M\n",
      "\u001b[32m[01/03 21:10:38 d2.utils.events]: \u001b[0m eta: 0:04:40  iter: 699  total_loss: 1.018  loss_cls: 0.1981  loss_box_reg: 0.3694  loss_mask: 0.2796  loss_rpn_cls: 0.0611  loss_rpn_loc: 0.06926    time: 0.9540  last_time: 0.9091  data_time: 0.0581  last_data_time: 0.0044   lr: 0.00017483  max_mem: 9964M\n",
      "\u001b[32m[01/03 21:10:56 d2.utils.events]: \u001b[0m eta: 0:04:22  iter: 719  total_loss: 1.15  loss_cls: 0.2322  loss_box_reg: 0.4555  loss_mask: 0.298  loss_rpn_cls: 0.06463  loss_rpn_loc: 0.08838    time: 0.9537  last_time: 0.8724  data_time: 0.0213  last_data_time: 0.0191   lr: 0.00017982  max_mem: 9964M\n",
      "\u001b[32m[01/03 21:11:16 d2.utils.events]: \u001b[0m eta: 0:04:03  iter: 739  total_loss: 1.112  loss_cls: 0.1963  loss_box_reg: 0.4453  loss_mask: 0.3011  loss_rpn_cls: 0.07358  loss_rpn_loc: 0.08264    time: 0.9545  last_time: 0.9631  data_time: 0.0593  last_data_time: 0.0111   lr: 0.00018482  max_mem: 9964M\n",
      "\u001b[32m[01/03 21:11:35 d2.utils.events]: \u001b[0m eta: 0:03:44  iter: 759  total_loss: 1.123  loss_cls: 0.2097  loss_box_reg: 0.4277  loss_mask: 0.294  loss_rpn_cls: 0.06449  loss_rpn_loc: 0.09295    time: 0.9545  last_time: 0.9206  data_time: 0.0279  last_data_time: 0.0056   lr: 0.00018981  max_mem: 9964M\n",
      "\u001b[32m[01/03 21:11:54 d2.utils.events]: \u001b[0m eta: 0:03:26  iter: 779  total_loss: 1.058  loss_cls: 0.1918  loss_box_reg: 0.4101  loss_mask: 0.2903  loss_rpn_cls: 0.07027  loss_rpn_loc: 0.07482    time: 0.9543  last_time: 0.9324  data_time: 0.0303  last_data_time: 0.0056   lr: 0.00019481  max_mem: 9964M\n",
      "\u001b[32m[01/03 21:12:13 d2.utils.events]: \u001b[0m eta: 0:03:07  iter: 799  total_loss: 1.1  loss_cls: 0.2038  loss_box_reg: 0.4191  loss_mask: 0.3026  loss_rpn_cls: 0.06594  loss_rpn_loc: 0.079    time: 0.9542  last_time: 1.0285  data_time: 0.0334  last_data_time: 0.0947   lr: 0.0001998  max_mem: 9964M\n",
      "\u001b[32m[01/03 21:12:32 d2.utils.events]: \u001b[0m eta: 0:02:48  iter: 819  total_loss: 1.143  loss_cls: 0.2274  loss_box_reg: 0.4575  loss_mask: 0.2884  loss_rpn_cls: 0.07828  loss_rpn_loc: 0.08016    time: 0.9542  last_time: 1.0087  data_time: 0.0229  last_data_time: 0.0939   lr: 0.0002048  max_mem: 9964M\n",
      "\u001b[32m[01/03 21:12:51 d2.utils.events]: \u001b[0m eta: 0:02:29  iter: 839  total_loss: 1.003  loss_cls: 0.1885  loss_box_reg: 0.3581  loss_mask: 0.2849  loss_rpn_cls: 0.05133  loss_rpn_loc: 0.07328    time: 0.9539  last_time: 0.9032  data_time: 0.0180  last_data_time: 0.0045   lr: 0.00020979  max_mem: 9964M\n",
      "\u001b[32m[01/03 21:13:10 d2.utils.events]: \u001b[0m eta: 0:02:11  iter: 859  total_loss: 1.17  loss_cls: 0.2229  loss_box_reg: 0.4244  loss_mask: 0.2794  loss_rpn_cls: 0.06917  loss_rpn_loc: 0.07243    time: 0.9538  last_time: 0.9595  data_time: 0.0323  last_data_time: 0.0037   lr: 0.00021479  max_mem: 9964M\n",
      "\u001b[32m[01/03 21:13:29 d2.utils.events]: \u001b[0m eta: 0:01:52  iter: 879  total_loss: 1.014  loss_cls: 0.1982  loss_box_reg: 0.3969  loss_mask: 0.2569  loss_rpn_cls: 0.06749  loss_rpn_loc: 0.07882    time: 0.9534  last_time: 1.0319  data_time: 0.0180  last_data_time: 0.0762   lr: 0.00021978  max_mem: 9964M\n",
      "\u001b[32m[01/03 21:13:48 d2.utils.events]: \u001b[0m eta: 0:01:33  iter: 899  total_loss: 1.046  loss_cls: 0.1927  loss_box_reg: 0.4161  loss_mask: 0.2925  loss_rpn_cls: 0.0565  loss_rpn_loc: 0.09112    time: 0.9535  last_time: 0.9167  data_time: 0.0403  last_data_time: 0.0196   lr: 0.00022478  max_mem: 9964M\n",
      "\u001b[32m[01/03 21:14:07 d2.utils.events]: \u001b[0m eta: 0:01:14  iter: 919  total_loss: 0.9637  loss_cls: 0.1874  loss_box_reg: 0.3662  loss_mask: 0.2709  loss_rpn_cls: 0.06364  loss_rpn_loc: 0.05797    time: 0.9532  last_time: 0.8940  data_time: 0.0238  last_data_time: 0.0063   lr: 0.00022977  max_mem: 9964M\n",
      "\u001b[32m[01/03 21:14:26 d2.utils.events]: \u001b[0m eta: 0:00:56  iter: 939  total_loss: 1.09  loss_cls: 0.2108  loss_box_reg: 0.4317  loss_mask: 0.284  loss_rpn_cls: 0.06339  loss_rpn_loc: 0.07829    time: 0.9529  last_time: 0.9575  data_time: 0.0256  last_data_time: 0.0168   lr: 0.00023477  max_mem: 9964M\n",
      "\u001b[32m[01/03 21:14:45 d2.utils.events]: \u001b[0m eta: 0:00:37  iter: 959  total_loss: 0.9501  loss_cls: 0.1801  loss_box_reg: 0.3509  loss_mask: 0.2534  loss_rpn_cls: 0.065  loss_rpn_loc: 0.06596    time: 0.9528  last_time: 1.0574  data_time: 0.0326  last_data_time: 0.1429   lr: 0.00023976  max_mem: 9964M\n",
      "\u001b[32m[01/03 21:15:04 d2.utils.events]: \u001b[0m eta: 0:00:18  iter: 979  total_loss: 1.003  loss_cls: 0.1871  loss_box_reg: 0.3912  loss_mask: 0.2962  loss_rpn_cls: 0.06836  loss_rpn_loc: 0.0779    time: 0.9528  last_time: 0.9542  data_time: 0.0327  last_data_time: 0.0029   lr: 0.00024476  max_mem: 9964M\n",
      "\u001b[32m[01/03 21:15:23 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 999  total_loss: 1.031  loss_cls: 0.1866  loss_box_reg: 0.391  loss_mask: 0.2691  loss_rpn_cls: 0.05818  loss_rpn_loc: 0.0858    time: 0.9528  last_time: 1.0393  data_time: 0.0271  last_data_time: 0.0864   lr: 0.00024975  max_mem: 9964M\n",
      "\u001b[32m[01/03 21:15:23 d2.engine.hooks]: \u001b[0mOverall training speed: 998 iterations in 0:15:50 (0.9528 s / it)\n",
      "\u001b[32m[01/03 21:15:23 d2.engine.hooks]: \u001b[0mTotal training time: 0:15:52 (0:00:01 on hooks)\n",
      "\u001b[32m[01/03 21:15:23 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/03 21:15:23 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[01/03 21:15:23 d2.data.common]: \u001b[0mSerializing 23 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/03 21:15:23 d2.data.common]: \u001b[0mSerialized dataset takes 0.37 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[01/03 21:15:23 d2.engine.defaults]: \u001b[0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.\n",
      "Finished training mask_rcnn_R_50_C4_3x. Model saved in /home/etaylor/code_projects/thesis/checkpoints/stigmas_segmentation/detectron2/fine_tuned/mask_rcnn_R_50_C4_3x\n",
      "Training mask_rcnn_R_50_DC5_3x...\n",
      "\u001b[32m[01/03 21:15:26 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): ResNet(\n",
      "    (stem): BasicStem(\n",
      "      (conv1): Conv2d(\n",
      "        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "      )\n",
      "    )\n",
      "    (res2): Sequential(\n",
      "      (0): BottleneckBlock(\n",
      "        (shortcut): Conv2d(\n",
      "          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv1): Conv2d(\n",
      "          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (1): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (2): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (res3): Sequential(\n",
      "      (0): BottleneckBlock(\n",
      "        (shortcut): Conv2d(\n",
      "          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "        (conv1): Conv2d(\n",
      "          256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (1): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (2): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (3): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (res4): Sequential(\n",
      "      (0): BottleneckBlock(\n",
      "        (shortcut): Conv2d(\n",
      "          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "        (conv1): Conv2d(\n",
      "          512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (1): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (2): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (3): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (4): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (5): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (res5): Sequential(\n",
      "      (0): BottleneckBlock(\n",
      "        (shortcut): Conv2d(\n",
      "          1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "        )\n",
      "        (conv1): Conv2d(\n",
      "          1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (1): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (2): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(2048, 15, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(2048, 60, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=100352, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=2, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[01/03 21:15:26 d2.data.build]: \u001b[0mRemoved 3 images with no usable annotations. 89 images left.\n",
      "\u001b[32m[01/03 21:15:26 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[01/03 21:15:26 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[01/03 21:15:26 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[01/03 21:15:26 d2.data.common]: \u001b[0mSerializing 89 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/03 21:15:26 d2.data.common]: \u001b[0mSerialized dataset takes 1.27 MiB\n",
      "\u001b[32m[01/03 21:15:26 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from https://dl.fbaipublicfiles.com/detectron2/COCO-InstanceSegmentation/mask_rcnn_R_50_DC5_3x/137849551/model_final_84107b.pkl ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (2, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (2,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (4, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (4,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (1, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (1,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.mask_head.predictor.{bias, weight}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[01/03 21:15:27 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/etaylor/.conda/envs/detectron_fastai/lib/python3.9/site-packages/detectron2/data/detection_utils.py:446: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)\n",
      "  torch.stack([torch.from_numpy(np.ascontiguousarray(x)) for x in masks])\n",
      "/home/etaylor/.conda/envs/detectron_fastai/lib/python3.9/site-packages/detectron2/data/detection_utils.py:446: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)\n",
      "  torch.stack([torch.from_numpy(np.ascontiguousarray(x)) for x in masks])\n",
      "/home/etaylor/.conda/envs/detectron_fastai/lib/python3.9/site-packages/detectron2/data/detection_utils.py:446: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)\n",
      "  torch.stack([torch.from_numpy(np.ascontiguousarray(x)) for x in masks])\n",
      "/home/etaylor/.conda/envs/detectron_fastai/lib/python3.9/site-packages/detectron2/data/detection_utils.py:446: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)\n",
      "  torch.stack([torch.from_numpy(np.ascontiguousarray(x)) for x in masks])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[01/03 21:15:47 d2.utils.events]: \u001b[0m eta: 0:14:24  iter: 19  total_loss: 3.21  loss_cls: 0.5947  loss_box_reg: 0.2539  loss_mask: 0.6919  loss_rpn_cls: 1.58  loss_rpn_loc: 0.1678    time: 0.9393  last_time: 0.7666  data_time: 0.2165  last_data_time: 0.0149   lr: 4.9953e-06  max_mem: 9964M\n",
      "\u001b[32m[01/03 21:16:04 d2.utils.events]: \u001b[0m eta: 0:13:32  iter: 39  total_loss: 2.682  loss_cls: 0.5324  loss_box_reg: 0.2477  loss_mask: 0.6855  loss_rpn_cls: 1.093  loss_rpn_loc: 0.1007    time: 0.8879  last_time: 0.8666  data_time: 0.0602  last_data_time: 0.0994   lr: 9.9902e-06  max_mem: 9964M\n",
      "\u001b[32m[01/03 21:16:21 d2.utils.events]: \u001b[0m eta: 0:13:25  iter: 59  total_loss: 2.264  loss_cls: 0.459  loss_box_reg: 0.4099  loss_mask: 0.6698  loss_rpn_cls: 0.5898  loss_rpn_loc: 0.09267    time: 0.8807  last_time: 0.8479  data_time: 0.0290  last_data_time: 0.0653   lr: 1.4985e-05  max_mem: 9964M\n",
      "\u001b[32m[01/03 21:16:39 d2.utils.events]: \u001b[0m eta: 0:13:18  iter: 79  total_loss: 2.22  loss_cls: 0.4223  loss_box_reg: 0.4859  loss_mask: 0.6512  loss_rpn_cls: 0.6177  loss_rpn_loc: 0.1188    time: 0.8872  last_time: 1.1019  data_time: 0.0480  last_data_time: 0.2644   lr: 1.998e-05  max_mem: 9964M\n",
      "\u001b[32m[01/03 21:16:57 d2.utils.events]: \u001b[0m eta: 0:13:12  iter: 99  total_loss: 2.249  loss_cls: 0.4546  loss_box_reg: 0.6995  loss_mask: 0.6307  loss_rpn_cls: 0.3885  loss_rpn_loc: 0.09686    time: 0.8925  last_time: 0.8742  data_time: 0.0557  last_data_time: 0.0265   lr: 2.4975e-05  max_mem: 9964M\n",
      "\u001b[32m[01/03 21:17:15 d2.utils.events]: \u001b[0m eta: 0:12:49  iter: 119  total_loss: 1.933  loss_cls: 0.3844  loss_box_reg: 0.5518  loss_mask: 0.6062  loss_rpn_cls: 0.3049  loss_rpn_loc: 0.08977    time: 0.8885  last_time: 0.8183  data_time: 0.0350  last_data_time: 0.0050   lr: 2.997e-05  max_mem: 9964M\n",
      "\u001b[32m[01/03 21:17:33 d2.utils.events]: \u001b[0m eta: 0:12:31  iter: 139  total_loss: 1.946  loss_cls: 0.394  loss_box_reg: 0.5828  loss_mask: 0.5856  loss_rpn_cls: 0.2579  loss_rpn_loc: 0.1208    time: 0.8917  last_time: 0.8518  data_time: 0.0504  last_data_time: 0.0059   lr: 3.4965e-05  max_mem: 9964M\n",
      "\u001b[32m[01/03 21:17:50 d2.utils.events]: \u001b[0m eta: 0:12:08  iter: 159  total_loss: 1.835  loss_cls: 0.3839  loss_box_reg: 0.6063  loss_mask: 0.561  loss_rpn_cls: 0.1942  loss_rpn_loc: 0.0831    time: 0.8882  last_time: 0.8216  data_time: 0.0445  last_data_time: 0.0042   lr: 3.996e-05  max_mem: 9964M\n",
      "\u001b[32m[01/03 21:18:08 d2.utils.events]: \u001b[0m eta: 0:11:50  iter: 179  total_loss: 1.853  loss_cls: 0.4001  loss_box_reg: 0.6795  loss_mask: 0.542  loss_rpn_cls: 0.2002  loss_rpn_loc: 0.08731    time: 0.8884  last_time: 0.8440  data_time: 0.0811  last_data_time: 0.0049   lr: 4.4955e-05  max_mem: 9964M\n",
      "\u001b[32m[01/03 21:18:26 d2.utils.events]: \u001b[0m eta: 0:11:34  iter: 199  total_loss: 1.802  loss_cls: 0.3654  loss_box_reg: 0.6521  loss_mask: 0.4986  loss_rpn_cls: 0.151  loss_rpn_loc: 0.08991    time: 0.8889  last_time: 1.0574  data_time: 0.0576  last_data_time: 0.2118   lr: 4.995e-05  max_mem: 9964M\n",
      "\u001b[32m[01/03 21:18:44 d2.utils.events]: \u001b[0m eta: 0:11:17  iter: 219  total_loss: 1.79  loss_cls: 0.3585  loss_box_reg: 0.6205  loss_mask: 0.4899  loss_rpn_cls: 0.1334  loss_rpn_loc: 0.09122    time: 0.8888  last_time: 0.8729  data_time: 0.0652  last_data_time: 0.0292   lr: 5.4945e-05  max_mem: 9964M\n",
      "\u001b[32m[01/03 21:19:01 d2.utils.events]: \u001b[0m eta: 0:10:59  iter: 239  total_loss: 1.979  loss_cls: 0.4063  loss_box_reg: 0.7803  loss_mask: 0.5013  loss_rpn_cls: 0.149  loss_rpn_loc: 0.1107    time: 0.8878  last_time: 0.8627  data_time: 0.0284  last_data_time: 0.0055   lr: 5.994e-05  max_mem: 9964M\n",
      "\u001b[32m[01/03 21:19:19 d2.utils.events]: \u001b[0m eta: 0:10:42  iter: 259  total_loss: 1.666  loss_cls: 0.3578  loss_box_reg: 0.6592  loss_mask: 0.4427  loss_rpn_cls: 0.1058  loss_rpn_loc: 0.08614    time: 0.8868  last_time: 0.7977  data_time: 0.0570  last_data_time: 0.0051   lr: 6.4935e-05  max_mem: 9964M\n",
      "\u001b[32m[01/03 21:19:37 d2.utils.events]: \u001b[0m eta: 0:10:25  iter: 279  total_loss: 1.683  loss_cls: 0.3516  loss_box_reg: 0.6573  loss_mask: 0.4432  loss_rpn_cls: 0.1271  loss_rpn_loc: 0.09196    time: 0.8870  last_time: 0.9815  data_time: 0.0625  last_data_time: 0.1545   lr: 6.993e-05  max_mem: 9964M\n",
      "\u001b[32m[01/03 21:19:54 d2.utils.events]: \u001b[0m eta: 0:10:07  iter: 299  total_loss: 1.689  loss_cls: 0.3551  loss_box_reg: 0.6938  loss_mask: 0.4193  loss_rpn_cls: 0.1238  loss_rpn_loc: 0.09823    time: 0.8876  last_time: 0.8004  data_time: 0.0356  last_data_time: 0.0044   lr: 7.4925e-05  max_mem: 9964M\n",
      "\u001b[32m[01/03 21:20:12 d2.utils.events]: \u001b[0m eta: 0:09:50  iter: 319  total_loss: 1.487  loss_cls: 0.308  loss_box_reg: 0.5814  loss_mask: 0.4058  loss_rpn_cls: 0.09798  loss_rpn_loc: 0.06424    time: 0.8879  last_time: 0.9529  data_time: 0.0537  last_data_time: 0.0035   lr: 7.992e-05  max_mem: 9964M\n",
      "\u001b[32m[01/03 21:20:31 d2.utils.events]: \u001b[0m eta: 0:09:34  iter: 339  total_loss: 1.683  loss_cls: 0.3302  loss_box_reg: 0.7322  loss_mask: 0.4045  loss_rpn_cls: 0.1078  loss_rpn_loc: 0.0804    time: 0.8902  last_time: 0.8947  data_time: 0.0610  last_data_time: 0.0963   lr: 8.4915e-05  max_mem: 9964M\n",
      "\u001b[32m[01/03 21:20:49 d2.utils.events]: \u001b[0m eta: 0:09:16  iter: 359  total_loss: 1.573  loss_cls: 0.3183  loss_box_reg: 0.6696  loss_mask: 0.4013  loss_rpn_cls: 0.1009  loss_rpn_loc: 0.08165    time: 0.8897  last_time: 0.8174  data_time: 0.0390  last_data_time: 0.0141   lr: 8.991e-05  max_mem: 9964M\n",
      "\u001b[32m[01/03 21:21:07 d2.utils.events]: \u001b[0m eta: 0:09:01  iter: 379  total_loss: 1.497  loss_cls: 0.2967  loss_box_reg: 0.657  loss_mask: 0.3739  loss_rpn_cls: 0.08413  loss_rpn_loc: 0.08541    time: 0.8909  last_time: 0.9544  data_time: 0.0622  last_data_time: 0.1042   lr: 9.4905e-05  max_mem: 9964M\n",
      "\u001b[32m[01/03 21:21:25 d2.utils.events]: \u001b[0m eta: 0:08:43  iter: 399  total_loss: 1.408  loss_cls: 0.272  loss_box_reg: 0.6392  loss_mask: 0.3836  loss_rpn_cls: 0.08374  loss_rpn_loc: 0.07484    time: 0.8909  last_time: 0.8459  data_time: 0.0584  last_data_time: 0.0040   lr: 9.99e-05  max_mem: 9964M\n",
      "\u001b[32m[01/03 21:21:42 d2.utils.events]: \u001b[0m eta: 0:08:24  iter: 419  total_loss: 1.378  loss_cls: 0.2672  loss_box_reg: 0.6064  loss_mask: 0.3414  loss_rpn_cls: 0.06963  loss_rpn_loc: 0.06122    time: 0.8900  last_time: 0.9035  data_time: 0.0503  last_data_time: 0.1564   lr: 0.0001049  max_mem: 9964M\n",
      "\u001b[32m[01/03 21:22:00 d2.utils.events]: \u001b[0m eta: 0:08:07  iter: 439  total_loss: 1.467  loss_cls: 0.2639  loss_box_reg: 0.6357  loss_mask: 0.3644  loss_rpn_cls: 0.07293  loss_rpn_loc: 0.08878    time: 0.8905  last_time: 0.8461  data_time: 0.0592  last_data_time: 0.0747   lr: 0.00010989  max_mem: 9964M\n",
      "\u001b[32m[01/03 21:22:18 d2.utils.events]: \u001b[0m eta: 0:07:49  iter: 459  total_loss: 1.286  loss_cls: 0.2328  loss_box_reg: 0.5718  loss_mask: 0.369  loss_rpn_cls: 0.06932  loss_rpn_loc: 0.06888    time: 0.8903  last_time: 0.8988  data_time: 0.0526  last_data_time: 0.0034   lr: 0.00011489  max_mem: 9964M\n",
      "\u001b[32m[01/03 21:22:35 d2.utils.events]: \u001b[0m eta: 0:07:31  iter: 479  total_loss: 1.377  loss_cls: 0.2616  loss_box_reg: 0.6365  loss_mask: 0.3328  loss_rpn_cls: 0.06589  loss_rpn_loc: 0.0786    time: 0.8897  last_time: 0.9808  data_time: 0.0356  last_data_time: 0.0070   lr: 0.00011988  max_mem: 9964M\n",
      "\u001b[32m[01/03 21:22:54 d2.utils.events]: \u001b[0m eta: 0:07:14  iter: 499  total_loss: 1.267  loss_cls: 0.2386  loss_box_reg: 0.5403  loss_mask: 0.3169  loss_rpn_cls: 0.07029  loss_rpn_loc: 0.07527    time: 0.8906  last_time: 0.6646  data_time: 0.0470  last_data_time: 0.0757   lr: 0.00012488  max_mem: 9964M\n",
      "\u001b[32m[01/03 21:23:11 d2.utils.events]: \u001b[0m eta: 0:06:57  iter: 519  total_loss: 1.339  loss_cls: 0.2607  loss_box_reg: 0.5391  loss_mask: 0.3349  loss_rpn_cls: 0.07274  loss_rpn_loc: 0.08835    time: 0.8907  last_time: 0.8192  data_time: 0.0612  last_data_time: 0.0040   lr: 0.00012987  max_mem: 9964M\n",
      "\u001b[32m[01/03 21:23:29 d2.utils.events]: \u001b[0m eta: 0:06:39  iter: 539  total_loss: 1.223  loss_cls: 0.2406  loss_box_reg: 0.5541  loss_mask: 0.3358  loss_rpn_cls: 0.05473  loss_rpn_loc: 0.07706    time: 0.8906  last_time: 0.8326  data_time: 0.0359  last_data_time: 0.0040   lr: 0.00013487  max_mem: 9964M\n",
      "\u001b[32m[01/03 21:23:47 d2.utils.events]: \u001b[0m eta: 0:06:22  iter: 559  total_loss: 1.174  loss_cls: 0.219  loss_box_reg: 0.4961  loss_mask: 0.3257  loss_rpn_cls: 0.06484  loss_rpn_loc: 0.07366    time: 0.8903  last_time: 0.9576  data_time: 0.0479  last_data_time: 0.0944   lr: 0.00013986  max_mem: 9964M\n",
      "\u001b[32m[01/03 21:24:05 d2.utils.events]: \u001b[0m eta: 0:06:06  iter: 579  total_loss: 1.287  loss_cls: 0.2474  loss_box_reg: 0.5176  loss_mask: 0.3321  loss_rpn_cls: 0.05562  loss_rpn_loc: 0.07378    time: 0.8913  last_time: 0.9009  data_time: 0.0545  last_data_time: 0.0033   lr: 0.00014486  max_mem: 9964M\n",
      "\u001b[32m[01/03 21:24:23 d2.utils.events]: \u001b[0m eta: 0:05:49  iter: 599  total_loss: 1.219  loss_cls: 0.2296  loss_box_reg: 0.5144  loss_mask: 0.3381  loss_rpn_cls: 0.05778  loss_rpn_loc: 0.07338    time: 0.8916  last_time: 0.8343  data_time: 0.0664  last_data_time: 0.0571   lr: 0.00014985  max_mem: 9964M\n",
      "\u001b[32m[01/03 21:24:41 d2.utils.events]: \u001b[0m eta: 0:05:31  iter: 619  total_loss: 1.152  loss_cls: 0.2369  loss_box_reg: 0.4772  loss_mask: 0.3143  loss_rpn_cls: 0.06365  loss_rpn_loc: 0.06774    time: 0.8917  last_time: 0.8636  data_time: 0.0341  last_data_time: 0.0051   lr: 0.00015485  max_mem: 9964M\n",
      "\u001b[32m[01/03 21:24:59 d2.utils.events]: \u001b[0m eta: 0:05:14  iter: 639  total_loss: 1.19  loss_cls: 0.2327  loss_box_reg: 0.5145  loss_mask: 0.316  loss_rpn_cls: 0.04785  loss_rpn_loc: 0.07231    time: 0.8922  last_time: 0.8190  data_time: 0.0597  last_data_time: 0.0028   lr: 0.00015984  max_mem: 9964M\n",
      "\u001b[32m[01/03 21:25:17 d2.utils.events]: \u001b[0m eta: 0:04:57  iter: 659  total_loss: 1.113  loss_cls: 0.2117  loss_box_reg: 0.4421  loss_mask: 0.3107  loss_rpn_cls: 0.0498  loss_rpn_loc: 0.07428    time: 0.8921  last_time: 0.9010  data_time: 0.0482  last_data_time: 0.0034   lr: 0.00016484  max_mem: 9964M\n",
      "\u001b[32m[01/03 21:25:35 d2.utils.events]: \u001b[0m eta: 0:04:39  iter: 679  total_loss: 1.071  loss_cls: 0.1818  loss_box_reg: 0.4374  loss_mask: 0.3089  loss_rpn_cls: 0.04864  loss_rpn_loc: 0.06341    time: 0.8919  last_time: 0.8183  data_time: 0.0560  last_data_time: 0.0044   lr: 0.00016983  max_mem: 9964M\n",
      "\u001b[32m[01/03 21:25:53 d2.utils.events]: \u001b[0m eta: 0:04:22  iter: 699  total_loss: 1.042  loss_cls: 0.2135  loss_box_reg: 0.4391  loss_mask: 0.2815  loss_rpn_cls: 0.04383  loss_rpn_loc: 0.06615    time: 0.8918  last_time: 0.8182  data_time: 0.0441  last_data_time: 0.0066   lr: 0.00017483  max_mem: 9964M\n",
      "\u001b[32m[01/03 21:26:10 d2.utils.events]: \u001b[0m eta: 0:04:04  iter: 719  total_loss: 0.9916  loss_cls: 0.1736  loss_box_reg: 0.3803  loss_mask: 0.2903  loss_rpn_cls: 0.03286  loss_rpn_loc: 0.05995    time: 0.8911  last_time: 0.7713  data_time: 0.0321  last_data_time: 0.0020   lr: 0.00017982  max_mem: 9964M\n",
      "\u001b[32m[01/03 21:26:28 d2.utils.events]: \u001b[0m eta: 0:03:47  iter: 739  total_loss: 1.082  loss_cls: 0.1927  loss_box_reg: 0.4353  loss_mask: 0.3104  loss_rpn_cls: 0.04512  loss_rpn_loc: 0.06174    time: 0.8911  last_time: 0.8865  data_time: 0.0600  last_data_time: 0.0071   lr: 0.00018482  max_mem: 9964M\n",
      "\u001b[32m[01/03 21:26:46 d2.utils.events]: \u001b[0m eta: 0:03:29  iter: 759  total_loss: 1.142  loss_cls: 0.2292  loss_box_reg: 0.4621  loss_mask: 0.3337  loss_rpn_cls: 0.03841  loss_rpn_loc: 0.07599    time: 0.8920  last_time: 0.9539  data_time: 0.0747  last_data_time: 0.0054   lr: 0.00018981  max_mem: 9964M\n",
      "\u001b[32m[01/03 21:27:04 d2.utils.events]: \u001b[0m eta: 0:03:12  iter: 779  total_loss: 1.13  loss_cls: 0.1982  loss_box_reg: 0.4549  loss_mask: 0.3052  loss_rpn_cls: 0.03289  loss_rpn_loc: 0.05918    time: 0.8921  last_time: 0.9645  data_time: 0.0594  last_data_time: 0.1202   lr: 0.00019481  max_mem: 9964M\n",
      "\u001b[32m[01/03 21:27:22 d2.utils.events]: \u001b[0m eta: 0:02:54  iter: 799  total_loss: 0.8981  loss_cls: 0.183  loss_box_reg: 0.3701  loss_mask: 0.2899  loss_rpn_cls: 0.03193  loss_rpn_loc: 0.03997    time: 0.8919  last_time: 0.8086  data_time: 0.0579  last_data_time: 0.0035   lr: 0.0001998  max_mem: 9964M\n",
      "\u001b[32m[01/03 21:27:39 d2.utils.events]: \u001b[0m eta: 0:02:37  iter: 819  total_loss: 0.9271  loss_cls: 0.181  loss_box_reg: 0.3504  loss_mask: 0.3135  loss_rpn_cls: 0.02969  loss_rpn_loc: 0.04543    time: 0.8912  last_time: 0.9197  data_time: 0.0512  last_data_time: 0.0855   lr: 0.0002048  max_mem: 9964M\n",
      "\u001b[32m[01/03 21:27:58 d2.utils.events]: \u001b[0m eta: 0:02:19  iter: 839  total_loss: 1.067  loss_cls: 0.1894  loss_box_reg: 0.4742  loss_mask: 0.2905  loss_rpn_cls: 0.02934  loss_rpn_loc: 0.065    time: 0.8916  last_time: 0.9027  data_time: 0.0289  last_data_time: 0.0063   lr: 0.00020979  max_mem: 9964M\n",
      "\u001b[32m[01/03 21:28:16 d2.utils.events]: \u001b[0m eta: 0:02:02  iter: 859  total_loss: 1  loss_cls: 0.1762  loss_box_reg: 0.3972  loss_mask: 0.2864  loss_rpn_cls: 0.04736  loss_rpn_loc: 0.06605    time: 0.8920  last_time: 0.9915  data_time: 0.0607  last_data_time: 0.0363   lr: 0.00021479  max_mem: 9964M\n",
      "\u001b[32m[01/03 21:28:33 d2.utils.events]: \u001b[0m eta: 0:01:44  iter: 879  total_loss: 1.01  loss_cls: 0.1899  loss_box_reg: 0.4133  loss_mask: 0.3004  loss_rpn_cls: 0.03542  loss_rpn_loc: 0.06103    time: 0.8911  last_time: 0.8041  data_time: 0.0246  last_data_time: 0.0054   lr: 0.00021978  max_mem: 9964M\n",
      "\u001b[32m[01/03 21:28:51 d2.utils.events]: \u001b[0m eta: 0:01:27  iter: 899  total_loss: 0.8342  loss_cls: 0.1588  loss_box_reg: 0.3263  loss_mask: 0.2732  loss_rpn_cls: 0.02554  loss_rpn_loc: 0.05762    time: 0.8910  last_time: 0.9797  data_time: 0.0337  last_data_time: 0.0046   lr: 0.00022478  max_mem: 9964M\n",
      "\u001b[32m[01/03 21:29:09 d2.utils.events]: \u001b[0m eta: 0:01:09  iter: 919  total_loss: 0.98  loss_cls: 0.1845  loss_box_reg: 0.4179  loss_mask: 0.2921  loss_rpn_cls: 0.03095  loss_rpn_loc: 0.06361    time: 0.8911  last_time: 0.8114  data_time: 0.0502  last_data_time: 0.0958   lr: 0.00022977  max_mem: 9964M\n",
      "\u001b[32m[01/03 21:29:27 d2.utils.events]: \u001b[0m eta: 0:00:52  iter: 939  total_loss: 0.938  loss_cls: 0.1718  loss_box_reg: 0.3394  loss_mask: 0.3001  loss_rpn_cls: 0.03685  loss_rpn_loc: 0.05444    time: 0.8916  last_time: 0.9591  data_time: 0.0489  last_data_time: 0.0056   lr: 0.00023477  max_mem: 9964M\n",
      "\u001b[32m[01/03 21:29:45 d2.utils.events]: \u001b[0m eta: 0:00:34  iter: 959  total_loss: 0.9714  loss_cls: 0.1622  loss_box_reg: 0.369  loss_mask: 0.2959  loss_rpn_cls: 0.03325  loss_rpn_loc: 0.04958    time: 0.8915  last_time: 0.7916  data_time: 0.0714  last_data_time: 0.0036   lr: 0.00023976  max_mem: 9964M\n",
      "\u001b[32m[01/03 21:30:02 d2.utils.events]: \u001b[0m eta: 0:00:17  iter: 979  total_loss: 0.87  loss_cls: 0.161  loss_box_reg: 0.3428  loss_mask: 0.2846  loss_rpn_cls: 0.02628  loss_rpn_loc: 0.05351    time: 0.8912  last_time: 0.9147  data_time: 0.0458  last_data_time: 0.0869   lr: 0.00024476  max_mem: 9964M\n",
      "\u001b[32m[01/03 21:30:25 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 999  total_loss: 0.8902  loss_cls: 0.1694  loss_box_reg: 0.3533  loss_mask: 0.2842  loss_rpn_cls: 0.03367  loss_rpn_loc: 0.05709    time: 0.8919  last_time: 0.9063  data_time: 0.0643  last_data_time: 0.0044   lr: 0.00024975  max_mem: 9964M\n",
      "\u001b[32m[01/03 21:30:25 d2.engine.hooks]: \u001b[0mOverall training speed: 998 iterations in 0:14:50 (0.8919 s / it)\n",
      "\u001b[32m[01/03 21:30:25 d2.engine.hooks]: \u001b[0mTotal training time: 0:14:55 (0:00:05 on hooks)\n",
      "\u001b[32m[01/03 21:30:25 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/03 21:30:25 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[01/03 21:30:25 d2.data.common]: \u001b[0mSerializing 23 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/03 21:30:25 d2.data.common]: \u001b[0mSerialized dataset takes 0.37 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[01/03 21:30:25 d2.engine.defaults]: \u001b[0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.\n",
      "Finished training mask_rcnn_R_50_DC5_3x. Model saved in /home/etaylor/code_projects/thesis/checkpoints/stigmas_segmentation/detectron2/fine_tuned/mask_rcnn_R_50_DC5_3x\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.checkpoint import DetectionCheckpointer\n",
    "import torch\n",
    "from detectron2.engine import AMPTrainer\n",
    "import gc\n",
    "\n",
    "\n",
    "# Define paths and parameters\n",
    "detectron2_models_path = \"/home/etaylor/code_projects/thesis/checkpoints/stigmas_segmentation/detectron2/fine_tuned\"\n",
    "num_epochs = 50\n",
    "batch_size = 2\n",
    "learning_rate = 0.00025\n",
    "num_classes = 1\n",
    "\n",
    "# Dictionary of models to train\n",
    "models = {\n",
    "    \"mask_rcnn_R_50_FPN_3x\": \"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\",\n",
    "    \"mask_rcnn_R_101_FPN_3x\": \"COCO-InstanceSegmentation/mask_rcnn_R_101_FPN_3x.yaml\",\n",
    "    \"mask_rcnn_X_101_32x8d_FPN_3x\": \"COCO-InstanceSegmentation/mask_rcnn_X_101_32x8d_FPN_3x.yaml\",\n",
    "    \"mask_rcnn_R_50_C4_3x\": \"COCO-InstanceSegmentation/mask_rcnn_R_50_C4_3x.yaml\",\n",
    "    \"mask_rcnn_R_50_DC5_3x\": \"COCO-InstanceSegmentation/mask_rcnn_R_50_DC5_3x.yaml\"\n",
    "}\n",
    "\n",
    "# Function to train a model\n",
    "def train_model(model_name, config_path):\n",
    "    # Create configuration\n",
    "    cfg = get_cfg()\n",
    "    cfg.merge_from_file(model_zoo.get_config_file(config_path))\n",
    "    cfg.DATASETS.TRAIN = (f\"{segments_dataset_name}_train\",)\n",
    "    cfg.DATASETS.TEST = (f\"{segments_dataset_name}_test\",)\n",
    "    cfg.INPUT.MASK_FORMAT = \"bitmask\"\n",
    "    cfg.DATALOADER.NUM_WORKERS = 4\n",
    "    cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(config_path)  # Initialize from model zoo\n",
    "    cfg.SOLVER.IMS_PER_BATCH = batch_size\n",
    "    cfg.SOLVER.BASE_LR = learning_rate\n",
    "    cfg.SOLVER.MAX_ITER = 1000\n",
    "    cfg.SOLVER.STEPS = []  # Do not decay learning rate\n",
    "    cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 512  # Default is 512\n",
    "    cfg.MODEL.ROI_HEADS.NUM_CLASSES = num_classes  # Set number of classes\n",
    "    cfg.SOLVER.AMP.ENABLED = True\n",
    "\n",
    "    # Set output directory\n",
    "    model_saving_path = os.path.join(detectron2_models_path, model_name)\n",
    "    cfg.OUTPUT_DIR = model_saving_path\n",
    "    os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "    # Train the model\n",
    "    trainer = DefaultTrainer(cfg)\n",
    "    trainer.resume_or_load(resume=False)\n",
    "    trainer.train()\n",
    "\n",
    "    # Save checkpoint after training\n",
    "    checkpointer = DetectionCheckpointer(trainer.model, save_dir=cfg.OUTPUT_DIR)\n",
    "    checkpointer.save(\"model_final\")\n",
    "\n",
    "# Train each model\n",
    "for model_name, config_path in models.items():\n",
    "    print(f\"Training {model_name}...\")\n",
    "    train_model(model_name, config_path)\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    print(f\"Finished training {model_name}. Model saved in {os.path.join(detectron2_models_path, model_name)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "detectron_fastai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
