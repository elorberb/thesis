{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Logger detectron2 (DEBUG)>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This notebook have built from this tutorial: https://github.com/bnsreenu/python_for_microscopists/blob/master/330_Detectron2_Instance_3D_EM_Platelet.ipynb\n",
    "import os\n",
    "\n",
    "# Setup detectron2 logger\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing dataset...\n",
      "Preloading all samples. This may take a while...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[38;2;255;153;0m██████████\u001b[0m| 115/115 [00:00<00:00, 547.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized dataset with 115 images.\n",
      "Exporting dataset. This may take a while...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[38;2;255;153;0m██████████\u001b[0m| 115/115 [01:17<00:00,  1.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported to ./export_coco-instance_etaylor_stigmas_dataset_v0.2.json. Images in segments/etaylor_stigmas_dataset/v0.2\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[02/23 20:13:11 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[02/23 20:13:11 d2.data.datasets.coco]: \u001b[0mLoaded 115 images in COCO format from segments/etaylor_stigmas_dataset/annotations/export_coco-instance_etaylor_stigmas_dataset_v0.2.json\n",
      "Train dataset: 86 samples\n",
      "Test dataset: 29 samples\n"
     ]
    }
   ],
   "source": [
    "from src.segmentation.framework_handlers.detectron2_handler import register_and_split_dataset\n",
    "\n",
    "segments_dataset_name = \"etaylor/stigmas_dataset\"\n",
    "release = \"v0.2\"\n",
    "\n",
    "train_metadata, train_dataset_dicts, test_metadata, test_dataset_dicts = register_and_split_dataset(\n",
    "    dataset_name=segments_dataset_name,\n",
    "    release_version=release,\n",
    "    train_ratio=0.75,  # 75% for training, 25% for testing\n",
    ")\n",
    "\n",
    "print(f\"Train dataset: {len(train_dataset_dicts)} samples\")\n",
    "print(f\"Test dataset: {len(test_dataset_dicts)} samples\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.checkpoint import DetectionCheckpointer\n",
    "import torch\n",
    "from detectron2.engine import AMPTrainer\n",
    "import gc\n",
    "\n",
    "\n",
    "# Define paths and parameters\n",
    "detectron2_models_path = \"/home/etaylor/code_projects/thesis/checkpoints/stigmas_segmentation/detectron2/fine_tuned\"\n",
    "num_epochs = 50\n",
    "batch_size = 2\n",
    "learning_rate = 0.00025\n",
    "num_classes = 1\n",
    "\n",
    "# Dictionary of models to train\n",
    "models = {\n",
    "    \"mask_rcnn_R_50_FPN_3x\": \"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\",\n",
    "    \"mask_rcnn_R_101_FPN_3x\": \"COCO-InstanceSegmentation/mask_rcnn_R_101_FPN_3x.yaml\",\n",
    "    \"mask_rcnn_X_101_32x8d_FPN_3x\": \"COCO-InstanceSegmentation/mask_rcnn_X_101_32x8d_FPN_3x.yaml\",\n",
    "    \"mask_rcnn_R_50_C4_3x\": \"COCO-InstanceSegmentation/mask_rcnn_R_50_C4_3x.yaml\",\n",
    "    \"mask_rcnn_R_50_DC5_3x\": \"COCO-InstanceSegmentation/mask_rcnn_R_50_DC5_3x.yaml\"\n",
    "}\n",
    "\n",
    "# Function to train a model\n",
    "def train_model(model_name, config_path):\n",
    "    # Create configuration\n",
    "    cfg = get_cfg()\n",
    "    cfg.merge_from_file(model_zoo.get_config_file(config_path))\n",
    "    cfg.DATASETS.TRAIN = (f\"{segments_dataset_name}_train\",)\n",
    "    cfg.DATASETS.TEST = (f\"{segments_dataset_name}_test\",)\n",
    "    cfg.INPUT.MASK_FORMAT = \"bitmask\"\n",
    "    cfg.DATALOADER.NUM_WORKERS = 4\n",
    "    cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(config_path)  # Initialize from model zoo\n",
    "    cfg.SOLVER.IMS_PER_BATCH = batch_size\n",
    "    cfg.SOLVER.BASE_LR = learning_rate\n",
    "    cfg.SOLVER.MAX_ITER = 3000\n",
    "    cfg.SOLVER.STEPS = []  # Do not decay learning rate\n",
    "    cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 512  # Default is 512\n",
    "    cfg.MODEL.ROI_HEADS.NUM_CLASSES = num_classes  # Set number of classes\n",
    "    cfg.SOLVER.AMP.ENABLED = True\n",
    "\n",
    "    # Set output directory\n",
    "    model_saving_path = os.path.join(detectron2_models_path, model_name)\n",
    "    cfg.OUTPUT_DIR = model_saving_path\n",
    "    os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "    # Train the model\n",
    "    trainer = DefaultTrainer(cfg)\n",
    "    trainer.resume_or_load(resume=False)\n",
    "    trainer.train()\n",
    "\n",
    "    # Save checkpoint after training\n",
    "    checkpointer = DetectionCheckpointer(trainer.model, save_dir=cfg.OUTPUT_DIR)\n",
    "    checkpointer.save(\"model_final\")\n",
    "\n",
    "# Train each model\n",
    "for model_name, config_path in models.items():\n",
    "    print(f\"Training {model_name}...\")\n",
    "    train_model(model_name, config_path)\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    print(f\"Finished training {model_name}. Model saved in {os.path.join(detectron2_models_path, model_name)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import json\n",
    "import torch\n",
    "from datetime import datetime\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.checkpoint import DetectionCheckpointer\n",
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.data import build_detection_test_loader\n",
    "\n",
    "# Define paths and parameters\n",
    "DETECTRON2_MODELS_PATH = \"/home/etaylor/code_projects/thesis/checkpoints/stigmas_segmentation/detectron2/fine_tuned\"\n",
    "NUM_EPOCHS = 50\n",
    "BATCH_SIZE = 4\n",
    "LEARNING_RATE = 0.00025\n",
    "NUM_CLASSES = 1\n",
    "\n",
    "# Dataset names\n",
    "TRAIN_DATASET = f\"{segments_dataset_name}_train\"\n",
    "TEST_DATASET = f\"{segments_dataset_name}_test\"\n",
    "\n",
    "# Dictionary of models to train\n",
    "MODELS = {\n",
    "    \"mask_rcnn_R_50_FPN_3x\": \"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\",\n",
    "    \"mask_rcnn_R_101_FPN_3x\": \"COCO-InstanceSegmentation/mask_rcnn_R_101_FPN_3x.yaml\",\n",
    "    \"mask_rcnn_X_101_32x8d_FPN_3x\": \"COCO-InstanceSegmentation/mask_rcnn_X_101_32x8d_FPN_3x.yaml\",\n",
    "    \"mask_rcnn_R_50_C4_3x\": \"COCO-InstanceSegmentation/mask_rcnn_R_50_C4_3x.yaml\",\n",
    "    \"mask_rcnn_R_50_DC5_3x\": \"COCO-InstanceSegmentation/mask_rcnn_R_50_DC5_3x.yaml\"\n",
    "}\n",
    "\n",
    "\n",
    "def train_and_evaluate_model(model_name, config_path):\n",
    "    \"\"\"Train and evaluate a single model.\"\"\"\n",
    "    print(f\"Processing {model_name}...\")\n",
    "    cfg = get_cfg()\n",
    "    cfg.merge_from_file(model_zoo.get_config_file(config_path))\n",
    "    cfg.DATASETS.TRAIN = (TRAIN_DATASET,)\n",
    "    cfg.DATASETS.TEST = (TEST_DATASET,)\n",
    "    cfg.INPUT.MASK_FORMAT = \"bitmask\"\n",
    "    cfg.DATALOADER.NUM_WORKERS = 4\n",
    "    cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(config_path)\n",
    "    cfg.SOLVER.IMS_PER_BATCH = BATCH_SIZE\n",
    "    cfg.SOLVER.BASE_LR = LEARNING_RATE\n",
    "    cfg.SOLVER.MAX_ITER = 1000\n",
    "    cfg.SOLVER.STEPS = []  # No learning rate decay\n",
    "    cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 512\n",
    "    cfg.MODEL.ROI_HEADS.NUM_CLASSES = NUM_CLASSES\n",
    "    cfg.SOLVER.AMP.ENABLED = True\n",
    "    \n",
    "    # Set output directory\n",
    "    cfg.OUTPUT_DIR = os.path.join(DETECTRON2_MODELS_PATH, model_name)\n",
    "    os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "    \n",
    "    # Train the model\n",
    "    print(f\"Training {model_name}...\")\n",
    "    trainer = DefaultTrainer(cfg)\n",
    "    trainer.resume_or_load(resume=False)\n",
    "    trainer.train()\n",
    "    \n",
    "    # Save final model checkpoint\n",
    "    checkpointer = DetectionCheckpointer(trainer.model, save_dir=cfg.OUTPUT_DIR)\n",
    "    checkpointer.save(\"model_final\")\n",
    "    \n",
    "    # Free up memory\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    print(f\"Finished training {model_name}. Model saved in {cfg.OUTPUT_DIR}\")\n",
    "    \n",
    "    # Evaluate the model\n",
    "    print(f\"Evaluating {model_name}...\")\n",
    "    checkpointer.load(os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\"))\n",
    "    evaluator = COCOEvaluator(TEST_DATASET, output_dir=cfg.OUTPUT_DIR, max_dets_per_image=1000, use_fast_impl=True)\n",
    "    val_loader = build_detection_test_loader(cfg, TEST_DATASET)\n",
    "    eval_results = inference_on_dataset(trainer.model, val_loader, evaluator)\n",
    "    \n",
    "    # Save evaluation results\n",
    "    output_dir = os.path.join(cfg.OUTPUT_DIR, \"evaluation\")\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    results_file = os.path.join(output_dir, \"eval_results.json\")\n",
    "    \n",
    "    with open(results_file, \"w\") as f:\n",
    "        json.dump(eval_results, f, indent=4)\n",
    "    \n",
    "    print(f\"Evaluation completed. Results saved in {results_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing mask_rcnn_R_50_FPN_3x...\n",
      "Training mask_rcnn_R_50_FPN_3x...\n",
      "\u001b[32m[02/22 15:41:47 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=2, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[02/22 15:41:47 d2.data.build]: \u001b[0mRemoved 3 images with no usable annotations. 89 images left.\n",
      "\u001b[32m[02/22 15:41:47 d2.data.build]: \u001b[0mDistribution of instances among all 1 categories:\n",
      "\u001b[36m|  category  | #instances   |\n",
      "|:----------:|:-------------|\n",
      "|   stigma   | 690          |\n",
      "|            |              |\u001b[0m\n",
      "\u001b[32m[02/22 15:41:47 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[02/22 15:41:47 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[02/22 15:41:47 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[02/22 15:41:47 d2.data.common]: \u001b[0mSerializing 89 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/22 15:41:47 d2.data.common]: \u001b[0mSerialized dataset takes 1.35 MiB\n",
      "\u001b[32m[02/22 15:41:47 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from https://dl.fbaipublicfiles.com/detectron2/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x/137849600/model_final_f10217.pkl ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (2, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (2,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (4, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (4,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (1, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (1,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.mask_head.predictor.{bias, weight}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[02/22 15:41:51 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/etaylor/.conda/envs/detectron_fastai/lib/python3.9/site-packages/detectron2/data/detection_utils.py:446: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)\n",
      "  torch.stack([torch.from_numpy(np.ascontiguousarray(x)) for x in masks])\n",
      "/home/etaylor/.conda/envs/detectron_fastai/lib/python3.9/site-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3587.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "/home/etaylor/.conda/envs/detectron_fastai/lib/python3.9/site-packages/detectron2/data/detection_utils.py:446: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)\n",
      "  torch.stack([torch.from_numpy(np.ascontiguousarray(x)) for x in masks])\n",
      "/home/etaylor/.conda/envs/detectron_fastai/lib/python3.9/site-packages/detectron2/data/detection_utils.py:446: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)\n",
      "  torch.stack([torch.from_numpy(np.ascontiguousarray(x)) for x in masks])\n",
      "/home/etaylor/.conda/envs/detectron_fastai/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
      "/home/etaylor/.conda/envs/detectron_fastai/lib/python3.9/site-packages/detectron2/data/detection_utils.py:446: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)\n",
      "  torch.stack([torch.from_numpy(np.ascontiguousarray(x)) for x in masks])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[02/22 15:42:10 d2.utils.events]: \u001b[0m eta: 0:07:58  iter: 19  total_loss: 2.491  loss_cls: 0.797  loss_box_reg: 0.3043  loss_mask: 0.6945  loss_rpn_cls: 0.6238  loss_rpn_loc: 0.08114    time: 0.6995  last_time: 0.3670  data_time: 0.3788  last_data_time: 0.0049   lr: 4.9953e-06  max_mem: 2664M\n",
      "\u001b[32m[02/22 15:42:24 d2.utils.events]: \u001b[0m eta: 0:08:20  iter: 39  total_loss: 2.399  loss_cls: 0.6748  loss_box_reg: 0.2898  loss_mask: 0.6878  loss_rpn_cls: 0.6079  loss_rpn_loc: 0.08068    time: 0.6972  last_time: 0.5955  data_time: 0.3452  last_data_time: 0.2705   lr: 9.9902e-06  max_mem: 2896M\n",
      "\u001b[32m[02/22 15:42:39 d2.utils.events]: \u001b[0m eta: 0:08:42  iter: 59  total_loss: 1.953  loss_cls: 0.4928  loss_box_reg: 0.3004  loss_mask: 0.6763  loss_rpn_cls: 0.3411  loss_rpn_loc: 0.08559    time: 0.7060  last_time: 0.8765  data_time: 0.3724  last_data_time: 0.5401   lr: 1.4985e-05  max_mem: 2896M\n",
      "\u001b[32m[02/22 15:42:54 d2.utils.events]: \u001b[0m eta: 0:08:12  iter: 79  total_loss: 1.866  loss_cls: 0.4208  loss_box_reg: 0.439  loss_mask: 0.6582  loss_rpn_cls: 0.2489  loss_rpn_loc: 0.07462    time: 0.7164  last_time: 0.6758  data_time: 0.3803  last_data_time: 0.2641   lr: 1.998e-05  max_mem: 2896M\n",
      "\u001b[32m[02/22 15:43:08 d2.utils.events]: \u001b[0m eta: 0:08:02  iter: 99  total_loss: 1.665  loss_cls: 0.3636  loss_box_reg: 0.424  loss_mask: 0.636  loss_rpn_cls: 0.1636  loss_rpn_loc: 0.06148    time: 0.7159  last_time: 0.4420  data_time: 0.3563  last_data_time: 0.1117   lr: 2.4975e-05  max_mem: 2896M\n",
      "\u001b[32m[02/22 15:43:23 d2.utils.events]: \u001b[0m eta: 0:07:51  iter: 119  total_loss: 1.664  loss_cls: 0.3669  loss_box_reg: 0.4477  loss_mask: 0.6176  loss_rpn_cls: 0.1145  loss_rpn_loc: 0.0586    time: 0.7180  last_time: 0.3750  data_time: 0.3750  last_data_time: 0.0586   lr: 2.997e-05  max_mem: 2909M\n",
      "\u001b[32m[02/22 15:43:36 d2.utils.events]: \u001b[0m eta: 0:07:27  iter: 139  total_loss: 1.649  loss_cls: 0.3855  loss_box_reg: 0.4937  loss_mask: 0.5915  loss_rpn_cls: 0.08761  loss_rpn_loc: 0.06086    time: 0.7095  last_time: 0.3511  data_time: 0.3138  last_data_time: 0.0018   lr: 3.4965e-05  max_mem: 2929M\n",
      "\u001b[32m[02/22 15:43:52 d2.utils.events]: \u001b[0m eta: 0:07:30  iter: 159  total_loss: 1.641  loss_cls: 0.3785  loss_box_reg: 0.5385  loss_mask: 0.5614  loss_rpn_cls: 0.09052  loss_rpn_loc: 0.05522    time: 0.7219  last_time: 0.4121  data_time: 0.4424  last_data_time: 0.0022   lr: 3.996e-05  max_mem: 3038M\n",
      "\u001b[32m[02/22 15:44:04 d2.utils.events]: \u001b[0m eta: 0:07:29  iter: 179  total_loss: 1.545  loss_cls: 0.3449  loss_box_reg: 0.4752  loss_mask: 0.5435  loss_rpn_cls: 0.06884  loss_rpn_loc: 0.06125    time: 0.7107  last_time: 0.8869  data_time: 0.2634  last_data_time: 0.5367   lr: 4.4955e-05  max_mem: 3038M\n",
      "\u001b[32m[02/22 15:44:18 d2.utils.events]: \u001b[0m eta: 0:07:23  iter: 199  total_loss: 1.486  loss_cls: 0.3497  loss_box_reg: 0.5281  loss_mask: 0.5064  loss_rpn_cls: 0.07146  loss_rpn_loc: 0.05881    time: 0.7087  last_time: 0.4172  data_time: 0.3316  last_data_time: 0.0030   lr: 4.995e-05  max_mem: 3038M\n",
      "\u001b[32m[02/22 15:44:33 d2.utils.events]: \u001b[0m eta: 0:07:05  iter: 219  total_loss: 1.575  loss_cls: 0.3608  loss_box_reg: 0.5324  loss_mask: 0.5113  loss_rpn_cls: 0.06741  loss_rpn_loc: 0.0668    time: 0.7129  last_time: 0.3582  data_time: 0.3785  last_data_time: 0.0027   lr: 5.4945e-05  max_mem: 3038M\n",
      "\u001b[32m[02/22 15:44:47 d2.utils.events]: \u001b[0m eta: 0:06:58  iter: 239  total_loss: 1.526  loss_cls: 0.3571  loss_box_reg: 0.5544  loss_mask: 0.491  loss_rpn_cls: 0.06612  loss_rpn_loc: 0.06457    time: 0.7110  last_time: 1.0311  data_time: 0.3298  last_data_time: 0.7141   lr: 5.994e-05  max_mem: 3038M\n",
      "\u001b[32m[02/22 15:45:02 d2.utils.events]: \u001b[0m eta: 0:06:44  iter: 259  total_loss: 1.618  loss_cls: 0.3637  loss_box_reg: 0.5934  loss_mask: 0.4777  loss_rpn_cls: 0.05158  loss_rpn_loc: 0.05279    time: 0.7116  last_time: 0.9501  data_time: 0.3420  last_data_time: 0.6192   lr: 6.4935e-05  max_mem: 3051M\n",
      "\u001b[32m[02/22 15:45:16 d2.utils.events]: \u001b[0m eta: 0:06:38  iter: 279  total_loss: 1.54  loss_cls: 0.3355  loss_box_reg: 0.5553  loss_mask: 0.4565  loss_rpn_cls: 0.0517  loss_rpn_loc: 0.05751    time: 0.7111  last_time: 0.3416  data_time: 0.3288  last_data_time: 0.0037   lr: 6.993e-05  max_mem: 3051M\n",
      "\u001b[32m[02/22 15:45:31 d2.utils.events]: \u001b[0m eta: 0:06:22  iter: 299  total_loss: 1.634  loss_cls: 0.3758  loss_box_reg: 0.7112  loss_mask: 0.4606  loss_rpn_cls: 0.04379  loss_rpn_loc: 0.0595    time: 0.7130  last_time: 0.4320  data_time: 0.3636  last_data_time: 0.0301   lr: 7.4925e-05  max_mem: 3051M\n",
      "\u001b[32m[02/22 15:45:47 d2.utils.events]: \u001b[0m eta: 0:06:14  iter: 319  total_loss: 1.595  loss_cls: 0.3758  loss_box_reg: 0.678  loss_mask: 0.4179  loss_rpn_cls: 0.04666  loss_rpn_loc: 0.05412    time: 0.7187  last_time: 0.8960  data_time: 0.4172  last_data_time: 0.5411   lr: 7.992e-05  max_mem: 3051M\n",
      "\u001b[32m[02/22 15:45:59 d2.utils.events]: \u001b[0m eta: 0:06:01  iter: 339  total_loss: 1.42  loss_cls: 0.3272  loss_box_reg: 0.5793  loss_mask: 0.4273  loss_rpn_cls: 0.04349  loss_rpn_loc: 0.0538    time: 0.7137  last_time: 0.5490  data_time: 0.2512  last_data_time: 0.2250   lr: 8.4915e-05  max_mem: 3051M\n",
      "\u001b[32m[02/22 15:46:14 d2.utils.events]: \u001b[0m eta: 0:05:50  iter: 359  total_loss: 1.539  loss_cls: 0.3637  loss_box_reg: 0.6844  loss_mask: 0.405  loss_rpn_cls: 0.03557  loss_rpn_loc: 0.0503    time: 0.7143  last_time: 1.1158  data_time: 0.3439  last_data_time: 0.7454   lr: 8.991e-05  max_mem: 3052M\n",
      "\u001b[32m[02/22 15:46:27 d2.utils.events]: \u001b[0m eta: 0:05:39  iter: 379  total_loss: 1.488  loss_cls: 0.3332  loss_box_reg: 0.6389  loss_mask: 0.4034  loss_rpn_cls: 0.02937  loss_rpn_loc: 0.06142    time: 0.7123  last_time: 1.0001  data_time: 0.3069  last_data_time: 0.6036   lr: 9.4905e-05  max_mem: 3052M\n",
      "\u001b[32m[02/22 15:46:42 d2.utils.events]: \u001b[0m eta: 0:05:28  iter: 399  total_loss: 1.423  loss_cls: 0.3139  loss_box_reg: 0.6289  loss_mask: 0.3826  loss_rpn_cls: 0.05278  loss_rpn_loc: 0.05254    time: 0.7132  last_time: 0.3221  data_time: 0.3537  last_data_time: 0.0027   lr: 9.99e-05  max_mem: 3081M\n",
      "\u001b[32m[02/22 15:46:56 d2.utils.events]: \u001b[0m eta: 0:05:16  iter: 419  total_loss: 1.447  loss_cls: 0.3111  loss_box_reg: 0.6299  loss_mask: 0.3962  loss_rpn_cls: 0.04832  loss_rpn_loc: 0.05594    time: 0.7122  last_time: 0.5118  data_time: 0.3094  last_data_time: 0.1404   lr: 0.0001049  max_mem: 3081M\n",
      "\u001b[32m[02/22 15:47:11 d2.utils.events]: \u001b[0m eta: 0:05:06  iter: 439  total_loss: 1.453  loss_cls: 0.3239  loss_box_reg: 0.6183  loss_mask: 0.3832  loss_rpn_cls: 0.03381  loss_rpn_loc: 0.06082    time: 0.7142  last_time: 0.3951  data_time: 0.3832  last_data_time: 0.0027   lr: 0.00010989  max_mem: 3135M\n",
      "\u001b[32m[02/22 15:47:25 d2.utils.events]: \u001b[0m eta: 0:04:53  iter: 459  total_loss: 1.408  loss_cls: 0.3254  loss_box_reg: 0.6412  loss_mask: 0.3545  loss_rpn_cls: 0.0278  loss_rpn_loc: 0.04764    time: 0.7126  last_time: 0.6706  data_time: 0.2956  last_data_time: 0.2390   lr: 0.00011489  max_mem: 3135M\n",
      "\u001b[32m[02/22 15:47:39 d2.utils.events]: \u001b[0m eta: 0:04:40  iter: 479  total_loss: 1.436  loss_cls: 0.33  loss_box_reg: 0.6128  loss_mask: 0.3589  loss_rpn_cls: 0.03735  loss_rpn_loc: 0.06007    time: 0.7128  last_time: 1.3014  data_time: 0.3347  last_data_time: 0.8818   lr: 0.00011988  max_mem: 3135M\n",
      "\u001b[32m[02/22 15:47:54 d2.utils.events]: \u001b[0m eta: 0:04:31  iter: 499  total_loss: 1.33  loss_cls: 0.3169  loss_box_reg: 0.5412  loss_mask: 0.3552  loss_rpn_cls: 0.03047  loss_rpn_loc: 0.05439    time: 0.7133  last_time: 1.9090  data_time: 0.3438  last_data_time: 1.5303   lr: 0.00012488  max_mem: 3135M\n",
      "\u001b[32m[02/22 15:48:08 d2.utils.events]: \u001b[0m eta: 0:04:18  iter: 519  total_loss: 1.471  loss_cls: 0.3293  loss_box_reg: 0.5735  loss_mask: 0.3606  loss_rpn_cls: 0.0391  loss_rpn_loc: 0.05817    time: 0.7129  last_time: 0.3714  data_time: 0.3177  last_data_time: 0.0052   lr: 0.00012987  max_mem: 3135M\n",
      "\u001b[32m[02/22 15:48:21 d2.utils.events]: \u001b[0m eta: 0:04:07  iter: 539  total_loss: 1.304  loss_cls: 0.2958  loss_box_reg: 0.537  loss_mask: 0.357  loss_rpn_cls: 0.0349  loss_rpn_loc: 0.05926    time: 0.7114  last_time: 1.5114  data_time: 0.2987  last_data_time: 1.1270   lr: 0.00013487  max_mem: 3135M\n",
      "\u001b[32m[02/22 15:48:35 d2.utils.events]: \u001b[0m eta: 0:03:57  iter: 559  total_loss: 1.216  loss_cls: 0.2952  loss_box_reg: 0.5115  loss_mask: 0.3383  loss_rpn_cls: 0.04038  loss_rpn_loc: 0.05286    time: 0.7096  last_time: 0.3529  data_time: 0.2808  last_data_time: 0.0026   lr: 0.00013986  max_mem: 3135M\n",
      "\u001b[32m[02/22 15:48:49 d2.utils.events]: \u001b[0m eta: 0:03:47  iter: 579  total_loss: 1.233  loss_cls: 0.3107  loss_box_reg: 0.534  loss_mask: 0.3329  loss_rpn_cls: 0.01967  loss_rpn_loc: 0.0451    time: 0.7092  last_time: 0.6118  data_time: 0.3158  last_data_time: 0.2539   lr: 0.00014486  max_mem: 3135M\n",
      "\u001b[32m[02/22 15:49:03 d2.utils.events]: \u001b[0m eta: 0:03:38  iter: 599  total_loss: 1.286  loss_cls: 0.3019  loss_box_reg: 0.5527  loss_mask: 0.338  loss_rpn_cls: 0.02704  loss_rpn_loc: 0.05098    time: 0.7097  last_time: 0.4278  data_time: 0.3399  last_data_time: 0.0814   lr: 0.00014985  max_mem: 3169M\n",
      "\u001b[32m[02/22 15:49:17 d2.utils.events]: \u001b[0m eta: 0:03:28  iter: 619  total_loss: 1.209  loss_cls: 0.2832  loss_box_reg: 0.4976  loss_mask: 0.3548  loss_rpn_cls: 0.02522  loss_rpn_loc: 0.05437    time: 0.7096  last_time: 0.9175  data_time: 0.3288  last_data_time: 0.5550   lr: 0.00015485  max_mem: 3169M\n",
      "\u001b[32m[02/22 15:49:31 d2.utils.events]: \u001b[0m eta: 0:03:17  iter: 639  total_loss: 1.139  loss_cls: 0.2912  loss_box_reg: 0.4432  loss_mask: 0.3418  loss_rpn_cls: 0.02622  loss_rpn_loc: 0.04427    time: 0.7085  last_time: 1.0278  data_time: 0.2957  last_data_time: 0.6458   lr: 0.00015984  max_mem: 3169M\n",
      "\u001b[32m[02/22 15:49:44 d2.utils.events]: \u001b[0m eta: 0:03:06  iter: 659  total_loss: 1.183  loss_cls: 0.2854  loss_box_reg: 0.5132  loss_mask: 0.3246  loss_rpn_cls: 0.02818  loss_rpn_loc: 0.04781    time: 0.7072  last_time: 0.7520  data_time: 0.2843  last_data_time: 0.3805   lr: 0.00016484  max_mem: 3169M\n",
      "\u001b[32m[02/22 15:49:59 d2.utils.events]: \u001b[0m eta: 0:02:55  iter: 679  total_loss: 1.19  loss_cls: 0.3058  loss_box_reg: 0.4372  loss_mask: 0.3155  loss_rpn_cls: 0.02777  loss_rpn_loc: 0.04201    time: 0.7083  last_time: 0.9937  data_time: 0.3588  last_data_time: 0.6160   lr: 0.00016983  max_mem: 3169M\n",
      "\u001b[32m[02/22 15:50:13 d2.utils.events]: \u001b[0m eta: 0:02:44  iter: 699  total_loss: 1.251  loss_cls: 0.3135  loss_box_reg: 0.5273  loss_mask: 0.3688  loss_rpn_cls: 0.03074  loss_rpn_loc: 0.05048    time: 0.7082  last_time: 1.3015  data_time: 0.3269  last_data_time: 0.8633   lr: 0.00017483  max_mem: 3169M\n",
      "\u001b[32m[02/22 15:50:28 d2.utils.events]: \u001b[0m eta: 0:02:33  iter: 719  total_loss: 1.296  loss_cls: 0.3224  loss_box_reg: 0.5545  loss_mask: 0.3199  loss_rpn_cls: 0.0225  loss_rpn_loc: 0.05841    time: 0.7098  last_time: 0.4375  data_time: 0.3791  last_data_time: 0.0033   lr: 0.00017982  max_mem: 3169M\n",
      "\u001b[32m[02/22 15:50:42 d2.utils.events]: \u001b[0m eta: 0:02:22  iter: 739  total_loss: 1.155  loss_cls: 0.2963  loss_box_reg: 0.4741  loss_mask: 0.3307  loss_rpn_cls: 0.02609  loss_rpn_loc: 0.04519    time: 0.7096  last_time: 0.7120  data_time: 0.3194  last_data_time: 0.3442   lr: 0.00018482  max_mem: 3169M\n",
      "\u001b[32m[02/22 15:50:55 d2.utils.events]: \u001b[0m eta: 0:02:11  iter: 759  total_loss: 1.011  loss_cls: 0.2595  loss_box_reg: 0.3899  loss_mask: 0.3108  loss_rpn_cls: 0.01616  loss_rpn_loc: 0.03283    time: 0.7079  last_time: 0.4129  data_time: 0.2724  last_data_time: 0.0026   lr: 0.00018981  max_mem: 3169M\n",
      "\u001b[32m[02/22 15:51:10 d2.utils.events]: \u001b[0m eta: 0:02:00  iter: 779  total_loss: 1.039  loss_cls: 0.2683  loss_box_reg: 0.4025  loss_mask: 0.3199  loss_rpn_cls: 0.01576  loss_rpn_loc: 0.04218    time: 0.7085  last_time: 0.9042  data_time: 0.3485  last_data_time: 0.5625   lr: 0.00019481  max_mem: 3169M\n",
      "\u001b[32m[02/22 15:51:24 d2.utils.events]: \u001b[0m eta: 0:01:49  iter: 799  total_loss: 1.189  loss_cls: 0.2892  loss_box_reg: 0.5021  loss_mask: 0.3264  loss_rpn_cls: 0.0212  loss_rpn_loc: 0.05833    time: 0.7082  last_time: 0.8571  data_time: 0.3181  last_data_time: 0.4683   lr: 0.0001998  max_mem: 3169M\n",
      "\u001b[32m[02/22 15:51:39 d2.utils.events]: \u001b[0m eta: 0:01:38  iter: 819  total_loss: 1.098  loss_cls: 0.2677  loss_box_reg: 0.4483  loss_mask: 0.3023  loss_rpn_cls: 0.01959  loss_rpn_loc: 0.04126    time: 0.7067  last_time: 0.8921  data_time: 0.2755  last_data_time: 0.5585   lr: 0.0002048  max_mem: 3169M\n",
      "\u001b[32m[02/22 15:51:53 d2.utils.events]: \u001b[0m eta: 0:01:27  iter: 839  total_loss: 1.094  loss_cls: 0.2735  loss_box_reg: 0.4695  loss_mask: 0.3263  loss_rpn_cls: 0.01675  loss_rpn_loc: 0.05037    time: 0.7065  last_time: 1.1892  data_time: 0.3182  last_data_time: 0.8206   lr: 0.00020979  max_mem: 3169M\n",
      "\u001b[32m[02/22 15:52:07 d2.utils.events]: \u001b[0m eta: 0:01:16  iter: 859  total_loss: 1.179  loss_cls: 0.2757  loss_box_reg: 0.4794  loss_mask: 0.3313  loss_rpn_cls: 0.01697  loss_rpn_loc: 0.05746    time: 0.7070  last_time: 1.3153  data_time: 0.3453  last_data_time: 0.8806   lr: 0.00021479  max_mem: 3169M\n",
      "\u001b[32m[02/22 15:52:21 d2.utils.events]: \u001b[0m eta: 0:01:05  iter: 879  total_loss: 1.086  loss_cls: 0.2659  loss_box_reg: 0.4438  loss_mask: 0.3124  loss_rpn_cls: 0.02337  loss_rpn_loc: 0.04366    time: 0.7063  last_time: 0.3661  data_time: 0.2897  last_data_time: 0.0022   lr: 0.00021978  max_mem: 3169M\n",
      "\u001b[32m[02/22 15:52:35 d2.utils.events]: \u001b[0m eta: 0:00:54  iter: 899  total_loss: 1.151  loss_cls: 0.2769  loss_box_reg: 0.4719  loss_mask: 0.3095  loss_rpn_cls: 0.01708  loss_rpn_loc: 0.04994    time: 0.7064  last_time: 0.7795  data_time: 0.3240  last_data_time: 0.3543   lr: 0.00022478  max_mem: 3169M\n",
      "\u001b[32m[02/22 15:52:49 d2.utils.events]: \u001b[0m eta: 0:00:44  iter: 919  total_loss: 1.091  loss_cls: 0.2436  loss_box_reg: 0.4728  loss_mask: 0.3042  loss_rpn_cls: 0.01889  loss_rpn_loc: 0.05416    time: 0.7060  last_time: 0.9932  data_time: 0.3050  last_data_time: 0.5989   lr: 0.00022977  max_mem: 3169M\n",
      "\u001b[32m[02/22 15:53:02 d2.utils.events]: \u001b[0m eta: 0:00:33  iter: 939  total_loss: 1.008  loss_cls: 0.2673  loss_box_reg: 0.4226  loss_mask: 0.3056  loss_rpn_cls: 0.01749  loss_rpn_loc: 0.04159    time: 0.7054  last_time: 1.4232  data_time: 0.3070  last_data_time: 1.0268   lr: 0.00023477  max_mem: 3169M\n",
      "\u001b[32m[02/22 15:53:17 d2.utils.events]: \u001b[0m eta: 0:00:22  iter: 959  total_loss: 1.076  loss_cls: 0.274  loss_box_reg: 0.4338  loss_mask: 0.2929  loss_rpn_cls: 0.01552  loss_rpn_loc: 0.04092    time: 0.7062  last_time: 1.0382  data_time: 0.3436  last_data_time: 0.6913   lr: 0.00023976  max_mem: 3169M\n",
      "\u001b[32m[02/22 15:53:31 d2.utils.events]: \u001b[0m eta: 0:00:11  iter: 979  total_loss: 1.054  loss_cls: 0.2616  loss_box_reg: 0.4278  loss_mask: 0.3201  loss_rpn_cls: 0.01165  loss_rpn_loc: 0.04479    time: 0.7060  last_time: 0.9980  data_time: 0.3147  last_data_time: 0.5674   lr: 0.00024476  max_mem: 3169M\n",
      "\u001b[32m[02/22 15:53:47 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 999  total_loss: 1.037  loss_cls: 0.2655  loss_box_reg: 0.4241  loss_mask: 0.2892  loss_rpn_cls: 0.01737  loss_rpn_loc: 0.0464    time: 0.7061  last_time: 0.4095  data_time: 0.3095  last_data_time: 0.0039   lr: 0.00024975  max_mem: 3169M\n",
      "\u001b[32m[02/22 15:53:48 d2.engine.hooks]: \u001b[0mOverall training speed: 998 iterations in 0:11:44 (0.7061 s / it)\n",
      "\u001b[32m[02/22 15:53:48 d2.engine.hooks]: \u001b[0mTotal training time: 0:11:50 (0:00:05 on hooks)\n",
      "\u001b[32m[02/22 15:53:48 d2.data.build]: \u001b[0mDistribution of instances among all 1 categories:\n",
      "\u001b[36m|  category  | #instances   |\n",
      "|:----------:|:-------------|\n",
      "|   stigma   | 164          |\n",
      "|            |              |\u001b[0m\n",
      "\u001b[32m[02/22 15:53:48 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/22 15:53:48 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[02/22 15:53:48 d2.data.common]: \u001b[0mSerializing 23 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/22 15:53:48 d2.data.common]: \u001b[0mSerialized dataset takes 0.29 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[02/22 15:53:48 d2.engine.defaults]: \u001b[0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.\n",
      "Finished training mask_rcnn_R_50_FPN_3x. Model saved in /home/etaylor/code_projects/thesis/checkpoints/stigmas_segmentation/detectron2/fine_tuned/mask_rcnn_R_50_FPN_3x\n",
      "Evaluating mask_rcnn_R_50_FPN_3x...\n",
      "\u001b[32m[02/22 15:53:48 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from /home/etaylor/code_projects/thesis/checkpoints/stigmas_segmentation/detectron2/fine_tuned/mask_rcnn_R_50_FPN_3x/model_final.pth ...\n",
      "\u001b[32m[02/22 15:53:49 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n",
      "\u001b[32m[02/22 15:53:49 d2.evaluation.coco_evaluation]: \u001b[0mTrying to convert 'etaylor/stigmas_dataset_test' to COCO format ...\n",
      "\u001b[32m[02/22 15:53:49 d2.data.datasets.coco]: \u001b[0mConverting annotations of dataset 'etaylor/stigmas_dataset_test' to COCO format ...)\n",
      "\u001b[32m[02/22 15:53:49 d2.data.datasets.coco]: \u001b[0mConverting dataset dicts into COCO format\n",
      "\u001b[32m[02/22 15:53:49 d2.data.datasets.coco]: \u001b[0mConversion finished, #images: 23, #annotations: 164\n",
      "\u001b[32m[02/22 15:53:49 d2.data.datasets.coco]: \u001b[0mCaching COCO format annotations at '/home/etaylor/code_projects/thesis/checkpoints/stigmas_segmentation/detectron2/fine_tuned/mask_rcnn_R_50_FPN_3x/etaylor/stigmas_dataset_test_coco_format.json' ...\n",
      "\u001b[32m[02/22 15:53:49 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/22 15:53:49 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[02/22 15:53:49 d2.data.common]: \u001b[0mSerializing 23 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/22 15:53:49 d2.data.common]: \u001b[0mSerialized dataset takes 0.29 MiB\n",
      "\u001b[32m[02/22 15:53:49 d2.evaluation.evaluator]: \u001b[0mStart inference on 23 batches\n",
      "\u001b[32m[02/22 15:54:01 d2.evaluation.evaluator]: \u001b[0mInference done 11/23. Dataloading: 0.0009 s/iter. Inference: 0.1788 s/iter. Eval: 0.8264 s/iter. Total: 1.0061 s/iter. ETA=0:00:12\n",
      "\u001b[32m[02/22 15:54:06 d2.evaluation.evaluator]: \u001b[0mInference done 22/23. Dataloading: 0.0009 s/iter. Inference: 0.1376 s/iter. Eval: 0.5262 s/iter. Total: 0.6648 s/iter. ETA=0:00:00\n",
      "\u001b[32m[02/22 15:54:07 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:11.747661 (0.652648 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/22 15:54:07 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.135817 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/22 15:54:07 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[02/22 15:54:07 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to /home/etaylor/code_projects/thesis/checkpoints/stigmas_segmentation/detectron2/fine_tuned/mask_rcnn_R_50_FPN_3x/coco_instances_results.json\n",
      "\u001b[32m[02/22 15:54:07 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.09s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.304\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.630\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.250\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.306\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.067\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.352\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.475\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.478\n",
      "\u001b[32m[02/22 15:54:07 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
      "| 30.418 | 63.040 | 25.007 |  nan  | 0.000 | 30.631 |\n",
      "\u001b[32m[02/22 15:54:07 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *segm*\n",
      "DONE (t=0.13s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.113\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.408\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.011\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.114\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.032\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.171\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.218\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.220\n",
      "\u001b[32m[02/22 15:54:07 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
      "| 11.341 | 40.846 | 1.118  |  nan  | 0.000 | 11.403 |\n",
      "\u001b[32m[02/22 15:54:07 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
      "Evaluation completed. Results saved in /home/etaylor/code_projects/thesis/checkpoints/stigmas_segmentation/detectron2/fine_tuned/mask_rcnn_R_50_FPN_3x/evaluation/eval_results.json\n",
      "Processing mask_rcnn_R_101_FPN_3x...\n",
      "Training mask_rcnn_R_101_FPN_3x...\n",
      "\u001b[32m[02/22 15:54:08 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (6): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (7): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (8): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (9): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (10): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (11): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (12): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (13): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (14): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (15): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (16): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (17): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (18): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (19): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (20): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (21): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (22): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=2, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[02/22 15:54:08 d2.data.build]: \u001b[0mRemoved 3 images with no usable annotations. 89 images left.\n",
      "\u001b[32m[02/22 15:54:08 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[02/22 15:54:08 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[02/22 15:54:08 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[02/22 15:54:08 d2.data.common]: \u001b[0mSerializing 89 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/22 15:54:08 d2.data.common]: \u001b[0mSerialized dataset takes 1.35 MiB\n",
      "\u001b[32m[02/22 15:54:08 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from https://dl.fbaipublicfiles.com/detectron2/COCO-InstanceSegmentation/mask_rcnn_R_101_FPN_3x/138205316/model_final_a3ec72.pkl ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (2, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (2,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (4, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (4,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (1, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (1,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.mask_head.predictor.{bias, weight}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[02/22 15:54:12 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/etaylor/.conda/envs/detectron_fastai/lib/python3.9/site-packages/detectron2/data/detection_utils.py:446: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)\n",
      "  torch.stack([torch.from_numpy(np.ascontiguousarray(x)) for x in masks])\n",
      "/home/etaylor/.conda/envs/detectron_fastai/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
      "/home/etaylor/.conda/envs/detectron_fastai/lib/python3.9/site-packages/detectron2/data/detection_utils.py:446: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)\n",
      "  torch.stack([torch.from_numpy(np.ascontiguousarray(x)) for x in masks])\n",
      "/home/etaylor/.conda/envs/detectron_fastai/lib/python3.9/site-packages/detectron2/data/detection_utils.py:446: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)\n",
      "  torch.stack([torch.from_numpy(np.ascontiguousarray(x)) for x in masks])\n",
      "/home/etaylor/.conda/envs/detectron_fastai/lib/python3.9/site-packages/detectron2/data/detection_utils.py:446: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)\n",
      "  torch.stack([torch.from_numpy(np.ascontiguousarray(x)) for x in masks])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[02/22 15:54:28 d2.utils.events]: \u001b[0m eta: 0:10:43  iter: 19  total_loss: 2.765  loss_cls: 0.7391  loss_box_reg: 0.2532  loss_mask: 0.6936  loss_rpn_cls: 0.9281  loss_rpn_loc: 0.08173    time: 0.7058  last_time: 0.5996  data_time: 0.3308  last_data_time: 0.1487   lr: 4.9953e-06  max_mem: 5256M\n",
      "\u001b[32m[02/22 15:54:42 d2.utils.events]: \u001b[0m eta: 0:09:41  iter: 39  total_loss: 2.249  loss_cls: 0.6147  loss_box_reg: 0.2465  loss_mask: 0.6877  loss_rpn_cls: 0.6357  loss_rpn_loc: 0.07518    time: 0.7198  last_time: 0.4915  data_time: 0.2880  last_data_time: 0.0471   lr: 9.9902e-06  max_mem: 5256M\n",
      "\u001b[32m[02/22 15:54:58 d2.utils.events]: \u001b[0m eta: 0:09:28  iter: 59  total_loss: 2.123  loss_cls: 0.4651  loss_box_reg: 0.3289  loss_mask: 0.6786  loss_rpn_cls: 0.5243  loss_rpn_loc: 0.07738    time: 0.7447  last_time: 0.5892  data_time: 0.3316  last_data_time: 0.0723   lr: 1.4985e-05  max_mem: 5256M\n",
      "\u001b[32m[02/22 15:55:12 d2.utils.events]: \u001b[0m eta: 0:09:16  iter: 79  total_loss: 1.657  loss_cls: 0.3704  loss_box_reg: 0.3213  loss_mask: 0.6631  loss_rpn_cls: 0.2057  loss_rpn_loc: 0.0652    time: 0.7275  last_time: 0.3948  data_time: 0.2126  last_data_time: 0.0065   lr: 1.998e-05  max_mem: 5256M\n",
      "\u001b[32m[02/22 15:55:25 d2.utils.events]: \u001b[0m eta: 0:08:56  iter: 99  total_loss: 1.595  loss_cls: 0.3219  loss_box_reg: 0.379  loss_mask: 0.647  loss_rpn_cls: 0.1641  loss_rpn_loc: 0.05638    time: 0.7151  last_time: 0.5051  data_time: 0.1922  last_data_time: 0.0025   lr: 2.4975e-05  max_mem: 5256M\n",
      "\u001b[32m[02/22 15:55:40 d2.utils.events]: \u001b[0m eta: 0:08:38  iter: 119  total_loss: 1.617  loss_cls: 0.3371  loss_box_reg: 0.4393  loss_mask: 0.6315  loss_rpn_cls: 0.1256  loss_rpn_loc: 0.07472    time: 0.7200  last_time: 0.4595  data_time: 0.2732  last_data_time: 0.0012   lr: 2.997e-05  max_mem: 5256M\n",
      "\u001b[32m[02/22 15:55:55 d2.utils.events]: \u001b[0m eta: 0:08:22  iter: 139  total_loss: 1.58  loss_cls: 0.354  loss_box_reg: 0.4679  loss_mask: 0.6085  loss_rpn_cls: 0.08397  loss_rpn_loc: 0.06647    time: 0.7263  last_time: 1.0563  data_time: 0.2831  last_data_time: 0.5901   lr: 3.4965e-05  max_mem: 5256M\n",
      "\u001b[32m[02/22 15:56:09 d2.utils.events]: \u001b[0m eta: 0:08:11  iter: 159  total_loss: 1.499  loss_cls: 0.3404  loss_box_reg: 0.4477  loss_mask: 0.5845  loss_rpn_cls: 0.08506  loss_rpn_loc: 0.0518    time: 0.7179  last_time: 0.4312  data_time: 0.1898  last_data_time: 0.0021   lr: 3.996e-05  max_mem: 5256M\n",
      "\u001b[32m[02/22 15:56:23 d2.utils.events]: \u001b[0m eta: 0:08:03  iter: 179  total_loss: 1.61  loss_cls: 0.3677  loss_box_reg: 0.5433  loss_mask: 0.5599  loss_rpn_cls: 0.07449  loss_rpn_loc: 0.0549    time: 0.7196  last_time: 0.6758  data_time: 0.2473  last_data_time: 0.1939   lr: 4.4955e-05  max_mem: 5256M\n",
      "\u001b[32m[02/22 15:56:39 d2.utils.events]: \u001b[0m eta: 0:07:53  iter: 199  total_loss: 1.629  loss_cls: 0.3581  loss_box_reg: 0.5593  loss_mask: 0.5585  loss_rpn_cls: 0.07887  loss_rpn_loc: 0.06915    time: 0.7265  last_time: 0.6915  data_time: 0.3199  last_data_time: 0.2356   lr: 4.995e-05  max_mem: 5256M\n",
      "\u001b[32m[02/22 15:56:53 d2.utils.events]: \u001b[0m eta: 0:07:39  iter: 219  total_loss: 1.586  loss_cls: 0.357  loss_box_reg: 0.595  loss_mask: 0.5007  loss_rpn_cls: 0.06386  loss_rpn_loc: 0.04626    time: 0.7225  last_time: 0.7725  data_time: 0.2086  last_data_time: 0.3087   lr: 5.4945e-05  max_mem: 5256M\n",
      "\u001b[32m[02/22 15:57:08 d2.utils.events]: \u001b[0m eta: 0:07:27  iter: 239  total_loss: 1.546  loss_cls: 0.356  loss_box_reg: 0.5435  loss_mask: 0.483  loss_rpn_cls: 0.06976  loss_rpn_loc: 0.07096    time: 0.7262  last_time: 0.4731  data_time: 0.2826  last_data_time: 0.0026   lr: 5.994e-05  max_mem: 5256M\n",
      "\u001b[32m[02/22 15:57:23 d2.utils.events]: \u001b[0m eta: 0:07:16  iter: 259  total_loss: 1.406  loss_cls: 0.3435  loss_box_reg: 0.5691  loss_mask: 0.4547  loss_rpn_cls: 0.04549  loss_rpn_loc: 0.04683    time: 0.7237  last_time: 0.9980  data_time: 0.2094  last_data_time: 0.5265   lr: 6.4935e-05  max_mem: 5256M\n",
      "\u001b[32m[02/22 15:57:37 d2.utils.events]: \u001b[0m eta: 0:07:04  iter: 279  total_loss: 1.529  loss_cls: 0.3589  loss_box_reg: 0.6407  loss_mask: 0.4504  loss_rpn_cls: 0.042  loss_rpn_loc: 0.048    time: 0.7240  last_time: 1.6832  data_time: 0.2447  last_data_time: 1.2067   lr: 6.993e-05  max_mem: 5256M\n",
      "\u001b[32m[02/22 15:57:51 d2.utils.events]: \u001b[0m eta: 0:06:53  iter: 299  total_loss: 1.623  loss_cls: 0.3831  loss_box_reg: 0.6828  loss_mask: 0.4255  loss_rpn_cls: 0.04178  loss_rpn_loc: 0.06441    time: 0.7227  last_time: 0.7235  data_time: 0.2225  last_data_time: 0.1914   lr: 7.4925e-05  max_mem: 5256M\n",
      "\u001b[32m[02/22 15:58:05 d2.utils.events]: \u001b[0m eta: 0:06:43  iter: 319  total_loss: 1.633  loss_cls: 0.3699  loss_box_reg: 0.6783  loss_mask: 0.4181  loss_rpn_cls: 0.02546  loss_rpn_loc: 0.05736    time: 0.7197  last_time: 0.4713  data_time: 0.1799  last_data_time: 0.0277   lr: 7.992e-05  max_mem: 5256M\n",
      "\u001b[32m[02/22 15:58:19 d2.utils.events]: \u001b[0m eta: 0:06:40  iter: 339  total_loss: 1.493  loss_cls: 0.3501  loss_box_reg: 0.6411  loss_mask: 0.3918  loss_rpn_cls: 0.04037  loss_rpn_loc: 0.06022    time: 0.7206  last_time: 0.7954  data_time: 0.2501  last_data_time: 0.3592   lr: 8.4915e-05  max_mem: 5256M\n",
      "\u001b[32m[02/22 15:58:33 d2.utils.events]: \u001b[0m eta: 0:06:28  iter: 359  total_loss: 1.35  loss_cls: 0.3089  loss_box_reg: 0.588  loss_mask: 0.375  loss_rpn_cls: 0.02809  loss_rpn_loc: 0.04923    time: 0.7179  last_time: 0.4833  data_time: 0.1988  last_data_time: 0.0034   lr: 8.991e-05  max_mem: 5256M\n",
      "\u001b[32m[02/22 15:58:46 d2.utils.events]: \u001b[0m eta: 0:06:19  iter: 379  total_loss: 1.391  loss_cls: 0.3261  loss_box_reg: 0.5772  loss_mask: 0.3763  loss_rpn_cls: 0.03377  loss_rpn_loc: 0.05815    time: 0.7147  last_time: 0.4866  data_time: 0.1795  last_data_time: 0.0594   lr: 9.4905e-05  max_mem: 5256M\n",
      "\u001b[32m[02/22 15:59:01 d2.utils.events]: \u001b[0m eta: 0:06:07  iter: 399  total_loss: 1.447  loss_cls: 0.3265  loss_box_reg: 0.634  loss_mask: 0.3684  loss_rpn_cls: 0.04979  loss_rpn_loc: 0.05152    time: 0.7168  last_time: 0.6669  data_time: 0.2649  last_data_time: 0.1784   lr: 9.99e-05  max_mem: 5256M\n",
      "\u001b[32m[02/22 15:59:15 d2.utils.events]: \u001b[0m eta: 0:05:55  iter: 419  total_loss: 1.503  loss_cls: 0.3367  loss_box_reg: 0.7123  loss_mask: 0.341  loss_rpn_cls: 0.03644  loss_rpn_loc: 0.05652    time: 0.7161  last_time: 0.6051  data_time: 0.2232  last_data_time: 0.1411   lr: 0.0001049  max_mem: 5256M\n",
      "\u001b[32m[02/22 15:59:30 d2.utils.events]: \u001b[0m eta: 0:05:44  iter: 439  total_loss: 1.32  loss_cls: 0.3057  loss_box_reg: 0.5263  loss_mask: 0.3632  loss_rpn_cls: 0.028  loss_rpn_loc: 0.05912    time: 0.7160  last_time: 1.0059  data_time: 0.2342  last_data_time: 0.4635   lr: 0.00010989  max_mem: 5256M\n",
      "\u001b[32m[02/22 15:59:44 d2.utils.events]: \u001b[0m eta: 0:05:31  iter: 459  total_loss: 1.296  loss_cls: 0.311  loss_box_reg: 0.5583  loss_mask: 0.345  loss_rpn_cls: 0.02505  loss_rpn_loc: 0.04382    time: 0.7158  last_time: 1.4279  data_time: 0.2206  last_data_time: 0.8650   lr: 0.00011489  max_mem: 5256M\n",
      "\u001b[32m[02/22 16:00:00 d2.utils.events]: \u001b[0m eta: 0:05:20  iter: 479  total_loss: 1.255  loss_cls: 0.2774  loss_box_reg: 0.5487  loss_mask: 0.3323  loss_rpn_cls: 0.03163  loss_rpn_loc: 0.04971    time: 0.7188  last_time: 0.6742  data_time: 0.3029  last_data_time: 0.1387   lr: 0.00011988  max_mem: 5256M\n",
      "\u001b[32m[02/22 16:00:13 d2.utils.events]: \u001b[0m eta: 0:05:08  iter: 499  total_loss: 1.207  loss_cls: 0.2797  loss_box_reg: 0.523  loss_mask: 0.3398  loss_rpn_cls: 0.02222  loss_rpn_loc: 0.0441    time: 0.7178  last_time: 0.4663  data_time: 0.2087  last_data_time: 0.0018   lr: 0.00012488  max_mem: 5256M\n",
      "\u001b[32m[02/22 16:00:29 d2.utils.events]: \u001b[0m eta: 0:04:56  iter: 519  total_loss: 1.289  loss_cls: 0.2993  loss_box_reg: 0.5349  loss_mask: 0.3283  loss_rpn_cls: 0.03669  loss_rpn_loc: 0.05248    time: 0.7204  last_time: 1.0282  data_time: 0.2966  last_data_time: 0.4972   lr: 0.00012987  max_mem: 5256M\n",
      "\u001b[32m[02/22 16:00:44 d2.utils.events]: \u001b[0m eta: 0:04:43  iter: 539  total_loss: 1.245  loss_cls: 0.2927  loss_box_reg: 0.4957  loss_mask: 0.3292  loss_rpn_cls: 0.02044  loss_rpn_loc: 0.05449    time: 0.7209  last_time: 0.5373  data_time: 0.2376  last_data_time: 0.0026   lr: 0.00013487  max_mem: 5256M\n",
      "\u001b[32m[02/22 16:00:58 d2.utils.events]: \u001b[0m eta: 0:04:31  iter: 559  total_loss: 1.209  loss_cls: 0.2887  loss_box_reg: 0.5252  loss_mask: 0.3249  loss_rpn_cls: 0.02377  loss_rpn_loc: 0.05075    time: 0.7204  last_time: 0.5583  data_time: 0.2224  last_data_time: 0.1157   lr: 0.00013986  max_mem: 5256M\n",
      "\u001b[32m[02/22 16:01:13 d2.utils.events]: \u001b[0m eta: 0:04:18  iter: 579  total_loss: 1.09  loss_cls: 0.2648  loss_box_reg: 0.4501  loss_mask: 0.3281  loss_rpn_cls: 0.02479  loss_rpn_loc: 0.04108    time: 0.7209  last_time: 0.4705  data_time: 0.2400  last_data_time: 0.0014   lr: 0.00014486  max_mem: 5256M\n",
      "\u001b[32m[02/22 16:01:28 d2.utils.events]: \u001b[0m eta: 0:04:06  iter: 599  total_loss: 1.111  loss_cls: 0.2753  loss_box_reg: 0.4557  loss_mask: 0.311  loss_rpn_cls: 0.01709  loss_rpn_loc: 0.0451    time: 0.7225  last_time: 0.5620  data_time: 0.2818  last_data_time: 0.0022   lr: 0.00014985  max_mem: 5256M\n",
      "\u001b[32m[02/22 16:01:42 d2.utils.events]: \u001b[0m eta: 0:03:54  iter: 619  total_loss: 1.161  loss_cls: 0.284  loss_box_reg: 0.4613  loss_mask: 0.3192  loss_rpn_cls: 0.02448  loss_rpn_loc: 0.048    time: 0.7213  last_time: 0.4781  data_time: 0.2073  last_data_time: 0.0018   lr: 0.00015485  max_mem: 5256M\n",
      "\u001b[32m[02/22 16:01:56 d2.utils.events]: \u001b[0m eta: 0:03:42  iter: 639  total_loss: 1.105  loss_cls: 0.2813  loss_box_reg: 0.4599  loss_mask: 0.306  loss_rpn_cls: 0.01919  loss_rpn_loc: 0.04496    time: 0.7196  last_time: 0.5541  data_time: 0.1709  last_data_time: 0.0031   lr: 0.00015984  max_mem: 5256M\n",
      "\u001b[32m[02/22 16:02:11 d2.utils.events]: \u001b[0m eta: 0:03:32  iter: 659  total_loss: 1.14  loss_cls: 0.2837  loss_box_reg: 0.4772  loss_mask: 0.3145  loss_rpn_cls: 0.01898  loss_rpn_loc: 0.05788    time: 0.7206  last_time: 0.7886  data_time: 0.2701  last_data_time: 0.3170   lr: 0.00016484  max_mem: 5256M\n",
      "\u001b[32m[02/22 16:02:26 d2.utils.events]: \u001b[0m eta: 0:03:19  iter: 679  total_loss: 1.156  loss_cls: 0.2835  loss_box_reg: 0.5109  loss_mask: 0.3357  loss_rpn_cls: 0.02643  loss_rpn_loc: 0.05054    time: 0.7205  last_time: 0.3808  data_time: 0.2112  last_data_time: 0.0026   lr: 0.00016983  max_mem: 5256M\n",
      "\u001b[32m[02/22 16:02:39 d2.utils.events]: \u001b[0m eta: 0:03:06  iter: 699  total_loss: 0.9649  loss_cls: 0.2391  loss_box_reg: 0.3906  loss_mask: 0.2944  loss_rpn_cls: 0.01701  loss_rpn_loc: 0.04284    time: 0.7186  last_time: 0.9209  data_time: 0.1766  last_data_time: 0.3953   lr: 0.00017483  max_mem: 5256M\n",
      "\u001b[32m[02/22 16:02:54 d2.utils.events]: \u001b[0m eta: 0:02:54  iter: 719  total_loss: 1.102  loss_cls: 0.2972  loss_box_reg: 0.4594  loss_mask: 0.2994  loss_rpn_cls: 0.01964  loss_rpn_loc: 0.05499    time: 0.7201  last_time: 0.7158  data_time: 0.2792  last_data_time: 0.1696   lr: 0.00017982  max_mem: 5256M\n",
      "\u001b[32m[02/22 16:03:08 d2.utils.events]: \u001b[0m eta: 0:02:42  iter: 739  total_loss: 1.12  loss_cls: 0.2626  loss_box_reg: 0.4564  loss_mask: 0.3036  loss_rpn_cls: 0.01488  loss_rpn_loc: 0.04353    time: 0.7183  last_time: 0.7781  data_time: 0.1692  last_data_time: 0.2820   lr: 0.00018482  max_mem: 5256M\n",
      "\u001b[32m[02/22 16:03:24 d2.utils.events]: \u001b[0m eta: 0:02:29  iter: 759  total_loss: 1.137  loss_cls: 0.2663  loss_box_reg: 0.4799  loss_mask: 0.2951  loss_rpn_cls: 0.01772  loss_rpn_loc: 0.04874    time: 0.7204  last_time: 0.5481  data_time: 0.3054  last_data_time: 0.0025   lr: 0.00018981  max_mem: 5256M\n",
      "\u001b[32m[02/22 16:03:38 d2.utils.events]: \u001b[0m eta: 0:02:16  iter: 779  total_loss: 1.088  loss_cls: 0.2597  loss_box_reg: 0.4194  loss_mask: 0.2924  loss_rpn_cls: 0.01619  loss_rpn_loc: 0.0383    time: 0.7202  last_time: 0.6461  data_time: 0.2261  last_data_time: 0.2020   lr: 0.00019481  max_mem: 5256M\n",
      "\u001b[32m[02/22 16:03:52 d2.utils.events]: \u001b[0m eta: 0:02:04  iter: 799  total_loss: 1.03  loss_cls: 0.2428  loss_box_reg: 0.4133  loss_mask: 0.295  loss_rpn_cls: 0.01807  loss_rpn_loc: 0.04016    time: 0.7205  last_time: 0.4656  data_time: 0.2332  last_data_time: 0.0019   lr: 0.0001998  max_mem: 5256M\n",
      "\u001b[32m[02/22 16:04:06 d2.utils.events]: \u001b[0m eta: 0:01:51  iter: 819  total_loss: 0.9466  loss_cls: 0.2273  loss_box_reg: 0.368  loss_mask: 0.2929  loss_rpn_cls: 0.01308  loss_rpn_loc: 0.03818    time: 0.7192  last_time: 0.8066  data_time: 0.1664  last_data_time: 0.3239   lr: 0.0002048  max_mem: 5256M\n",
      "\u001b[32m[02/22 16:04:21 d2.utils.events]: \u001b[0m eta: 0:01:39  iter: 839  total_loss: 1.08  loss_cls: 0.2514  loss_box_reg: 0.4501  loss_mask: 0.3117  loss_rpn_cls: 0.01515  loss_rpn_loc: 0.0453    time: 0.7201  last_time: 0.7828  data_time: 0.2600  last_data_time: 0.2836   lr: 0.00020979  max_mem: 5256M\n",
      "\u001b[32m[02/22 16:04:34 d2.utils.events]: \u001b[0m eta: 0:01:27  iter: 859  total_loss: 0.999  loss_cls: 0.2394  loss_box_reg: 0.3881  loss_mask: 0.2938  loss_rpn_cls: 0.009773  loss_rpn_loc: 0.03394    time: 0.7188  last_time: 0.8445  data_time: 0.1726  last_data_time: 0.2963   lr: 0.00021479  max_mem: 5256M\n",
      "\u001b[32m[02/22 16:04:49 d2.utils.events]: \u001b[0m eta: 0:01:14  iter: 879  total_loss: 1.057  loss_cls: 0.2643  loss_box_reg: 0.4351  loss_mask: 0.301  loss_rpn_cls: 0.01373  loss_rpn_loc: 0.05193    time: 0.7196  last_time: 0.5230  data_time: 0.2596  last_data_time: 0.0604   lr: 0.00021978  max_mem: 5256M\n",
      "\u001b[32m[02/22 16:05:03 d2.utils.events]: \u001b[0m eta: 0:01:02  iter: 899  total_loss: 0.8915  loss_cls: 0.1993  loss_box_reg: 0.3456  loss_mask: 0.2756  loss_rpn_cls: 0.007443  loss_rpn_loc: 0.03712    time: 0.7191  last_time: 0.5270  data_time: 0.2048  last_data_time: 0.0806   lr: 0.00022478  max_mem: 5256M\n",
      "\u001b[32m[02/22 16:05:17 d2.utils.events]: \u001b[0m eta: 0:00:49  iter: 919  total_loss: 0.9765  loss_cls: 0.2195  loss_box_reg: 0.3935  loss_mask: 0.2857  loss_rpn_cls: 0.009842  loss_rpn_loc: 0.03679    time: 0.7186  last_time: 0.5589  data_time: 0.2024  last_data_time: 0.1067   lr: 0.00022977  max_mem: 5256M\n",
      "\u001b[32m[02/22 16:05:33 d2.utils.events]: \u001b[0m eta: 0:00:37  iter: 939  total_loss: 0.9904  loss_cls: 0.2425  loss_box_reg: 0.3995  loss_mask: 0.2968  loss_rpn_cls: 0.01282  loss_rpn_loc: 0.04683    time: 0.7197  last_time: 1.0607  data_time: 0.2729  last_data_time: 0.5036   lr: 0.00023477  max_mem: 5256M\n",
      "\u001b[32m[02/22 16:05:47 d2.utils.events]: \u001b[0m eta: 0:00:24  iter: 959  total_loss: 0.9765  loss_cls: 0.2288  loss_box_reg: 0.3614  loss_mask: 0.2954  loss_rpn_cls: 0.007657  loss_rpn_loc: 0.04734    time: 0.7196  last_time: 0.7751  data_time: 0.2186  last_data_time: 0.2151   lr: 0.00023976  max_mem: 5256M\n",
      "\u001b[32m[02/22 16:06:02 d2.utils.events]: \u001b[0m eta: 0:00:12  iter: 979  total_loss: 1.011  loss_cls: 0.2423  loss_box_reg: 0.408  loss_mask: 0.3054  loss_rpn_cls: 0.01455  loss_rpn_loc: 0.03937    time: 0.7203  last_time: 0.9770  data_time: 0.2627  last_data_time: 0.4832   lr: 0.00024476  max_mem: 5256M\n",
      "\u001b[32m[02/22 16:06:19 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 999  total_loss: 0.8625  loss_cls: 0.2102  loss_box_reg: 0.336  loss_mask: 0.2861  loss_rpn_cls: 0.01015  loss_rpn_loc: 0.0335    time: 0.7199  last_time: 0.7180  data_time: 0.2114  last_data_time: 0.2106   lr: 0.00024975  max_mem: 5256M\n",
      "\u001b[32m[02/22 16:06:19 d2.engine.hooks]: \u001b[0mOverall training speed: 998 iterations in 0:11:58 (0.7199 s / it)\n",
      "\u001b[32m[02/22 16:06:19 d2.engine.hooks]: \u001b[0mTotal training time: 0:12:03 (0:00:05 on hooks)\n",
      "\u001b[32m[02/22 16:06:19 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/22 16:06:19 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[02/22 16:06:19 d2.data.common]: \u001b[0mSerializing 23 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/22 16:06:19 d2.data.common]: \u001b[0mSerialized dataset takes 0.29 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[02/22 16:06:19 d2.engine.defaults]: \u001b[0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.\n",
      "Finished training mask_rcnn_R_101_FPN_3x. Model saved in /home/etaylor/code_projects/thesis/checkpoints/stigmas_segmentation/detectron2/fine_tuned/mask_rcnn_R_101_FPN_3x\n",
      "Evaluating mask_rcnn_R_101_FPN_3x...\n",
      "\u001b[32m[02/22 16:06:20 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from /home/etaylor/code_projects/thesis/checkpoints/stigmas_segmentation/detectron2/fine_tuned/mask_rcnn_R_101_FPN_3x/model_final.pth ...\n",
      "\u001b[32m[02/22 16:06:27 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n",
      "\u001b[32m[02/22 16:06:27 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/22 16:06:27 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[02/22 16:06:27 d2.data.common]: \u001b[0mSerializing 23 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/22 16:06:27 d2.data.common]: \u001b[0mSerialized dataset takes 0.29 MiB\n",
      "\u001b[32m[02/22 16:06:27 d2.evaluation.evaluator]: \u001b[0mStart inference on 23 batches\n",
      "\u001b[32m[02/22 16:06:41 d2.evaluation.evaluator]: \u001b[0mInference done 11/23. Dataloading: 0.0008 s/iter. Inference: 0.2143 s/iter. Eval: 1.0008 s/iter. Total: 1.2159 s/iter. ETA=0:00:14\n",
      "\u001b[32m[02/22 16:06:47 d2.evaluation.evaluator]: \u001b[0mInference done 20/23. Dataloading: 0.0009 s/iter. Inference: 0.1642 s/iter. Eval: 0.6772 s/iter. Total: 0.8425 s/iter. ETA=0:00:02\n",
      "\u001b[32m[02/22 16:06:48 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:14.108798 (0.783822 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/22 16:06:48 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:02 (0.156612 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/22 16:06:48 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[02/22 16:06:48 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to /home/etaylor/code_projects/thesis/checkpoints/stigmas_segmentation/detectron2/fine_tuned/mask_rcnn_R_101_FPN_3x/coco_instances_results.json\n",
      "\u001b[32m[02/22 16:06:48 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.09s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.317\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.620\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.320\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.318\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.068\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.364\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.501\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.504\n",
      "\u001b[32m[02/22 16:06:48 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
      "| 31.669 | 61.969 | 32.045 |  nan  | 0.000 | 31.840 |\n",
      "\u001b[32m[02/22 16:06:48 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *segm*\n",
      "DONE (t=0.12s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.116\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.429\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.010\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.117\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.037\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.177\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.229\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.230\n",
      "\u001b[32m[02/22 16:06:49 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
      "| 11.590 | 42.864 | 1.014  |  nan  | 0.000 | 11.651 |\n",
      "\u001b[32m[02/22 16:06:49 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
      "Evaluation completed. Results saved in /home/etaylor/code_projects/thesis/checkpoints/stigmas_segmentation/detectron2/fine_tuned/mask_rcnn_R_101_FPN_3x/evaluation/eval_results.json\n",
      "Processing mask_rcnn_X_101_32x8d_FPN_3x...\n",
      "Training mask_rcnn_X_101_32x8d_FPN_3x...\n",
      "\u001b[32m[02/22 16:06:50 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (6): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (7): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (8): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (9): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (10): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (11): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (12): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (13): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (14): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (15): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (16): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (17): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (18): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (19): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (20): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (21): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (22): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            2048, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=2, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[02/22 16:06:50 d2.data.build]: \u001b[0mRemoved 3 images with no usable annotations. 89 images left.\n",
      "\u001b[32m[02/22 16:06:50 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[02/22 16:06:50 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[02/22 16:06:50 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[02/22 16:06:50 d2.data.common]: \u001b[0mSerializing 89 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/22 16:06:50 d2.data.common]: \u001b[0mSerialized dataset takes 1.35 MiB\n",
      "\u001b[32m[02/22 16:06:50 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from https://dl.fbaipublicfiles.com/detectron2/COCO-InstanceSegmentation/mask_rcnn_X_101_32x8d_FPN_3x/139653917/model_final_2d9806.pkl ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (2, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (2,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (4, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (4,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (1, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (1,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.mask_head.predictor.{bias, weight}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[02/22 16:06:57 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/etaylor/.conda/envs/detectron_fastai/lib/python3.9/site-packages/detectron2/data/detection_utils.py:446: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)\n",
      "  torch.stack([torch.from_numpy(np.ascontiguousarray(x)) for x in masks])\n",
      "/home/etaylor/.conda/envs/detectron_fastai/lib/python3.9/site-packages/detectron2/data/detection_utils.py:446: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)\n",
      "  torch.stack([torch.from_numpy(np.ascontiguousarray(x)) for x in masks])\n",
      "/home/etaylor/.conda/envs/detectron_fastai/lib/python3.9/site-packages/detectron2/data/detection_utils.py:446: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)\n",
      "  torch.stack([torch.from_numpy(np.ascontiguousarray(x)) for x in masks])\n",
      "/home/etaylor/.conda/envs/detectron_fastai/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
      "/home/etaylor/.conda/envs/detectron_fastai/lib/python3.9/site-packages/detectron2/data/detection_utils.py:446: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)\n",
      "  torch.stack([torch.from_numpy(np.ascontiguousarray(x)) for x in masks])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[02/22 16:07:26 d2.utils.events]: \u001b[0m eta: 0:22:00  iter: 19  total_loss: 2.914  loss_cls: 0.7742  loss_box_reg: 0.1561  loss_mask: 0.6944  loss_rpn_cls: 1.27  loss_rpn_loc: 0.09105    time: 1.3229  last_time: 1.4931  data_time: 0.1169  last_data_time: 0.0037   lr: 4.9953e-06  max_mem: 5470M\n",
      "\u001b[32m[02/22 16:07:54 d2.utils.events]: \u001b[0m eta: 0:21:48  iter: 39  total_loss: 2.574  loss_cls: 0.6173  loss_box_reg: 0.2279  loss_mask: 0.6889  loss_rpn_cls: 0.8418  loss_rpn_loc: 0.08463    time: 1.3557  last_time: 1.5432  data_time: 0.0049  last_data_time: 0.0129   lr: 9.9902e-06  max_mem: 5470M\n",
      "\u001b[32m[02/22 16:08:21 d2.utils.events]: \u001b[0m eta: 0:21:21  iter: 59  total_loss: 1.798  loss_cls: 0.4761  loss_box_reg: 0.2008  loss_mask: 0.6751  loss_rpn_cls: 0.2773  loss_rpn_loc: 0.06349    time: 1.3632  last_time: 1.2146  data_time: 0.0045  last_data_time: 0.0050   lr: 1.4985e-05  max_mem: 5470M\n",
      "\u001b[32m[02/22 16:08:48 d2.utils.events]: \u001b[0m eta: 0:20:54  iter: 79  total_loss: 1.851  loss_cls: 0.41  loss_box_reg: 0.4282  loss_mask: 0.6598  loss_rpn_cls: 0.2269  loss_rpn_loc: 0.0894    time: 1.3543  last_time: 1.2419  data_time: 0.0044  last_data_time: 0.0035   lr: 1.998e-05  max_mem: 5470M\n",
      "\u001b[32m[02/22 16:09:15 d2.utils.events]: \u001b[0m eta: 0:20:30  iter: 99  total_loss: 1.602  loss_cls: 0.3282  loss_box_reg: 0.3573  loss_mask: 0.6394  loss_rpn_cls: 0.1109  loss_rpn_loc: 0.06436    time: 1.3571  last_time: 1.4071  data_time: 0.0041  last_data_time: 0.0047   lr: 2.4975e-05  max_mem: 5470M\n",
      "\u001b[32m[02/22 16:09:43 d2.utils.events]: \u001b[0m eta: 0:20:08  iter: 119  total_loss: 1.718  loss_cls: 0.3865  loss_box_reg: 0.5024  loss_mask: 0.6177  loss_rpn_cls: 0.1087  loss_rpn_loc: 0.07145    time: 1.3613  last_time: 1.3740  data_time: 0.0174  last_data_time: 0.0043   lr: 2.997e-05  max_mem: 5470M\n",
      "\u001b[32m[02/22 16:10:11 d2.utils.events]: \u001b[0m eta: 0:19:42  iter: 139  total_loss: 1.732  loss_cls: 0.3778  loss_box_reg: 0.5147  loss_mask: 0.5883  loss_rpn_cls: 0.08794  loss_rpn_loc: 0.07709    time: 1.3671  last_time: 1.5338  data_time: 0.0047  last_data_time: 0.0038   lr: 3.4965e-05  max_mem: 5470M\n",
      "\u001b[32m[02/22 16:10:39 d2.utils.events]: \u001b[0m eta: 0:19:15  iter: 159  total_loss: 1.606  loss_cls: 0.3755  loss_box_reg: 0.526  loss_mask: 0.5704  loss_rpn_cls: 0.07938  loss_rpn_loc: 0.06871    time: 1.3705  last_time: 1.3492  data_time: 0.0042  last_data_time: 0.0040   lr: 3.996e-05  max_mem: 5470M\n",
      "\u001b[32m[02/22 16:11:06 d2.utils.events]: \u001b[0m eta: 0:18:48  iter: 179  total_loss: 1.575  loss_cls: 0.3696  loss_box_reg: 0.4906  loss_mask: 0.5453  loss_rpn_cls: 0.0685  loss_rpn_loc: 0.05343    time: 1.3678  last_time: 1.1096  data_time: 0.0044  last_data_time: 0.0038   lr: 4.4955e-05  max_mem: 5470M\n",
      "\u001b[32m[02/22 16:11:37 d2.utils.events]: \u001b[0m eta: 0:18:20  iter: 199  total_loss: 1.621  loss_cls: 0.3915  loss_box_reg: 0.5789  loss_mask: 0.5234  loss_rpn_cls: 0.04743  loss_rpn_loc: 0.05751    time: 1.3724  last_time: 1.5633  data_time: 0.0043  last_data_time: 0.0044   lr: 4.995e-05  max_mem: 5470M\n",
      "\u001b[32m[02/22 16:12:05 d2.utils.events]: \u001b[0m eta: 0:17:54  iter: 219  total_loss: 1.645  loss_cls: 0.385  loss_box_reg: 0.602  loss_mask: 0.5064  loss_rpn_cls: 0.05808  loss_rpn_loc: 0.06391    time: 1.3734  last_time: 1.2201  data_time: 0.0110  last_data_time: 0.0040   lr: 5.4945e-05  max_mem: 5470M\n",
      "\u001b[32m[02/22 16:12:33 d2.utils.events]: \u001b[0m eta: 0:17:28  iter: 239  total_loss: 1.55  loss_cls: 0.368  loss_box_reg: 0.5824  loss_mask: 0.4745  loss_rpn_cls: 0.05593  loss_rpn_loc: 0.0578    time: 1.3741  last_time: 1.5403  data_time: 0.0044  last_data_time: 0.0044   lr: 5.994e-05  max_mem: 5470M\n",
      "\u001b[32m[02/22 16:13:01 d2.utils.events]: \u001b[0m eta: 0:17:01  iter: 259  total_loss: 1.658  loss_cls: 0.3791  loss_box_reg: 0.6404  loss_mask: 0.4763  loss_rpn_cls: 0.0475  loss_rpn_loc: 0.07046    time: 1.3754  last_time: 1.2670  data_time: 0.0047  last_data_time: 0.0080   lr: 6.4935e-05  max_mem: 5470M\n",
      "\u001b[32m[02/22 16:13:28 d2.utils.events]: \u001b[0m eta: 0:16:32  iter: 279  total_loss: 1.516  loss_cls: 0.3671  loss_box_reg: 0.6351  loss_mask: 0.4146  loss_rpn_cls: 0.03304  loss_rpn_loc: 0.04878    time: 1.3748  last_time: 1.4183  data_time: 0.0041  last_data_time: 0.0035   lr: 6.993e-05  max_mem: 5470M\n",
      "\u001b[32m[02/22 16:13:56 d2.utils.events]: \u001b[0m eta: 0:16:07  iter: 299  total_loss: 1.502  loss_cls: 0.3535  loss_box_reg: 0.6018  loss_mask: 0.4416  loss_rpn_cls: 0.03384  loss_rpn_loc: 0.05829    time: 1.3760  last_time: 1.3722  data_time: 0.0092  last_data_time: 0.0040   lr: 7.4925e-05  max_mem: 5470M\n",
      "\u001b[32m[02/22 16:14:24 d2.utils.events]: \u001b[0m eta: 0:15:42  iter: 319  total_loss: 1.509  loss_cls: 0.3638  loss_box_reg: 0.6804  loss_mask: 0.4232  loss_rpn_cls: 0.03328  loss_rpn_loc: 0.06428    time: 1.3777  last_time: 1.3883  data_time: 0.0054  last_data_time: 0.0053   lr: 7.992e-05  max_mem: 5470M\n",
      "\u001b[32m[02/22 16:14:51 d2.utils.events]: \u001b[0m eta: 0:15:14  iter: 339  total_loss: 1.394  loss_cls: 0.3239  loss_box_reg: 0.5682  loss_mask: 0.4101  loss_rpn_cls: 0.04368  loss_rpn_loc: 0.05391    time: 1.3771  last_time: 1.1106  data_time: 0.0145  last_data_time: 0.0125   lr: 8.4915e-05  max_mem: 5470M\n",
      "\u001b[32m[02/22 16:15:19 d2.utils.events]: \u001b[0m eta: 0:14:47  iter: 359  total_loss: 1.453  loss_cls: 0.3413  loss_box_reg: 0.64  loss_mask: 0.3827  loss_rpn_cls: 0.03054  loss_rpn_loc: 0.06258    time: 1.3784  last_time: 1.5479  data_time: 0.0047  last_data_time: 0.0062   lr: 8.991e-05  max_mem: 5470M\n",
      "\u001b[32m[02/22 16:15:48 d2.utils.events]: \u001b[0m eta: 0:14:21  iter: 379  total_loss: 1.518  loss_cls: 0.3411  loss_box_reg: 0.6597  loss_mask: 0.3915  loss_rpn_cls: 0.02626  loss_rpn_loc: 0.04842    time: 1.3817  last_time: 1.6437  data_time: 0.0051  last_data_time: 0.0056   lr: 9.4905e-05  max_mem: 5470M\n",
      "\u001b[32m[02/22 16:16:17 d2.utils.events]: \u001b[0m eta: 0:13:53  iter: 399  total_loss: 1.453  loss_cls: 0.3243  loss_box_reg: 0.5889  loss_mask: 0.3689  loss_rpn_cls: 0.03173  loss_rpn_loc: 0.05416    time: 1.3842  last_time: 1.2499  data_time: 0.0152  last_data_time: 0.0038   lr: 9.99e-05  max_mem: 5470M\n",
      "\u001b[32m[02/22 16:16:45 d2.utils.events]: \u001b[0m eta: 0:13:26  iter: 419  total_loss: 1.528  loss_cls: 0.3423  loss_box_reg: 0.7041  loss_mask: 0.3766  loss_rpn_cls: 0.02708  loss_rpn_loc: 0.06581    time: 1.3840  last_time: 1.1084  data_time: 0.0068  last_data_time: 0.0041   lr: 0.0001049  max_mem: 5470M\n",
      "\u001b[32m[02/22 16:17:12 d2.utils.events]: \u001b[0m eta: 0:12:58  iter: 439  total_loss: 1.37  loss_cls: 0.3159  loss_box_reg: 0.5934  loss_mask: 0.3666  loss_rpn_cls: 0.02551  loss_rpn_loc: 0.04516    time: 1.3838  last_time: 1.3358  data_time: 0.0045  last_data_time: 0.0060   lr: 0.00010989  max_mem: 5470M\n",
      "\u001b[32m[02/22 16:17:39 d2.utils.events]: \u001b[0m eta: 0:12:30  iter: 459  total_loss: 1.255  loss_cls: 0.2956  loss_box_reg: 0.5741  loss_mask: 0.3492  loss_rpn_cls: 0.02655  loss_rpn_loc: 0.03955    time: 1.3827  last_time: 1.2464  data_time: 0.0091  last_data_time: 0.0039   lr: 0.00011489  max_mem: 5470M\n",
      "\u001b[32m[02/22 16:18:07 d2.utils.events]: \u001b[0m eta: 0:12:02  iter: 479  total_loss: 1.405  loss_cls: 0.3345  loss_box_reg: 0.6266  loss_mask: 0.3396  loss_rpn_cls: 0.02468  loss_rpn_loc: 0.06942    time: 1.3834  last_time: 1.2987  data_time: 0.0069  last_data_time: 0.0067   lr: 0.00011988  max_mem: 5470M\n",
      "\u001b[32m[02/22 16:18:34 d2.utils.events]: \u001b[0m eta: 0:11:34  iter: 499  total_loss: 1.239  loss_cls: 0.2812  loss_box_reg: 0.5319  loss_mask: 0.3412  loss_rpn_cls: 0.02276  loss_rpn_loc: 0.05732    time: 1.3823  last_time: 1.5624  data_time: 0.0045  last_data_time: 0.0041   lr: 0.00012488  max_mem: 5470M\n",
      "\u001b[32m[02/22 16:19:02 d2.utils.events]: \u001b[0m eta: 0:11:06  iter: 519  total_loss: 1.395  loss_cls: 0.3179  loss_box_reg: 0.563  loss_mask: 0.3317  loss_rpn_cls: 0.02947  loss_rpn_loc: 0.06135    time: 1.3815  last_time: 1.3959  data_time: 0.0085  last_data_time: 0.0037   lr: 0.00012987  max_mem: 5470M\n",
      "\u001b[32m[02/22 16:19:29 d2.utils.events]: \u001b[0m eta: 0:10:39  iter: 539  total_loss: 1.283  loss_cls: 0.3053  loss_box_reg: 0.5591  loss_mask: 0.3127  loss_rpn_cls: 0.02141  loss_rpn_loc: 0.05281    time: 1.3815  last_time: 1.4077  data_time: 0.0044  last_data_time: 0.0046   lr: 0.00013487  max_mem: 5470M\n",
      "\u001b[32m[02/22 16:19:58 d2.utils.events]: \u001b[0m eta: 0:10:11  iter: 559  total_loss: 1.299  loss_cls: 0.2789  loss_box_reg: 0.513  loss_mask: 0.3417  loss_rpn_cls: 0.01907  loss_rpn_loc: 0.05112    time: 1.3826  last_time: 1.3787  data_time: 0.0116  last_data_time: 0.0042   lr: 0.00013986  max_mem: 5470M\n",
      "\u001b[32m[02/22 16:20:25 d2.utils.events]: \u001b[0m eta: 0:09:43  iter: 579  total_loss: 1.141  loss_cls: 0.2587  loss_box_reg: 0.5055  loss_mask: 0.3183  loss_rpn_cls: 0.01358  loss_rpn_loc: 0.04632    time: 1.3825  last_time: 1.5598  data_time: 0.0046  last_data_time: 0.0044   lr: 0.00014486  max_mem: 5470M\n",
      "\u001b[32m[02/22 16:20:53 d2.utils.events]: \u001b[0m eta: 0:09:15  iter: 599  total_loss: 1.025  loss_cls: 0.2868  loss_box_reg: 0.4496  loss_mask: 0.3096  loss_rpn_cls: 0.0128  loss_rpn_loc: 0.04066    time: 1.3822  last_time: 1.3924  data_time: 0.0044  last_data_time: 0.0030   lr: 0.00014985  max_mem: 5470M\n",
      "\u001b[32m[02/22 16:21:21 d2.utils.events]: \u001b[0m eta: 0:08:48  iter: 619  total_loss: 1.184  loss_cls: 0.284  loss_box_reg: 0.499  loss_mask: 0.3172  loss_rpn_cls: 0.01949  loss_rpn_loc: 0.04313    time: 1.3825  last_time: 1.3650  data_time: 0.0058  last_data_time: 0.0043   lr: 0.00015485  max_mem: 5470M\n",
      "\u001b[32m[02/22 16:21:49 d2.utils.events]: \u001b[0m eta: 0:08:20  iter: 639  total_loss: 1.145  loss_cls: 0.2678  loss_box_reg: 0.5136  loss_mask: 0.3365  loss_rpn_cls: 0.01331  loss_rpn_loc: 0.05516    time: 1.3829  last_time: 1.2838  data_time: 0.0048  last_data_time: 0.0035   lr: 0.00015984  max_mem: 5470M\n",
      "\u001b[32m[02/22 16:22:17 d2.utils.events]: \u001b[0m eta: 0:07:52  iter: 659  total_loss: 1.017  loss_cls: 0.241  loss_box_reg: 0.4314  loss_mask: 0.3096  loss_rpn_cls: 0.0142  loss_rpn_loc: 0.03808    time: 1.3836  last_time: 1.5239  data_time: 0.0047  last_data_time: 0.0042   lr: 0.00016484  max_mem: 5470M\n",
      "\u001b[32m[02/22 16:22:45 d2.utils.events]: \u001b[0m eta: 0:07:24  iter: 679  total_loss: 1.005  loss_cls: 0.2183  loss_box_reg: 0.4112  loss_mask: 0.301  loss_rpn_cls: 0.01338  loss_rpn_loc: 0.04135    time: 1.3840  last_time: 1.5639  data_time: 0.0046  last_data_time: 0.0039   lr: 0.00016983  max_mem: 5470M\n",
      "\u001b[32m[02/22 16:23:12 d2.utils.events]: \u001b[0m eta: 0:06:56  iter: 699  total_loss: 1.093  loss_cls: 0.2249  loss_box_reg: 0.4795  loss_mask: 0.2968  loss_rpn_cls: 0.01124  loss_rpn_loc: 0.04376    time: 1.3832  last_time: 1.5190  data_time: 0.0062  last_data_time: 0.0045   lr: 0.00017483  max_mem: 5470M\n",
      "\u001b[32m[02/22 16:23:40 d2.utils.events]: \u001b[0m eta: 0:06:28  iter: 719  total_loss: 1.116  loss_cls: 0.2412  loss_box_reg: 0.4718  loss_mask: 0.325  loss_rpn_cls: 0.01366  loss_rpn_loc: 0.04854    time: 1.3832  last_time: 1.4206  data_time: 0.0041  last_data_time: 0.0039   lr: 0.00017982  max_mem: 5470M\n",
      "\u001b[32m[02/22 16:24:08 d2.utils.events]: \u001b[0m eta: 0:06:01  iter: 739  total_loss: 1.065  loss_cls: 0.2375  loss_box_reg: 0.4656  loss_mask: 0.2971  loss_rpn_cls: 0.01619  loss_rpn_loc: 0.04306    time: 1.3839  last_time: 1.4147  data_time: 0.0051  last_data_time: 0.0042   lr: 0.00018482  max_mem: 5470M\n",
      "\u001b[32m[02/22 16:24:36 d2.utils.events]: \u001b[0m eta: 0:05:33  iter: 759  total_loss: 0.9791  loss_cls: 0.2303  loss_box_reg: 0.4119  loss_mask: 0.2907  loss_rpn_cls: 0.009044  loss_rpn_loc: 0.03584    time: 1.3849  last_time: 1.5458  data_time: 0.0067  last_data_time: 0.0054   lr: 0.00018981  max_mem: 5470M\n",
      "\u001b[32m[02/22 16:25:04 d2.utils.events]: \u001b[0m eta: 0:05:05  iter: 779  total_loss: 1.057  loss_cls: 0.2597  loss_box_reg: 0.4197  loss_mask: 0.3102  loss_rpn_cls: 0.01034  loss_rpn_loc: 0.04753    time: 1.3854  last_time: 1.4199  data_time: 0.0078  last_data_time: 0.0043   lr: 0.00019481  max_mem: 5470M\n",
      "\u001b[32m[02/22 16:25:31 d2.utils.events]: \u001b[0m eta: 0:04:37  iter: 799  total_loss: 0.8987  loss_cls: 0.2253  loss_box_reg: 0.36  loss_mask: 0.2913  loss_rpn_cls: 0.008212  loss_rpn_loc: 0.04157    time: 1.3843  last_time: 1.3667  data_time: 0.0043  last_data_time: 0.0039   lr: 0.0001998  max_mem: 5470M\n",
      "\u001b[32m[02/22 16:25:59 d2.utils.events]: \u001b[0m eta: 0:04:10  iter: 819  total_loss: 0.9519  loss_cls: 0.2151  loss_box_reg: 0.4052  loss_mask: 0.2973  loss_rpn_cls: 0.01148  loss_rpn_loc: 0.04613    time: 1.3844  last_time: 1.5663  data_time: 0.0097  last_data_time: 0.0063   lr: 0.0002048  max_mem: 5470M\n",
      "\u001b[32m[02/22 16:26:28 d2.utils.events]: \u001b[0m eta: 0:03:42  iter: 839  total_loss: 0.817  loss_cls: 0.1717  loss_box_reg: 0.3235  loss_mask: 0.2964  loss_rpn_cls: 0.006994  loss_rpn_loc: 0.03517    time: 1.3854  last_time: 1.5272  data_time: 0.0047  last_data_time: 0.0041   lr: 0.00020979  max_mem: 5470M\n",
      "\u001b[32m[02/22 16:26:55 d2.utils.events]: \u001b[0m eta: 0:03:14  iter: 859  total_loss: 0.9383  loss_cls: 0.2083  loss_box_reg: 0.3737  loss_mask: 0.2896  loss_rpn_cls: 0.007744  loss_rpn_loc: 0.0403    time: 1.3850  last_time: 1.4178  data_time: 0.0056  last_data_time: 0.0044   lr: 0.00021479  max_mem: 5470M\n",
      "\u001b[32m[02/22 16:27:24 d2.utils.events]: \u001b[0m eta: 0:02:46  iter: 879  total_loss: 0.8269  loss_cls: 0.1813  loss_box_reg: 0.3148  loss_mask: 0.2762  loss_rpn_cls: 0.006563  loss_rpn_loc: 0.03396    time: 1.3863  last_time: 1.5846  data_time: 0.0058  last_data_time: 0.0035   lr: 0.00021978  max_mem: 5470M\n",
      "\u001b[32m[02/22 16:27:52 d2.utils.events]: \u001b[0m eta: 0:02:19  iter: 899  total_loss: 0.8631  loss_cls: 0.1831  loss_box_reg: 0.3423  loss_mask: 0.2824  loss_rpn_cls: 0.009201  loss_rpn_loc: 0.0473    time: 1.3864  last_time: 1.2945  data_time: 0.0046  last_data_time: 0.0037   lr: 0.00022478  max_mem: 5470M\n",
      "\u001b[32m[02/22 16:28:20 d2.utils.events]: \u001b[0m eta: 0:01:51  iter: 919  total_loss: 0.7878  loss_cls: 0.1746  loss_box_reg: 0.3229  loss_mask: 0.286  loss_rpn_cls: 0.007445  loss_rpn_loc: 0.03639    time: 1.3869  last_time: 1.5702  data_time: 0.0105  last_data_time: 0.0052   lr: 0.00022977  max_mem: 5470M\n",
      "\u001b[32m[02/22 16:28:48 d2.utils.events]: \u001b[0m eta: 0:01:23  iter: 939  total_loss: 0.8924  loss_cls: 0.1835  loss_box_reg: 0.3061  loss_mask: 0.2844  loss_rpn_cls: 0.007191  loss_rpn_loc: 0.03647    time: 1.3870  last_time: 1.1201  data_time: 0.0079  last_data_time: 0.0053   lr: 0.00023477  max_mem: 5470M\n",
      "\u001b[32m[02/22 16:29:16 d2.utils.events]: \u001b[0m eta: 0:00:55  iter: 959  total_loss: 0.7936  loss_cls: 0.1658  loss_box_reg: 0.3299  loss_mask: 0.2685  loss_rpn_cls: 0.003922  loss_rpn_loc: 0.03108    time: 1.3878  last_time: 1.4391  data_time: 0.0112  last_data_time: 0.0044   lr: 0.00023976  max_mem: 5470M\n",
      "\u001b[32m[02/22 16:29:44 d2.utils.events]: \u001b[0m eta: 0:00:27  iter: 979  total_loss: 0.7877  loss_cls: 0.1663  loss_box_reg: 0.3087  loss_mask: 0.2945  loss_rpn_cls: 0.003268  loss_rpn_loc: 0.0375    time: 1.3880  last_time: 1.4084  data_time: 0.0067  last_data_time: 0.0047   lr: 0.00024476  max_mem: 5470M\n",
      "\u001b[32m[02/22 16:30:16 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 999  total_loss: 0.8747  loss_cls: 0.1905  loss_box_reg: 0.3526  loss_mask: 0.2675  loss_rpn_cls: 0.004039  loss_rpn_loc: 0.03709    time: 1.3885  last_time: 1.5673  data_time: 0.0052  last_data_time: 0.0039   lr: 0.00024975  max_mem: 5470M\n",
      "\u001b[32m[02/22 16:30:16 d2.engine.hooks]: \u001b[0mOverall training speed: 998 iterations in 0:23:05 (1.3885 s / it)\n",
      "\u001b[32m[02/22 16:30:16 d2.engine.hooks]: \u001b[0mTotal training time: 0:23:13 (0:00:08 on hooks)\n",
      "\u001b[32m[02/22 16:30:16 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/22 16:30:16 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[02/22 16:30:16 d2.data.common]: \u001b[0mSerializing 23 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/22 16:30:16 d2.data.common]: \u001b[0mSerialized dataset takes 0.29 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[02/22 16:30:16 d2.engine.defaults]: \u001b[0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.\n",
      "Finished training mask_rcnn_X_101_32x8d_FPN_3x. Model saved in /home/etaylor/code_projects/thesis/checkpoints/stigmas_segmentation/detectron2/fine_tuned/mask_rcnn_X_101_32x8d_FPN_3x\n",
      "Evaluating mask_rcnn_X_101_32x8d_FPN_3x...\n",
      "\u001b[32m[02/22 16:30:18 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from /home/etaylor/code_projects/thesis/checkpoints/stigmas_segmentation/detectron2/fine_tuned/mask_rcnn_X_101_32x8d_FPN_3x/model_final.pth ...\n",
      "\u001b[32m[02/22 16:30:28 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n",
      "\u001b[32m[02/22 16:30:28 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/22 16:30:28 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[02/22 16:30:28 d2.data.common]: \u001b[0mSerializing 23 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/22 16:30:28 d2.data.common]: \u001b[0mSerialized dataset takes 0.29 MiB\n",
      "\u001b[32m[02/22 16:30:28 d2.evaluation.evaluator]: \u001b[0mStart inference on 23 batches\n",
      "\u001b[32m[02/22 16:30:38 d2.evaluation.evaluator]: \u001b[0mInference done 11/23. Dataloading: 0.0007 s/iter. Inference: 0.2339 s/iter. Eval: 0.5864 s/iter. Total: 0.8210 s/iter. ETA=0:00:09\n",
      "\u001b[32m[02/22 16:30:43 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:09.874169 (0.548565 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/22 16:30:43 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:03 (0.192970 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/22 16:30:43 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[02/22 16:30:43 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to /home/etaylor/code_projects/thesis/checkpoints/stigmas_segmentation/detectron2/fine_tuned/mask_rcnn_X_101_32x8d_FPN_3x/coco_instances_results.json\n",
      "\u001b[32m[02/22 16:30:43 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.06s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.244\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.553\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.222\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.245\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.063\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.332\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.402\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.405\n",
      "\u001b[32m[02/22 16:30:43 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
      "| 24.373 | 55.280 | 22.178 |  nan  | 0.000 | 24.484 |\n",
      "\u001b[32m[02/22 16:30:43 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *segm*\n",
      "DONE (t=0.08s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.095\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.369\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.003\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.095\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.032\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.170\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.196\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.197\n",
      "\u001b[32m[02/22 16:30:43 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
      "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
      "| 9.469 | 36.927 | 0.333  |  nan  | 0.000 | 9.489 |\n",
      "\u001b[32m[02/22 16:30:43 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
      "Evaluation completed. Results saved in /home/etaylor/code_projects/thesis/checkpoints/stigmas_segmentation/detectron2/fine_tuned/mask_rcnn_X_101_32x8d_FPN_3x/evaluation/eval_results.json\n",
      "Processing mask_rcnn_R_50_C4_3x...\n",
      "Training mask_rcnn_R_50_C4_3x...\n",
      "\u001b[32m[02/22 16:30:44 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): ResNet(\n",
      "    (stem): BasicStem(\n",
      "      (conv1): Conv2d(\n",
      "        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "      )\n",
      "    )\n",
      "    (res2): Sequential(\n",
      "      (0): BottleneckBlock(\n",
      "        (shortcut): Conv2d(\n",
      "          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv1): Conv2d(\n",
      "          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (1): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (2): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (res3): Sequential(\n",
      "      (0): BottleneckBlock(\n",
      "        (shortcut): Conv2d(\n",
      "          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "        (conv1): Conv2d(\n",
      "          256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (1): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (2): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (3): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (res4): Sequential(\n",
      "      (0): BottleneckBlock(\n",
      "        (shortcut): Conv2d(\n",
      "          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "        (conv1): Conv2d(\n",
      "          512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (1): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (2): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (3): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (4): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (5): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(1024, 15, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(1024, 60, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): Res5ROIHeads(\n",
      "    (pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (res5): Sequential(\n",
      "      (0): BottleneckBlock(\n",
      "        (shortcut): Conv2d(\n",
      "          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "        )\n",
      "        (conv1): Conv2d(\n",
      "          1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (1): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (2): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=2048, out_features=2, bias=True)\n",
      "      (bbox_pred): Linear(in_features=2048, out_features=4, bias=True)\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (deconv): ConvTranspose2d(2048, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[02/22 16:30:44 d2.data.build]: \u001b[0mRemoved 3 images with no usable annotations. 89 images left.\n",
      "\u001b[32m[02/22 16:30:44 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[02/22 16:30:44 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[02/22 16:30:44 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[02/22 16:30:44 d2.data.common]: \u001b[0mSerializing 89 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/22 16:30:44 d2.data.common]: \u001b[0mSerialized dataset takes 1.35 MiB\n",
      "\u001b[32m[02/22 16:30:44 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from https://dl.fbaipublicfiles.com/detectron2/COCO-InstanceSegmentation/mask_rcnn_R_50_C4_3x/137849525/model_final_4ce675.pkl ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 2048) in the checkpoint but (2, 2048) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (2,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 2048) in the checkpoint but (4, 2048) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (4,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (1, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (1,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.mask_head.predictor.{bias, weight}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[02/22 16:30:47 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/etaylor/.conda/envs/detectron_fastai/lib/python3.9/site-packages/detectron2/data/detection_utils.py:446: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)\n",
      "  torch.stack([torch.from_numpy(np.ascontiguousarray(x)) for x in masks])\n",
      "/home/etaylor/.conda/envs/detectron_fastai/lib/python3.9/site-packages/detectron2/data/detection_utils.py:446: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)\n",
      "  torch.stack([torch.from_numpy(np.ascontiguousarray(x)) for x in masks])\n",
      "/home/etaylor/.conda/envs/detectron_fastai/lib/python3.9/site-packages/detectron2/data/detection_utils.py:446: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)\n",
      "  torch.stack([torch.from_numpy(np.ascontiguousarray(x)) for x in masks])\n",
      "/home/etaylor/.conda/envs/detectron_fastai/lib/python3.9/site-packages/detectron2/data/detection_utils.py:446: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)\n",
      "  torch.stack([torch.from_numpy(np.ascontiguousarray(x)) for x in masks])\n",
      "/home/etaylor/.conda/envs/detectron_fastai/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[02/22 16:31:07 d2.utils.events]: \u001b[0m eta: 0:14:59  iter: 19  total_loss: 2.624  loss_cls: 0.6655  loss_box_reg: 0.3797  loss_mask: 0.6941  loss_rpn_cls: 0.7077  loss_rpn_loc: 0.09745    time: 0.9861  last_time: 0.8883  data_time: 0.1255  last_data_time: 0.0069   lr: 4.9953e-06  max_mem: 5853M\n",
      "\u001b[32m[02/22 16:31:27 d2.utils.events]: \u001b[0m eta: 0:15:03  iter: 39  total_loss: 2.769  loss_cls: 0.5889  loss_box_reg: 0.4151  loss_mask: 0.6873  loss_rpn_cls: 0.8453  loss_rpn_loc: 0.1543    time: 0.9809  last_time: 1.0870  data_time: 0.0575  last_data_time: 0.1312   lr: 9.9902e-06  max_mem: 5853M\n",
      "\u001b[32m[02/22 16:31:48 d2.utils.events]: \u001b[0m eta: 0:15:04  iter: 59  total_loss: 2.332  loss_cls: 0.492  loss_box_reg: 0.464  loss_mask: 0.6759  loss_rpn_cls: 0.595  loss_rpn_loc: 0.1279    time: 1.0004  last_time: 1.2276  data_time: 0.0512  last_data_time: 0.0047   lr: 1.4985e-05  max_mem: 5853M\n",
      "\u001b[32m[02/22 16:32:12 d2.utils.events]: \u001b[0m eta: 0:15:14  iter: 79  total_loss: 2.043  loss_cls: 0.4178  loss_box_reg: 0.4769  loss_mask: 0.6541  loss_rpn_cls: 0.4149  loss_rpn_loc: 0.1036    time: 1.0545  last_time: 1.3437  data_time: 0.0325  last_data_time: 0.0037   lr: 1.998e-05  max_mem: 5853M\n",
      "\u001b[32m[02/22 16:32:36 d2.utils.events]: \u001b[0m eta: 0:15:40  iter: 99  total_loss: 1.985  loss_cls: 0.4131  loss_box_reg: 0.5309  loss_mask: 0.6256  loss_rpn_cls: 0.3181  loss_rpn_loc: 0.1274    time: 1.0888  last_time: 1.2517  data_time: 0.0279  last_data_time: 0.0052   lr: 2.4975e-05  max_mem: 5853M\n",
      "\u001b[32m[02/22 16:33:01 d2.utils.events]: \u001b[0m eta: 0:16:00  iter: 119  total_loss: 1.977  loss_cls: 0.4157  loss_box_reg: 0.5966  loss_mask: 0.6019  loss_rpn_cls: 0.3149  loss_rpn_loc: 0.1143    time: 1.1124  last_time: 1.1745  data_time: 0.0406  last_data_time: 0.0071   lr: 2.997e-05  max_mem: 5853M\n",
      "\u001b[32m[02/22 16:33:26 d2.utils.events]: \u001b[0m eta: 0:16:38  iter: 139  total_loss: 1.846  loss_cls: 0.3987  loss_box_reg: 0.5714  loss_mask: 0.5655  loss_rpn_cls: 0.2333  loss_rpn_loc: 0.1118    time: 1.1301  last_time: 1.2466  data_time: 0.0421  last_data_time: 0.0054   lr: 3.4965e-05  max_mem: 5853M\n",
      "\u001b[32m[02/22 16:33:50 d2.utils.events]: \u001b[0m eta: 0:16:36  iter: 159  total_loss: 1.949  loss_cls: 0.3982  loss_box_reg: 0.6044  loss_mask: 0.56  loss_rpn_cls: 0.2285  loss_rpn_loc: 0.1082    time: 1.1388  last_time: 1.2167  data_time: 0.0278  last_data_time: 0.0043   lr: 3.996e-05  max_mem: 5853M\n",
      "\u001b[32m[02/22 16:34:12 d2.utils.events]: \u001b[0m eta: 0:15:57  iter: 179  total_loss: 1.859  loss_cls: 0.3997  loss_box_reg: 0.7188  loss_mask: 0.5195  loss_rpn_cls: 0.1761  loss_rpn_loc: 0.1029    time: 1.1349  last_time: 1.1099  data_time: 0.0429  last_data_time: 0.1736   lr: 4.4955e-05  max_mem: 5853M\n",
      "\u001b[32m[02/22 16:34:34 d2.utils.events]: \u001b[0m eta: 0:15:19  iter: 199  total_loss: 1.87  loss_cls: 0.3916  loss_box_reg: 0.6893  loss_mask: 0.48  loss_rpn_cls: 0.1704  loss_rpn_loc: 0.1163    time: 1.1324  last_time: 1.0246  data_time: 0.1753  last_data_time: 0.0330   lr: 4.995e-05  max_mem: 5853M\n",
      "\u001b[32m[02/22 16:34:53 d2.utils.events]: \u001b[0m eta: 0:14:22  iter: 219  total_loss: 1.819  loss_cls: 0.3579  loss_box_reg: 0.6908  loss_mask: 0.4804  loss_rpn_cls: 0.1798  loss_rpn_loc: 0.1071    time: 1.1156  last_time: 0.9778  data_time: 0.0365  last_data_time: 0.0677   lr: 5.4945e-05  max_mem: 5853M\n",
      "\u001b[32m[02/22 16:35:12 d2.utils.events]: \u001b[0m eta: 0:13:29  iter: 239  total_loss: 1.764  loss_cls: 0.3402  loss_box_reg: 0.6884  loss_mask: 0.4405  loss_rpn_cls: 0.1648  loss_rpn_loc: 0.1032    time: 1.1023  last_time: 0.9785  data_time: 0.0296  last_data_time: 0.0031   lr: 5.994e-05  max_mem: 5853M\n",
      "\u001b[32m[02/22 16:35:32 d2.utils.events]: \u001b[0m eta: 0:12:52  iter: 259  total_loss: 1.661  loss_cls: 0.3159  loss_box_reg: 0.6989  loss_mask: 0.4441  loss_rpn_cls: 0.1409  loss_rpn_loc: 0.09564    time: 1.0898  last_time: 0.9665  data_time: 0.0251  last_data_time: 0.0801   lr: 6.4935e-05  max_mem: 5853M\n",
      "\u001b[32m[02/22 16:35:51 d2.utils.events]: \u001b[0m eta: 0:12:20  iter: 279  total_loss: 1.69  loss_cls: 0.312  loss_box_reg: 0.6555  loss_mask: 0.4214  loss_rpn_cls: 0.1488  loss_rpn_loc: 0.09759    time: 1.0792  last_time: 0.9251  data_time: 0.0304  last_data_time: 0.0039   lr: 6.993e-05  max_mem: 5853M\n",
      "\u001b[32m[02/22 16:36:10 d2.utils.events]: \u001b[0m eta: 0:11:51  iter: 299  total_loss: 1.69  loss_cls: 0.3098  loss_box_reg: 0.6685  loss_mask: 0.4051  loss_rpn_cls: 0.1236  loss_rpn_loc: 0.07897    time: 1.0720  last_time: 1.1450  data_time: 0.0471  last_data_time: 0.2205   lr: 7.4925e-05  max_mem: 5853M\n",
      "\u001b[32m[02/22 16:36:30 d2.utils.events]: \u001b[0m eta: 0:11:22  iter: 319  total_loss: 1.66  loss_cls: 0.2999  loss_box_reg: 0.7311  loss_mask: 0.3898  loss_rpn_cls: 0.154  loss_rpn_loc: 0.1116    time: 1.0655  last_time: 1.1851  data_time: 0.0154  last_data_time: 0.0282   lr: 7.992e-05  max_mem: 5853M\n",
      "\u001b[32m[02/22 16:36:55 d2.utils.events]: \u001b[0m eta: 0:11:15  iter: 339  total_loss: 1.77  loss_cls: 0.3145  loss_box_reg: 0.7535  loss_mask: 0.4062  loss_rpn_cls: 0.1273  loss_rpn_loc: 0.1099    time: 1.0764  last_time: 1.2148  data_time: 0.0618  last_data_time: 0.0068   lr: 8.4915e-05  max_mem: 5853M\n",
      "\u001b[32m[02/22 16:37:16 d2.utils.events]: \u001b[0m eta: 0:10:52  iter: 359  total_loss: 1.419  loss_cls: 0.2554  loss_box_reg: 0.637  loss_mask: 0.3308  loss_rpn_cls: 0.1186  loss_rpn_loc: 0.07383    time: 1.0743  last_time: 1.4313  data_time: 0.0654  last_data_time: 0.5090   lr: 8.991e-05  max_mem: 5853M\n",
      "\u001b[32m[02/22 16:37:35 d2.utils.events]: \u001b[0m eta: 0:10:24  iter: 379  total_loss: 1.471  loss_cls: 0.2563  loss_box_reg: 0.6266  loss_mask: 0.3371  loss_rpn_cls: 0.1201  loss_rpn_loc: 0.09651    time: 1.0681  last_time: 0.8844  data_time: 0.0320  last_data_time: 0.0051   lr: 9.4905e-05  max_mem: 5853M\n",
      "\u001b[32m[02/22 16:37:54 d2.utils.events]: \u001b[0m eta: 0:09:58  iter: 399  total_loss: 1.615  loss_cls: 0.2812  loss_box_reg: 0.6133  loss_mask: 0.3701  loss_rpn_cls: 0.1563  loss_rpn_loc: 0.1116    time: 1.0624  last_time: 0.9427  data_time: 0.0269  last_data_time: 0.0054   lr: 9.99e-05  max_mem: 5853M\n",
      "\u001b[32m[02/22 16:38:14 d2.utils.events]: \u001b[0m eta: 0:09:33  iter: 419  total_loss: 1.36  loss_cls: 0.2414  loss_box_reg: 0.5528  loss_mask: 0.3565  loss_rpn_cls: 0.1125  loss_rpn_loc: 0.09122    time: 1.0564  last_time: 0.8828  data_time: 0.0317  last_data_time: 0.0067   lr: 0.0001049  max_mem: 5853M\n",
      "\u001b[32m[02/22 16:38:33 d2.utils.events]: \u001b[0m eta: 0:09:08  iter: 439  total_loss: 1.541  loss_cls: 0.2681  loss_box_reg: 0.6619  loss_mask: 0.3226  loss_rpn_cls: 0.09882  loss_rpn_loc: 0.08558    time: 1.0529  last_time: 0.9689  data_time: 0.0612  last_data_time: 0.0285   lr: 0.00010989  max_mem: 5853M\n",
      "\u001b[32m[02/22 16:38:52 d2.utils.events]: \u001b[0m eta: 0:08:45  iter: 459  total_loss: 1.307  loss_cls: 0.227  loss_box_reg: 0.5247  loss_mask: 0.3008  loss_rpn_cls: 0.1024  loss_rpn_loc: 0.0653    time: 1.0473  last_time: 0.9100  data_time: 0.0180  last_data_time: 0.0051   lr: 0.00011489  max_mem: 5853M\n",
      "\u001b[32m[02/22 16:39:12 d2.utils.events]: \u001b[0m eta: 0:08:25  iter: 479  total_loss: 1.417  loss_cls: 0.2739  loss_box_reg: 0.5931  loss_mask: 0.3415  loss_rpn_cls: 0.1133  loss_rpn_loc: 0.09596    time: 1.0445  last_time: 0.9460  data_time: 0.0539  last_data_time: 0.0047   lr: 0.00011988  max_mem: 5853M\n",
      "\u001b[32m[02/22 16:39:30 d2.utils.events]: \u001b[0m eta: 0:08:03  iter: 499  total_loss: 1.367  loss_cls: 0.2749  loss_box_reg: 0.5361  loss_mask: 0.325  loss_rpn_cls: 0.1046  loss_rpn_loc: 0.07576    time: 1.0403  last_time: 0.9226  data_time: 0.0199  last_data_time: 0.0056   lr: 0.00012488  max_mem: 5853M\n",
      "\u001b[32m[02/22 16:39:49 d2.utils.events]: \u001b[0m eta: 0:07:43  iter: 519  total_loss: 1.288  loss_cls: 0.2457  loss_box_reg: 0.489  loss_mask: 0.3132  loss_rpn_cls: 0.09359  loss_rpn_loc: 0.07447    time: 1.0367  last_time: 0.9029  data_time: 0.0233  last_data_time: 0.0047   lr: 0.00012987  max_mem: 5853M\n",
      "\u001b[32m[02/22 16:40:09 d2.utils.events]: \u001b[0m eta: 0:07:23  iter: 539  total_loss: 1.389  loss_cls: 0.2629  loss_box_reg: 0.5428  loss_mask: 0.3167  loss_rpn_cls: 0.1183  loss_rpn_loc: 0.1197    time: 1.0343  last_time: 0.9602  data_time: 0.0386  last_data_time: 0.0048   lr: 0.00013487  max_mem: 5853M\n",
      "\u001b[32m[02/22 16:40:28 d2.utils.events]: \u001b[0m eta: 0:07:04  iter: 559  total_loss: 1.281  loss_cls: 0.243  loss_box_reg: 0.5184  loss_mask: 0.3003  loss_rpn_cls: 0.1051  loss_rpn_loc: 0.0939    time: 1.0316  last_time: 0.9159  data_time: 0.0463  last_data_time: 0.0052   lr: 0.00013986  max_mem: 5853M\n",
      "\u001b[32m[02/22 16:40:47 d2.utils.events]: \u001b[0m eta: 0:06:44  iter: 579  total_loss: 1.274  loss_cls: 0.2313  loss_box_reg: 0.4784  loss_mask: 0.3091  loss_rpn_cls: 0.0965  loss_rpn_loc: 0.1069    time: 1.0286  last_time: 0.9479  data_time: 0.0235  last_data_time: 0.0028   lr: 0.00014486  max_mem: 5853M\n",
      "\u001b[32m[02/22 16:41:06 d2.utils.events]: \u001b[0m eta: 0:06:24  iter: 599  total_loss: 1.108  loss_cls: 0.2041  loss_box_reg: 0.4479  loss_mask: 0.3106  loss_rpn_cls: 0.08943  loss_rpn_loc: 0.06953    time: 1.0254  last_time: 0.9161  data_time: 0.0229  last_data_time: 0.0046   lr: 0.00014985  max_mem: 5853M\n",
      "\u001b[32m[02/22 16:41:24 d2.utils.events]: \u001b[0m eta: 0:06:04  iter: 619  total_loss: 1.213  loss_cls: 0.2448  loss_box_reg: 0.4844  loss_mask: 0.3043  loss_rpn_cls: 0.109  loss_rpn_loc: 0.08753    time: 1.0227  last_time: 1.0038  data_time: 0.0254  last_data_time: 0.0903   lr: 0.00015485  max_mem: 5853M\n",
      "\u001b[32m[02/22 16:41:44 d2.utils.events]: \u001b[0m eta: 0:05:44  iter: 639  total_loss: 1.2  loss_cls: 0.2265  loss_box_reg: 0.4878  loss_mask: 0.2992  loss_rpn_cls: 0.09443  loss_rpn_loc: 0.09128    time: 1.0206  last_time: 0.9178  data_time: 0.0376  last_data_time: 0.0048   lr: 0.00015984  max_mem: 5853M\n",
      "\u001b[32m[02/22 16:42:02 d2.utils.events]: \u001b[0m eta: 0:05:25  iter: 659  total_loss: 1.299  loss_cls: 0.2577  loss_box_reg: 0.5008  loss_mask: 0.3177  loss_rpn_cls: 0.1046  loss_rpn_loc: 0.08943    time: 1.0182  last_time: 0.9020  data_time: 0.0281  last_data_time: 0.0042   lr: 0.00016484  max_mem: 5853M\n",
      "\u001b[32m[02/22 16:42:21 d2.utils.events]: \u001b[0m eta: 0:05:05  iter: 679  total_loss: 1.041  loss_cls: 0.2172  loss_box_reg: 0.391  loss_mask: 0.2899  loss_rpn_cls: 0.06885  loss_rpn_loc: 0.07219    time: 1.0153  last_time: 0.8487  data_time: 0.0119  last_data_time: 0.0058   lr: 0.00016983  max_mem: 5853M\n",
      "\u001b[32m[02/22 16:42:40 d2.utils.events]: \u001b[0m eta: 0:04:46  iter: 699  total_loss: 1.227  loss_cls: 0.2337  loss_box_reg: 0.4607  loss_mask: 0.3102  loss_rpn_cls: 0.09282  loss_rpn_loc: 0.09178    time: 1.0131  last_time: 0.9077  data_time: 0.0362  last_data_time: 0.0036   lr: 0.00017483  max_mem: 5853M\n",
      "\u001b[32m[02/22 16:42:59 d2.utils.events]: \u001b[0m eta: 0:04:27  iter: 719  total_loss: 1.099  loss_cls: 0.219  loss_box_reg: 0.4135  loss_mask: 0.2708  loss_rpn_cls: 0.06935  loss_rpn_loc: 0.0756    time: 1.0124  last_time: 0.9403  data_time: 0.0628  last_data_time: 0.0053   lr: 0.00017982  max_mem: 5853M\n",
      "\u001b[32m[02/22 16:43:19 d2.utils.events]: \u001b[0m eta: 0:04:08  iter: 739  total_loss: 1.204  loss_cls: 0.2486  loss_box_reg: 0.487  loss_mask: 0.3002  loss_rpn_cls: 0.09086  loss_rpn_loc: 0.09314    time: 1.0115  last_time: 0.9288  data_time: 0.0654  last_data_time: 0.0059   lr: 0.00018482  max_mem: 5853M\n",
      "\u001b[32m[02/22 16:43:38 d2.utils.events]: \u001b[0m eta: 0:03:49  iter: 759  total_loss: 1.056  loss_cls: 0.2011  loss_box_reg: 0.4089  loss_mask: 0.2827  loss_rpn_cls: 0.05534  loss_rpn_loc: 0.07902    time: 1.0098  last_time: 0.9577  data_time: 0.0230  last_data_time: 0.0058   lr: 0.00018981  max_mem: 5853M\n",
      "\u001b[32m[02/22 16:43:57 d2.utils.events]: \u001b[0m eta: 0:03:29  iter: 779  total_loss: 1.1  loss_cls: 0.2077  loss_box_reg: 0.4355  loss_mask: 0.2824  loss_rpn_cls: 0.08731  loss_rpn_loc: 0.08864    time: 1.0085  last_time: 0.8925  data_time: 0.0400  last_data_time: 0.0049   lr: 0.00019481  max_mem: 5853M\n",
      "\u001b[32m[02/22 16:44:17 d2.utils.events]: \u001b[0m eta: 0:03:10  iter: 799  total_loss: 1.142  loss_cls: 0.2333  loss_box_reg: 0.4701  loss_mask: 0.3019  loss_rpn_cls: 0.06279  loss_rpn_loc: 0.08396    time: 1.0084  last_time: 0.9636  data_time: 0.0762  last_data_time: 0.0056   lr: 0.0001998  max_mem: 5853M\n",
      "\u001b[32m[02/22 16:44:39 d2.utils.events]: \u001b[0m eta: 0:02:51  iter: 819  total_loss: 1.072  loss_cls: 0.2141  loss_box_reg: 0.4323  loss_mask: 0.2809  loss_rpn_cls: 0.07645  loss_rpn_loc: 0.07732    time: 1.0108  last_time: 0.8829  data_time: 0.1735  last_data_time: 0.0030   lr: 0.0002048  max_mem: 5853M\n",
      "\u001b[32m[02/22 16:45:00 d2.utils.events]: \u001b[0m eta: 0:02:32  iter: 839  total_loss: 1.042  loss_cls: 0.1892  loss_box_reg: 0.4143  loss_mask: 0.2859  loss_rpn_cls: 0.06242  loss_rpn_loc: 0.08154    time: 1.0112  last_time: 0.8876  data_time: 0.0916  last_data_time: 0.0039   lr: 0.00020979  max_mem: 5853M\n",
      "\u001b[32m[02/22 16:45:19 d2.utils.events]: \u001b[0m eta: 0:02:13  iter: 859  total_loss: 1.074  loss_cls: 0.199  loss_box_reg: 0.4442  loss_mask: 0.2942  loss_rpn_cls: 0.06187  loss_rpn_loc: 0.08747    time: 1.0100  last_time: 0.9058  data_time: 0.0448  last_data_time: 0.0038   lr: 0.00021479  max_mem: 5853M\n",
      "\u001b[32m[02/22 16:45:39 d2.utils.events]: \u001b[0m eta: 0:01:54  iter: 879  total_loss: 1.029  loss_cls: 0.1955  loss_box_reg: 0.4058  loss_mask: 0.269  loss_rpn_cls: 0.0731  loss_rpn_loc: 0.07391    time: 1.0090  last_time: 0.9219  data_time: 0.0496  last_data_time: 0.0031   lr: 0.00021978  max_mem: 5853M\n",
      "\u001b[32m[02/22 16:45:58 d2.utils.events]: \u001b[0m eta: 0:01:35  iter: 899  total_loss: 1.121  loss_cls: 0.2318  loss_box_reg: 0.4581  loss_mask: 0.2894  loss_rpn_cls: 0.07789  loss_rpn_loc: 0.07944    time: 1.0081  last_time: 0.9139  data_time: 0.0377  last_data_time: 0.0057   lr: 0.00022478  max_mem: 5853M\n",
      "\u001b[32m[02/22 16:46:18 d2.utils.events]: \u001b[0m eta: 0:01:16  iter: 919  total_loss: 1.009  loss_cls: 0.1843  loss_box_reg: 0.3823  loss_mask: 0.261  loss_rpn_cls: 0.06625  loss_rpn_loc: 0.0833    time: 1.0074  last_time: 0.9524  data_time: 0.0412  last_data_time: 0.0061   lr: 0.00022977  max_mem: 5853M\n",
      "\u001b[32m[02/22 16:46:37 d2.utils.events]: \u001b[0m eta: 0:00:57  iter: 939  total_loss: 1.054  loss_cls: 0.2136  loss_box_reg: 0.4016  loss_mask: 0.2769  loss_rpn_cls: 0.07009  loss_rpn_loc: 0.07819    time: 1.0067  last_time: 0.9183  data_time: 0.0484  last_data_time: 0.0038   lr: 0.00023477  max_mem: 5853M\n",
      "\u001b[32m[02/22 16:46:56 d2.utils.events]: \u001b[0m eta: 0:00:38  iter: 959  total_loss: 1.102  loss_cls: 0.2034  loss_box_reg: 0.4398  loss_mask: 0.2936  loss_rpn_cls: 0.06502  loss_rpn_loc: 0.092    time: 1.0055  last_time: 0.8881  data_time: 0.0333  last_data_time: 0.0042   lr: 0.00023976  max_mem: 5853M\n",
      "\u001b[32m[02/22 16:47:17 d2.utils.events]: \u001b[0m eta: 0:00:19  iter: 979  total_loss: 0.986  loss_cls: 0.1815  loss_box_reg: 0.3944  loss_mask: 0.2513  loss_rpn_cls: 0.0658  loss_rpn_loc: 0.09063    time: 1.0068  last_time: 1.2243  data_time: 0.1107  last_data_time: 0.2786   lr: 0.00024476  max_mem: 5853M\n",
      "\u001b[32m[02/22 16:47:39 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 999  total_loss: 0.9842  loss_cls: 0.1934  loss_box_reg: 0.4207  loss_mask: 0.2671  loss_rpn_cls: 0.04898  loss_rpn_loc: 0.07987    time: 1.0073  last_time: 1.0294  data_time: 0.0459  last_data_time: 0.0036   lr: 0.00024975  max_mem: 5853M\n",
      "\u001b[32m[02/22 16:47:39 d2.engine.hooks]: \u001b[0mOverall training speed: 998 iterations in 0:16:45 (1.0073 s / it)\n",
      "\u001b[32m[02/22 16:47:39 d2.engine.hooks]: \u001b[0mTotal training time: 0:16:49 (0:00:04 on hooks)\n",
      "\u001b[32m[02/22 16:47:39 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/22 16:47:39 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[02/22 16:47:39 d2.data.common]: \u001b[0mSerializing 23 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/22 16:47:39 d2.data.common]: \u001b[0mSerialized dataset takes 0.29 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[02/22 16:47:39 d2.engine.defaults]: \u001b[0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.\n",
      "Finished training mask_rcnn_R_50_C4_3x. Model saved in /home/etaylor/code_projects/thesis/checkpoints/stigmas_segmentation/detectron2/fine_tuned/mask_rcnn_R_50_C4_3x\n",
      "Evaluating mask_rcnn_R_50_C4_3x...\n",
      "\u001b[32m[02/22 16:47:40 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from /home/etaylor/code_projects/thesis/checkpoints/stigmas_segmentation/detectron2/fine_tuned/mask_rcnn_R_50_C4_3x/model_final.pth ...\n",
      "\u001b[32m[02/22 16:47:41 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n",
      "\u001b[32m[02/22 16:47:41 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/22 16:47:41 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[02/22 16:47:41 d2.data.common]: \u001b[0mSerializing 23 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/22 16:47:41 d2.data.common]: \u001b[0mSerialized dataset takes 0.29 MiB\n",
      "\u001b[32m[02/22 16:47:41 d2.evaluation.evaluator]: \u001b[0mStart inference on 23 batches\n",
      "\u001b[32m[02/22 16:48:06 d2.evaluation.evaluator]: \u001b[0mInference done 11/23. Dataloading: 0.0012 s/iter. Inference: 0.9219 s/iter. Eval: 1.7763 s/iter. Total: 2.6993 s/iter. ETA=0:00:32\n",
      "\u001b[32m[02/22 16:48:12 d2.evaluation.evaluator]: \u001b[0mInference done 18/23. Dataloading: 0.0011 s/iter. Inference: 0.6020 s/iter. Eval: 1.0961 s/iter. Total: 1.6994 s/iter. ETA=0:00:08\n",
      "\u001b[32m[02/22 16:48:17 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:27.015509 (1.500862 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/22 16:48:17 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:09 (0.527423 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/22 16:48:17 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[02/22 16:48:17 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to /home/etaylor/code_projects/thesis/checkpoints/stigmas_segmentation/detectron2/fine_tuned/mask_rcnn_R_50_C4_3x/coco_instances_results.json\n",
      "\u001b[32m[02/22 16:48:17 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.12s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.301\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.632\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.246\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.303\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.073\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.384\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.505\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.509\n",
      "\u001b[32m[02/22 16:48:17 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
      "| 30.109 | 63.205 | 24.597 |  nan  | 0.000 | 30.321 |\n",
      "\u001b[32m[02/22 16:48:17 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *segm*\n",
      "DONE (t=0.16s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.105\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.379\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.010\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.105\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.035\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.186\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.245\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.247\n",
      "\u001b[32m[02/22 16:48:17 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
      "| 10.451 | 37.944 | 1.030  |  nan  | 0.000 | 10.530 |\n",
      "\u001b[32m[02/22 16:48:17 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
      "Evaluation completed. Results saved in /home/etaylor/code_projects/thesis/checkpoints/stigmas_segmentation/detectron2/fine_tuned/mask_rcnn_R_50_C4_3x/evaluation/eval_results.json\n",
      "Processing mask_rcnn_R_50_DC5_3x...\n",
      "Training mask_rcnn_R_50_DC5_3x...\n",
      "\u001b[32m[02/22 16:48:19 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): ResNet(\n",
      "    (stem): BasicStem(\n",
      "      (conv1): Conv2d(\n",
      "        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "      )\n",
      "    )\n",
      "    (res2): Sequential(\n",
      "      (0): BottleneckBlock(\n",
      "        (shortcut): Conv2d(\n",
      "          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv1): Conv2d(\n",
      "          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (1): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (2): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (res3): Sequential(\n",
      "      (0): BottleneckBlock(\n",
      "        (shortcut): Conv2d(\n",
      "          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "        (conv1): Conv2d(\n",
      "          256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (1): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (2): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (3): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (res4): Sequential(\n",
      "      (0): BottleneckBlock(\n",
      "        (shortcut): Conv2d(\n",
      "          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "        (conv1): Conv2d(\n",
      "          512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (1): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (2): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (3): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (4): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (5): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (res5): Sequential(\n",
      "      (0): BottleneckBlock(\n",
      "        (shortcut): Conv2d(\n",
      "          1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "        )\n",
      "        (conv1): Conv2d(\n",
      "          1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (1): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (2): BottleneckBlock(\n",
      "        (conv1): Conv2d(\n",
      "          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "        (conv2): Conv2d(\n",
      "          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "        )\n",
      "        (conv3): Conv2d(\n",
      "          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(2048, 15, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(2048, 60, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=100352, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=2, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[02/22 16:48:19 d2.data.build]: \u001b[0mRemoved 3 images with no usable annotations. 89 images left.\n",
      "\u001b[32m[02/22 16:48:19 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[02/22 16:48:19 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[02/22 16:48:19 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[02/22 16:48:19 d2.data.common]: \u001b[0mSerializing 89 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/22 16:48:19 d2.data.common]: \u001b[0mSerialized dataset takes 1.35 MiB\n",
      "\u001b[32m[02/22 16:48:19 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from https://dl.fbaipublicfiles.com/detectron2/COCO-InstanceSegmentation/mask_rcnn_R_50_DC5_3x/137849551/model_final_84107b.pkl ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (2, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (2,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (4, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (4,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (1, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (1,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.mask_head.predictor.{bias, weight}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[02/22 16:48:36 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/etaylor/.conda/envs/detectron_fastai/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
      "/home/etaylor/.conda/envs/detectron_fastai/lib/python3.9/site-packages/detectron2/data/detection_utils.py:446: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)\n",
      "  torch.stack([torch.from_numpy(np.ascontiguousarray(x)) for x in masks])\n",
      "/home/etaylor/.conda/envs/detectron_fastai/lib/python3.9/site-packages/detectron2/data/detection_utils.py:446: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)\n",
      "  torch.stack([torch.from_numpy(np.ascontiguousarray(x)) for x in masks])\n",
      "/home/etaylor/.conda/envs/detectron_fastai/lib/python3.9/site-packages/detectron2/data/detection_utils.py:446: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)\n",
      "  torch.stack([torch.from_numpy(np.ascontiguousarray(x)) for x in masks])\n",
      "/home/etaylor/.conda/envs/detectron_fastai/lib/python3.9/site-packages/detectron2/data/detection_utils.py:446: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)\n",
      "  torch.stack([torch.from_numpy(np.ascontiguousarray(x)) for x in masks])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[02/22 16:48:56 d2.utils.events]: \u001b[0m eta: 0:13:48  iter: 19  total_loss: 4.084  loss_cls: 0.7874  loss_box_reg: 0.2366  loss_mask: 0.6961  loss_rpn_cls: 2.016  loss_rpn_loc: 0.1529    time: 0.9491  last_time: 0.8947  data_time: 0.2318  last_data_time: 0.0035   lr: 4.9953e-06  max_mem: 6082M\n",
      "\u001b[32m[02/22 16:49:13 d2.utils.events]: \u001b[0m eta: 0:13:31  iter: 39  total_loss: 3.023  loss_cls: 0.6483  loss_box_reg: 0.3048  loss_mask: 0.6895  loss_rpn_cls: 1.148  loss_rpn_loc: 0.1157    time: 0.8884  last_time: 0.8570  data_time: 0.0355  last_data_time: 0.0053   lr: 9.9902e-06  max_mem: 6082M\n",
      "\u001b[32m[02/22 16:49:31 d2.utils.events]: \u001b[0m eta: 0:13:19  iter: 59  total_loss: 2.589  loss_cls: 0.5202  loss_box_reg: 0.4703  loss_mask: 0.6749  loss_rpn_cls: 0.7492  loss_rpn_loc: 0.1144    time: 0.8919  last_time: 0.8550  data_time: 0.0659  last_data_time: 0.0602   lr: 1.4985e-05  max_mem: 6196M\n",
      "\u001b[32m[02/22 16:49:50 d2.utils.events]: \u001b[0m eta: 0:13:14  iter: 79  total_loss: 2.291  loss_cls: 0.4537  loss_box_reg: 0.5557  loss_mask: 0.6609  loss_rpn_cls: 0.4633  loss_rpn_loc: 0.129    time: 0.9047  last_time: 0.9387  data_time: 0.0635  last_data_time: 0.0206   lr: 1.998e-05  max_mem: 6492M\n",
      "\u001b[32m[02/22 16:50:08 d2.utils.events]: \u001b[0m eta: 0:12:57  iter: 99  total_loss: 2.135  loss_cls: 0.4324  loss_box_reg: 0.5924  loss_mask: 0.6322  loss_rpn_cls: 0.3547  loss_rpn_loc: 0.08215    time: 0.9018  last_time: 0.8448  data_time: 0.0314  last_data_time: 0.0056   lr: 2.4975e-05  max_mem: 6492M\n",
      "\u001b[32m[02/22 16:50:26 d2.utils.events]: \u001b[0m eta: 0:12:41  iter: 119  total_loss: 1.997  loss_cls: 0.4055  loss_box_reg: 0.5848  loss_mask: 0.6179  loss_rpn_cls: 0.2919  loss_rpn_loc: 0.09497    time: 0.9050  last_time: 0.8739  data_time: 0.0507  last_data_time: 0.0047   lr: 2.997e-05  max_mem: 6518M\n",
      "\u001b[32m[02/22 16:50:43 d2.utils.events]: \u001b[0m eta: 0:12:22  iter: 139  total_loss: 2.104  loss_cls: 0.4098  loss_box_reg: 0.6748  loss_mask: 0.6008  loss_rpn_cls: 0.2522  loss_rpn_loc: 0.1101    time: 0.9003  last_time: 0.8209  data_time: 0.0422  last_data_time: 0.0049   lr: 3.4965e-05  max_mem: 6518M\n",
      "\u001b[32m[02/22 16:51:02 d2.utils.events]: \u001b[0m eta: 0:12:05  iter: 159  total_loss: 1.968  loss_cls: 0.4119  loss_box_reg: 0.6744  loss_mask: 0.5667  loss_rpn_cls: 0.2448  loss_rpn_loc: 0.08841    time: 0.9017  last_time: 0.7357  data_time: 0.0619  last_data_time: 0.0064   lr: 3.996e-05  max_mem: 6518M\n",
      "\u001b[32m[02/22 16:51:20 d2.utils.events]: \u001b[0m eta: 0:11:48  iter: 179  total_loss: 1.919  loss_cls: 0.4033  loss_box_reg: 0.6397  loss_mask: 0.5376  loss_rpn_cls: 0.1803  loss_rpn_loc: 0.1103    time: 0.9007  last_time: 0.8554  data_time: 0.0291  last_data_time: 0.0052   lr: 4.4955e-05  max_mem: 6518M\n",
      "\u001b[32m[02/22 16:51:38 d2.utils.events]: \u001b[0m eta: 0:11:31  iter: 199  total_loss: 1.906  loss_cls: 0.3743  loss_box_reg: 0.6696  loss_mask: 0.5126  loss_rpn_cls: 0.1866  loss_rpn_loc: 0.09432    time: 0.9004  last_time: 0.7408  data_time: 0.0528  last_data_time: 0.0037   lr: 4.995e-05  max_mem: 6518M\n",
      "\u001b[32m[02/22 16:51:56 d2.utils.events]: \u001b[0m eta: 0:11:15  iter: 219  total_loss: 1.967  loss_cls: 0.409  loss_box_reg: 0.7275  loss_mask: 0.4985  loss_rpn_cls: 0.1749  loss_rpn_loc: 0.08448    time: 0.9010  last_time: 0.9564  data_time: 0.0581  last_data_time: 0.0034   lr: 5.4945e-05  max_mem: 6518M\n",
      "\u001b[32m[02/22 16:52:14 d2.utils.events]: \u001b[0m eta: 0:10:58  iter: 239  total_loss: 1.974  loss_cls: 0.4138  loss_box_reg: 0.839  loss_mask: 0.4606  loss_rpn_cls: 0.1572  loss_rpn_loc: 0.09218    time: 0.9028  last_time: 1.2605  data_time: 0.0621  last_data_time: 0.2733   lr: 5.994e-05  max_mem: 6545M\n",
      "\u001b[32m[02/22 16:52:32 d2.utils.events]: \u001b[0m eta: 0:10:40  iter: 259  total_loss: 1.72  loss_cls: 0.3467  loss_box_reg: 0.666  loss_mask: 0.4509  loss_rpn_cls: 0.09841  loss_rpn_loc: 0.076    time: 0.9019  last_time: 0.8577  data_time: 0.0518  last_data_time: 0.0039   lr: 6.4935e-05  max_mem: 6550M\n",
      "\u001b[32m[02/22 16:52:50 d2.utils.events]: \u001b[0m eta: 0:10:23  iter: 279  total_loss: 1.609  loss_cls: 0.3137  loss_box_reg: 0.6327  loss_mask: 0.4495  loss_rpn_cls: 0.13  loss_rpn_loc: 0.09907    time: 0.9010  last_time: 0.9352  data_time: 0.0555  last_data_time: 0.0917   lr: 6.993e-05  max_mem: 6627M\n",
      "\u001b[32m[02/22 16:53:08 d2.utils.events]: \u001b[0m eta: 0:10:06  iter: 299  total_loss: 1.685  loss_cls: 0.3279  loss_box_reg: 0.7143  loss_mask: 0.4444  loss_rpn_cls: 0.1278  loss_rpn_loc: 0.1023    time: 0.9004  last_time: 0.8662  data_time: 0.0547  last_data_time: 0.0066   lr: 7.4925e-05  max_mem: 6627M\n",
      "\u001b[32m[02/22 16:53:26 d2.utils.events]: \u001b[0m eta: 0:09:49  iter: 319  total_loss: 1.675  loss_cls: 0.327  loss_box_reg: 0.7122  loss_mask: 0.4205  loss_rpn_cls: 0.1206  loss_rpn_loc: 0.08217    time: 0.9007  last_time: 0.8214  data_time: 0.0530  last_data_time: 0.0974   lr: 7.992e-05  max_mem: 6627M\n",
      "\u001b[32m[02/22 16:53:43 d2.utils.events]: \u001b[0m eta: 0:09:35  iter: 339  total_loss: 1.618  loss_cls: 0.3195  loss_box_reg: 0.6793  loss_mask: 0.4315  loss_rpn_cls: 0.1109  loss_rpn_loc: 0.09095    time: 0.8995  last_time: 0.8862  data_time: 0.0339  last_data_time: 0.0045   lr: 8.4915e-05  max_mem: 6627M\n",
      "\u001b[32m[02/22 16:54:01 d2.utils.events]: \u001b[0m eta: 0:09:18  iter: 359  total_loss: 1.713  loss_cls: 0.3198  loss_box_reg: 0.7592  loss_mask: 0.3888  loss_rpn_cls: 0.1117  loss_rpn_loc: 0.09454    time: 0.8991  last_time: 0.8368  data_time: 0.0164  last_data_time: 0.0364   lr: 8.991e-05  max_mem: 6627M\n",
      "\u001b[32m[02/22 16:54:20 d2.utils.events]: \u001b[0m eta: 0:09:01  iter: 379  total_loss: 1.539  loss_cls: 0.2937  loss_box_reg: 0.6932  loss_mask: 0.3859  loss_rpn_cls: 0.1186  loss_rpn_loc: 0.08545    time: 0.8995  last_time: 0.8407  data_time: 0.0489  last_data_time: 0.0030   lr: 9.4905e-05  max_mem: 6663M\n",
      "\u001b[32m[02/22 16:54:39 d2.utils.events]: \u001b[0m eta: 0:08:46  iter: 399  total_loss: 1.624  loss_cls: 0.2992  loss_box_reg: 0.6853  loss_mask: 0.3713  loss_rpn_cls: 0.09214  loss_rpn_loc: 0.08631    time: 0.9029  last_time: 0.9467  data_time: 0.0856  last_data_time: 0.0166   lr: 9.99e-05  max_mem: 6663M\n",
      "\u001b[32m[02/22 16:54:57 d2.utils.events]: \u001b[0m eta: 0:08:28  iter: 419  total_loss: 1.455  loss_cls: 0.2695  loss_box_reg: 0.6352  loss_mask: 0.3705  loss_rpn_cls: 0.08446  loss_rpn_loc: 0.1    time: 0.9028  last_time: 0.9366  data_time: 0.0453  last_data_time: 0.0584   lr: 0.0001049  max_mem: 6663M\n",
      "\u001b[32m[02/22 16:55:15 d2.utils.events]: \u001b[0m eta: 0:08:11  iter: 439  total_loss: 1.389  loss_cls: 0.2672  loss_box_reg: 0.6023  loss_mask: 0.3305  loss_rpn_cls: 0.07143  loss_rpn_loc: 0.08756    time: 0.9032  last_time: 0.9292  data_time: 0.0372  last_data_time: 0.0034   lr: 0.00010989  max_mem: 6663M\n",
      "\u001b[32m[02/22 16:55:33 d2.utils.events]: \u001b[0m eta: 0:07:54  iter: 459  total_loss: 1.501  loss_cls: 0.2837  loss_box_reg: 0.6398  loss_mask: 0.3494  loss_rpn_cls: 0.0815  loss_rpn_loc: 0.1025    time: 0.9033  last_time: 0.8271  data_time: 0.0526  last_data_time: 0.0444   lr: 0.00011489  max_mem: 6663M\n",
      "\u001b[32m[02/22 16:55:52 d2.utils.events]: \u001b[0m eta: 0:07:38  iter: 479  total_loss: 1.388  loss_cls: 0.2788  loss_box_reg: 0.6005  loss_mask: 0.3225  loss_rpn_cls: 0.07781  loss_rpn_loc: 0.1071    time: 0.9042  last_time: 0.9830  data_time: 0.0474  last_data_time: 0.0043   lr: 0.00011988  max_mem: 6663M\n",
      "\u001b[32m[02/22 16:56:11 d2.utils.events]: \u001b[0m eta: 0:07:20  iter: 499  total_loss: 1.379  loss_cls: 0.2797  loss_box_reg: 0.5459  loss_mask: 0.3368  loss_rpn_cls: 0.07912  loss_rpn_loc: 0.08384    time: 0.9044  last_time: 0.8620  data_time: 0.0584  last_data_time: 0.0027   lr: 0.00012488  max_mem: 6663M\n",
      "\u001b[32m[02/22 16:56:29 d2.utils.events]: \u001b[0m eta: 0:07:02  iter: 519  total_loss: 1.171  loss_cls: 0.2005  loss_box_reg: 0.5182  loss_mask: 0.3219  loss_rpn_cls: 0.06185  loss_rpn_loc: 0.06923    time: 0.9031  last_time: 0.8817  data_time: 0.0367  last_data_time: 0.0023   lr: 0.00012987  max_mem: 6663M\n",
      "\u001b[32m[02/22 16:56:47 d2.utils.events]: \u001b[0m eta: 0:06:45  iter: 539  total_loss: 1.232  loss_cls: 0.2436  loss_box_reg: 0.5153  loss_mask: 0.3212  loss_rpn_cls: 0.09226  loss_rpn_loc: 0.08315    time: 0.9038  last_time: 0.8285  data_time: 0.0627  last_data_time: 0.0048   lr: 0.00013487  max_mem: 6663M\n",
      "\u001b[32m[02/22 16:57:06 d2.utils.events]: \u001b[0m eta: 0:06:27  iter: 559  total_loss: 1.222  loss_cls: 0.2411  loss_box_reg: 0.5229  loss_mask: 0.3351  loss_rpn_cls: 0.0682  loss_rpn_loc: 0.072    time: 0.9042  last_time: 0.8615  data_time: 0.0611  last_data_time: 0.0069   lr: 0.00013986  max_mem: 6663M\n",
      "\u001b[32m[02/22 16:57:25 d2.utils.events]: \u001b[0m eta: 0:06:10  iter: 579  total_loss: 1.161  loss_cls: 0.2265  loss_box_reg: 0.5132  loss_mask: 0.3072  loss_rpn_cls: 0.05607  loss_rpn_loc: 0.0532    time: 0.9059  last_time: 0.8145  data_time: 0.1059  last_data_time: 0.0295   lr: 0.00014486  max_mem: 6663M\n",
      "\u001b[32m[02/22 16:57:42 d2.utils.events]: \u001b[0m eta: 0:05:52  iter: 599  total_loss: 1.131  loss_cls: 0.2217  loss_box_reg: 0.4809  loss_mask: 0.3313  loss_rpn_cls: 0.04444  loss_rpn_loc: 0.07762    time: 0.9045  last_time: 0.8561  data_time: 0.0388  last_data_time: 0.0044   lr: 0.00014985  max_mem: 6663M\n",
      "\u001b[32m[02/22 16:58:00 d2.utils.events]: \u001b[0m eta: 0:05:35  iter: 619  total_loss: 1.331  loss_cls: 0.2517  loss_box_reg: 0.5438  loss_mask: 0.3033  loss_rpn_cls: 0.07  loss_rpn_loc: 0.1047    time: 0.9051  last_time: 0.9490  data_time: 0.0570  last_data_time: 0.1365   lr: 0.00015485  max_mem: 6663M\n",
      "\u001b[32m[02/22 16:58:20 d2.utils.events]: \u001b[0m eta: 0:05:17  iter: 639  total_loss: 1.314  loss_cls: 0.2644  loss_box_reg: 0.5441  loss_mask: 0.3144  loss_rpn_cls: 0.05268  loss_rpn_loc: 0.1006    time: 0.9070  last_time: 0.8790  data_time: 0.0718  last_data_time: 0.0844   lr: 0.00015984  max_mem: 6663M\n",
      "\u001b[32m[02/22 16:58:38 d2.utils.events]: \u001b[0m eta: 0:05:00  iter: 659  total_loss: 1.189  loss_cls: 0.2288  loss_box_reg: 0.4951  loss_mask: 0.2897  loss_rpn_cls: 0.0459  loss_rpn_loc: 0.08803    time: 0.9071  last_time: 0.9413  data_time: 0.0303  last_data_time: 0.0072   lr: 0.00016484  max_mem: 6663M\n",
      "\u001b[32m[02/22 16:58:56 d2.utils.events]: \u001b[0m eta: 0:04:42  iter: 679  total_loss: 1.056  loss_cls: 0.2118  loss_box_reg: 0.4487  loss_mask: 0.3018  loss_rpn_cls: 0.04699  loss_rpn_loc: 0.06728    time: 0.9068  last_time: 0.8433  data_time: 0.0486  last_data_time: 0.0041   lr: 0.00016983  max_mem: 6663M\n",
      "\u001b[32m[02/22 16:59:14 d2.utils.events]: \u001b[0m eta: 0:04:25  iter: 699  total_loss: 1.168  loss_cls: 0.2303  loss_box_reg: 0.5204  loss_mask: 0.2956  loss_rpn_cls: 0.06625  loss_rpn_loc: 0.07098    time: 0.9069  last_time: 0.8635  data_time: 0.0405  last_data_time: 0.0037   lr: 0.00017483  max_mem: 6663M\n",
      "\u001b[32m[02/22 16:59:32 d2.utils.events]: \u001b[0m eta: 0:04:07  iter: 719  total_loss: 1.106  loss_cls: 0.2167  loss_box_reg: 0.4649  loss_mask: 0.3128  loss_rpn_cls: 0.04092  loss_rpn_loc: 0.06597    time: 0.9069  last_time: 1.0759  data_time: 0.0653  last_data_time: 0.1491   lr: 0.00017982  max_mem: 6663M\n",
      "\u001b[32m[02/22 16:59:51 d2.utils.events]: \u001b[0m eta: 0:03:50  iter: 739  total_loss: 1.07  loss_cls: 0.1962  loss_box_reg: 0.4593  loss_mask: 0.2941  loss_rpn_cls: 0.0429  loss_rpn_loc: 0.07141    time: 0.9074  last_time: 1.1206  data_time: 0.0808  last_data_time: 0.2673   lr: 0.00018482  max_mem: 6663M\n",
      "\u001b[32m[02/22 17:00:09 d2.utils.events]: \u001b[0m eta: 0:03:33  iter: 759  total_loss: 1.035  loss_cls: 0.1988  loss_box_reg: 0.4443  loss_mask: 0.2882  loss_rpn_cls: 0.04432  loss_rpn_loc: 0.05249    time: 0.9079  last_time: 0.9106  data_time: 0.0562  last_data_time: 0.0068   lr: 0.00018981  max_mem: 6663M\n",
      "\u001b[32m[02/22 17:00:28 d2.utils.events]: \u001b[0m eta: 0:03:15  iter: 779  total_loss: 1.138  loss_cls: 0.2203  loss_box_reg: 0.4696  loss_mask: 0.3059  loss_rpn_cls: 0.04788  loss_rpn_loc: 0.07163    time: 0.9080  last_time: 0.9616  data_time: 0.0473  last_data_time: 0.0069   lr: 0.00019481  max_mem: 6663M\n",
      "\u001b[32m[02/22 17:00:46 d2.utils.events]: \u001b[0m eta: 0:02:57  iter: 799  total_loss: 1.063  loss_cls: 0.201  loss_box_reg: 0.438  loss_mask: 0.2919  loss_rpn_cls: 0.04824  loss_rpn_loc: 0.06988    time: 0.9078  last_time: 0.8031  data_time: 0.0298  last_data_time: 0.0051   lr: 0.0001998  max_mem: 6663M\n",
      "\u001b[32m[02/22 17:01:04 d2.utils.events]: \u001b[0m eta: 0:02:39  iter: 819  total_loss: 1.091  loss_cls: 0.2077  loss_box_reg: 0.4815  loss_mask: 0.2969  loss_rpn_cls: 0.03203  loss_rpn_loc: 0.08083    time: 0.9082  last_time: 0.8587  data_time: 0.0628  last_data_time: 0.0051   lr: 0.0002048  max_mem: 6663M\n",
      "\u001b[32m[02/22 17:01:22 d2.utils.events]: \u001b[0m eta: 0:02:21  iter: 839  total_loss: 0.9877  loss_cls: 0.1748  loss_box_reg: 0.4053  loss_mask: 0.2964  loss_rpn_cls: 0.03313  loss_rpn_loc: 0.05659    time: 0.9075  last_time: 0.9111  data_time: 0.0304  last_data_time: 0.0972   lr: 0.00020979  max_mem: 6663M\n",
      "\u001b[32m[02/22 17:01:40 d2.utils.events]: \u001b[0m eta: 0:02:04  iter: 859  total_loss: 1.058  loss_cls: 0.212  loss_box_reg: 0.454  loss_mask: 0.3051  loss_rpn_cls: 0.0328  loss_rpn_loc: 0.06836    time: 0.9080  last_time: 1.0860  data_time: 0.0636  last_data_time: 0.2234   lr: 0.00021479  max_mem: 6663M\n",
      "\u001b[32m[02/22 17:01:58 d2.utils.events]: \u001b[0m eta: 0:01:46  iter: 879  total_loss: 0.8932  loss_cls: 0.176  loss_box_reg: 0.354  loss_mask: 0.2807  loss_rpn_cls: 0.03922  loss_rpn_loc: 0.06294    time: 0.9070  last_time: 0.7934  data_time: 0.0249  last_data_time: 0.0043   lr: 0.00021978  max_mem: 6663M\n",
      "\u001b[32m[02/22 17:02:16 d2.utils.events]: \u001b[0m eta: 0:01:28  iter: 899  total_loss: 1.023  loss_cls: 0.2185  loss_box_reg: 0.4182  loss_mask: 0.2961  loss_rpn_cls: 0.03531  loss_rpn_loc: 0.06775    time: 0.9069  last_time: 0.7875  data_time: 0.0602  last_data_time: 0.0418   lr: 0.00022478  max_mem: 6663M\n",
      "\u001b[32m[02/22 17:02:34 d2.utils.events]: \u001b[0m eta: 0:01:10  iter: 919  total_loss: 1.056  loss_cls: 0.201  loss_box_reg: 0.4534  loss_mask: 0.282  loss_rpn_cls: 0.04343  loss_rpn_loc: 0.05994    time: 0.9072  last_time: 1.0225  data_time: 0.0721  last_data_time: 0.2270   lr: 0.00022977  max_mem: 6663M\n",
      "\u001b[32m[02/22 17:02:52 d2.utils.events]: \u001b[0m eta: 0:00:53  iter: 939  total_loss: 0.881  loss_cls: 0.1565  loss_box_reg: 0.3379  loss_mask: 0.2752  loss_rpn_cls: 0.02769  loss_rpn_loc: 0.06436    time: 0.9065  last_time: 0.8029  data_time: 0.0301  last_data_time: 0.0041   lr: 0.00023477  max_mem: 6663M\n",
      "\u001b[32m[02/22 17:03:10 d2.utils.events]: \u001b[0m eta: 0:00:35  iter: 959  total_loss: 0.9916  loss_cls: 0.1806  loss_box_reg: 0.4182  loss_mask: 0.2883  loss_rpn_cls: 0.03402  loss_rpn_loc: 0.07123    time: 0.9065  last_time: 0.8734  data_time: 0.0598  last_data_time: 0.0037   lr: 0.00023976  max_mem: 6663M\n",
      "\u001b[32m[02/22 17:03:27 d2.utils.events]: \u001b[0m eta: 0:00:17  iter: 979  total_loss: 1.001  loss_cls: 0.1829  loss_box_reg: 0.4109  loss_mask: 0.2695  loss_rpn_cls: 0.03095  loss_rpn_loc: 0.06069    time: 0.9058  last_time: 0.8952  data_time: 0.0334  last_data_time: 0.0051   lr: 0.00024476  max_mem: 6663M\n",
      "\u001b[32m[02/22 17:03:51 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 999  total_loss: 0.8766  loss_cls: 0.1429  loss_box_reg: 0.3339  loss_mask: 0.2686  loss_rpn_cls: 0.03003  loss_rpn_loc: 0.04595    time: 0.9059  last_time: 0.7464  data_time: 0.0355  last_data_time: 0.0038   lr: 0.00024975  max_mem: 6663M\n",
      "\u001b[32m[02/22 17:03:51 d2.engine.hooks]: \u001b[0mOverall training speed: 998 iterations in 0:15:04 (0.9059 s / it)\n",
      "\u001b[32m[02/22 17:03:51 d2.engine.hooks]: \u001b[0mTotal training time: 0:15:11 (0:00:07 on hooks)\n",
      "\u001b[32m[02/22 17:03:51 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/22 17:03:51 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[02/22 17:03:51 d2.data.common]: \u001b[0mSerializing 23 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/22 17:03:51 d2.data.common]: \u001b[0mSerialized dataset takes 0.29 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[02/22 17:03:51 d2.engine.defaults]: \u001b[0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.\n",
      "Finished training mask_rcnn_R_50_DC5_3x. Model saved in /home/etaylor/code_projects/thesis/checkpoints/stigmas_segmentation/detectron2/fine_tuned/mask_rcnn_R_50_DC5_3x\n",
      "Evaluating mask_rcnn_R_50_DC5_3x...\n",
      "\u001b[32m[02/22 17:03:57 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from /home/etaylor/code_projects/thesis/checkpoints/stigmas_segmentation/detectron2/fine_tuned/mask_rcnn_R_50_DC5_3x/model_final.pth ...\n",
      "\u001b[32m[02/22 17:04:16 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n",
      "\u001b[32m[02/22 17:04:16 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[02/22 17:04:16 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[02/22 17:04:16 d2.data.common]: \u001b[0mSerializing 23 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[02/22 17:04:16 d2.data.common]: \u001b[0mSerialized dataset takes 0.29 MiB\n",
      "\u001b[32m[02/22 17:04:16 d2.evaluation.evaluator]: \u001b[0mStart inference on 23 batches\n",
      "\u001b[32m[02/22 17:04:32 d2.evaluation.evaluator]: \u001b[0mInference done 11/23. Dataloading: 0.0008 s/iter. Inference: 0.4379 s/iter. Eval: 1.0109 s/iter. Total: 1.4496 s/iter. ETA=0:00:17\n",
      "\u001b[32m[02/22 17:04:37 d2.evaluation.evaluator]: \u001b[0mInference done 18/23. Dataloading: 0.0009 s/iter. Inference: 0.3804 s/iter. Eval: 0.7076 s/iter. Total: 1.0891 s/iter. ETA=0:00:05\n",
      "\u001b[32m[02/22 17:04:41 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:18.372797 (1.020711 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/22 17:04:41 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:06 (0.367746 s / iter per device, on 1 devices)\n",
      "\u001b[32m[02/22 17:04:41 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[02/22 17:04:41 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to /home/etaylor/code_projects/thesis/checkpoints/stigmas_segmentation/detectron2/fine_tuned/mask_rcnn_R_50_DC5_3x/coco_instances_results.json\n",
      "\u001b[32m[02/22 17:04:41 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.10s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.289\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.583\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.294\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.291\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.063\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.376\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.487\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.490\n",
      "\u001b[32m[02/22 17:04:42 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
      "| 28.940 | 58.257 | 29.412 |  nan  | 0.000 | 29.074 |\n",
      "\u001b[32m[02/22 17:04:42 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *segm*\n",
      "DONE (t=0.14s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.01s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.112\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.413\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.009\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.112\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.030\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.185\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.223\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.224\n",
      "\u001b[32m[02/22 17:04:42 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
      "| 11.171 | 41.327 | 0.872  |  nan  | 0.000 | 11.219 |\n",
      "\u001b[32m[02/22 17:04:42 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
      "Evaluation completed. Results saved in /home/etaylor/code_projects/thesis/checkpoints/stigmas_segmentation/detectron2/fine_tuned/mask_rcnn_R_50_DC5_3x/evaluation/eval_results.json\n"
     ]
    }
   ],
   "source": [
    "for model_name, config_path in MODELS.items():\n",
    "    train_and_evaluate_model(model_name, config_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "detectron_fastai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
