{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check How many Images we have from each of the classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Train Images ---\n",
      "Class cloudy,  533 images: \n",
      "\n",
      "Class amber,  371 images: \n",
      "\n",
      "Class clear,  202 images: \n",
      "\n",
      "--- Val Images ---\n",
      "Class clear,  51 images: \n",
      "\n",
      "Class cloudy,  133 images: \n",
      "\n",
      "Class amber,  93 images: \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "path = \"/home/etaylor/code_projects/thesis/segments/etaylor_cannabis_patches_train_26-04-2024_15-44-44/ground_truth_trichomes_datasets/trichome_dataset_125_good_quality/train_test\"\n",
    "\n",
    "train_path = os.path.join(path, \"train\")\n",
    "test_path = os.path.join(path, \"val\")\n",
    "\n",
    "classes = os.listdir(train_path)\n",
    "print(\"--- Train Images ---\")\n",
    "for class_name in classes:\n",
    "    class_path = os.path.join(train_path, class_name)\n",
    "\n",
    "    class_count = len(os.listdir(class_path))\n",
    "    print(f\"Class {class_name},  {class_count} images: \")\n",
    "    print()\n",
    "    \n",
    "    \n",
    "classes = os.listdir(test_path)\n",
    "print(\"--- Val Images ---\")\n",
    "for class_name in classes:\n",
    "    class_path = os.path.join(test_path, class_name)\n",
    "\n",
    "    class_count = len(os.listdir(class_path))\n",
    "    print(f\"Class {class_name},  {class_count} images: \")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Balanced Data set from the good quality images of the 1.25x \n",
    "- This dataset will have 200 images for each class.\n",
    "- I want to measure the performance of balanced dataset compared to the original which received good score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balancing train set - Class cloudy to 200 images.\n",
      "Balancing train set - Class amber to 200 images.\n",
      "Balancing train set - Class clear to 200 images.\n",
      "Balanced dataset created successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "# Define paths\n",
    "original_path = \"/home/etaylor/code_projects/thesis/segments/etaylor_cannabis_patches_train_26-04-2024_15-44-44/ground_truth_trichomes_datasets/trichome_dataset_125_good_quality/train_test\"\n",
    "balanced_path = \"/home/etaylor/code_projects/thesis/segments/etaylor_cannabis_patches_train_26-04-2024_15-44-44/ground_truth_trichomes_datasets/trichome_dataset_125_good_quality/train_test_balanced\"\n",
    "\n",
    "train_path = os.path.join(original_path, \"train\")\n",
    "balanced_train_path = os.path.join(balanced_path, \"train\")\n",
    "\n",
    "# Ensure the balanced dataset directories exist\n",
    "os.makedirs(balanced_train_path, exist_ok=True)\n",
    "\n",
    "def balance_class_images(source_class_path, target_class_path, target_count):\n",
    "    \"\"\"Balance the number of images for a class.\"\"\"\n",
    "    images = os.listdir(source_class_path)\n",
    "    if len(images) > target_count:\n",
    "        images = random.sample(images, target_count)  # Randomly select target_count images if there are too many\n",
    "    else:\n",
    "        # Duplicate images if there are fewer than target_count images\n",
    "        images = images * (target_count // len(images)) + images[:target_count % len(images)]\n",
    "\n",
    "    # Copy selected images to the target directory\n",
    "    for i, img_name in enumerate(images):\n",
    "        src_img_path = os.path.join(source_class_path, img_name)\n",
    "        dest_img_path = os.path.join(target_class_path, f\"{i}_{img_name}\")\n",
    "        shutil.copy(src_img_path, dest_img_path)\n",
    "\n",
    "# Process train and val directories\n",
    "for data_type, src_path, dest_path in [(\"train\", train_path, balanced_train_path)]:\n",
    "    classes = os.listdir(src_path)\n",
    "    for class_name in classes:\n",
    "        source_class_path = os.path.join(src_path, class_name)\n",
    "        target_class_path = os.path.join(dest_path, class_name)\n",
    "        os.makedirs(target_class_path, exist_ok=True)\n",
    "\n",
    "        print(f\"Balancing {data_type} set - Class {class_name} to 200 images.\")\n",
    "        balance_class_images(source_class_path, target_class_path, 200)\n",
    "\n",
    "print(\"Balanced dataset created successfully!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Split the Val dataset to Val and Test in order to eval the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting clear into validation and test sets (80-20 split).\n",
      "Splitting cloudy into validation and test sets (80-20 split).\n",
      "Splitting amber into validation and test sets (80-20 split).\n",
      "Validation and test datasets created successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "# Define paths\n",
    "original_val_path = \"/home/etaylor/code_projects/thesis/segments/etaylor_cannabis_patches_train_26-04-2024_15-44-44/ground_truth_trichomes_datasets/trichome_dataset_125_good_quality/train_test/val\"\n",
    "split_val_path = \"/home/etaylor/code_projects/thesis/segments/etaylor_cannabis_patches_train_26-04-2024_15-44-44/ground_truth_trichomes_datasets/trichome_dataset_125_good_quality/train_test_balanced/val\"\n",
    "split_test_path = \"/home/etaylor/code_projects/thesis/segments/etaylor_cannabis_patches_train_26-04-2024_15-44-44/ground_truth_trichomes_datasets/trichome_dataset_125_good_quality/train_test_balanced/test\"\n",
    "\n",
    "# Ensure the split dataset directories exist\n",
    "os.makedirs(split_val_path, exist_ok=True)\n",
    "os.makedirs(split_test_path, exist_ok=True)\n",
    "\n",
    "def split_images(source_class_path, val_class_path, test_class_path, test_ratio=0.2):\n",
    "    \"\"\"Split images into validation and test sets based on the specified test ratio.\"\"\"\n",
    "    images = os.listdir(source_class_path)\n",
    "    random.shuffle(images)\n",
    "\n",
    "    # Calculate the number of images for test and validation sets\n",
    "    test_size = int(len(images) * test_ratio)\n",
    "    test_images = images[:test_size]\n",
    "    val_images = images[test_size:]\n",
    "\n",
    "    # Copy test images\n",
    "    for img_name in test_images:\n",
    "        src_img_path = os.path.join(source_class_path, img_name)\n",
    "        dest_img_path = os.path.join(test_class_path, img_name)\n",
    "        shutil.copy(src_img_path, dest_img_path)\n",
    "\n",
    "    # Copy validation images\n",
    "    for img_name in val_images:\n",
    "        src_img_path = os.path.join(source_class_path, img_name)\n",
    "        dest_img_path = os.path.join(val_class_path, img_name)\n",
    "        shutil.copy(src_img_path, dest_img_path)\n",
    "\n",
    "# Process each class in the original validation set\n",
    "classes = os.listdir(original_val_path)\n",
    "for class_name in classes:\n",
    "    source_class_path = os.path.join(original_val_path, class_name)\n",
    "    val_class_path = os.path.join(split_val_path, class_name)\n",
    "    test_class_path = os.path.join(split_test_path, class_name)\n",
    "\n",
    "    # Create directories for each class in the split sets\n",
    "    os.makedirs(val_class_path, exist_ok=True)\n",
    "    os.makedirs(test_class_path, exist_ok=True)\n",
    "\n",
    "    print(f\"Splitting {class_name} into validation and test sets (80-20 split).\")\n",
    "    split_images(source_class_path, val_class_path, test_class_path, test_ratio=0.2)\n",
    "\n",
    "print(\"Validation and test datasets created successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import YOLO model\n",
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import os\n",
    "\n",
    "\n",
    "data_path = \"/home/etaylor/code_projects/thesis/segments/etaylor_cannabis_patches_train_26-04-2024_15-44-44/ground_truth_trichomes_datasets/trichome_dataset_125_good_quality/train_test_balanced\"\n",
    "test_data_path = \"/home/etaylor/code_projects/thesis/segments/etaylor_cannabis_patches_train_26-04-2024_15-44-44/ground_truth_trichomes_datasets/trichome_dataset_125_good_quality/train_test_balanced/test\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison between Different Yolo Models\n",
    "- YOLO v5\n",
    "- YOLO v8\n",
    "- YOLO v9\n",
    "- YOLO v11\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo_classification_checkpoints = {\n",
    "    \"YOLOv8\": {\n",
    "        \"Nano\": \"yolov8n-cls.pt\",\n",
    "        \"Small\": \"yolov8s-cls.pt\",\n",
    "        \"Medium\": \"yolov8m-cls.pt\",\n",
    "        \"Large\": \"yolov8l-cls.pt\",\n",
    "        \"XLarge\": \"yolov8x-cls.pt\",\n",
    "    },\n",
    "        \"YOLOv11\": {\n",
    "        \"Nano\": \"yolo11n-cls.pt\",\n",
    "        \"Small\": \"yolo11s-cls.pt\",\n",
    "        \"Medium\": \"yolo11m-cls.pt\",\n",
    "        \"Large\": \"yolo11l-cls.pt\",\n",
    "        \"XLarge\": \"yolo11x-cls.pt\",\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions to fine tune each model and then evaluate it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(data_path, model_name, model_size, epochs=10, imgsz=128):\n",
    "    # Load the model checkpoint\n",
    "    checkpoint = yolo_classification_checkpoints[model_name][model_size]\n",
    "    model = YOLO(checkpoint)\n",
    "    \n",
    "    # Train the model\n",
    "    model.train(data=data_path, epochs=epochs, imgsz=imgsz)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def eval_model(model, test_data_path):\n",
    "    # Get class names from the test dataset directory\n",
    "    class_names = sorted(os.listdir(test_data_path))\n",
    "    class_to_idx = {class_name: idx for idx, class_name in enumerate(class_names)}\n",
    "\n",
    "    # Initialize lists for true labels (y_test) and predicted labels (y_pred)\n",
    "    y_test = []\n",
    "    y_pred = []\n",
    "\n",
    "    # Initialize a list to store image data for plotting\n",
    "    images_for_plotting = []\n",
    "\n",
    "    # Process each class in the test directory\n",
    "    for class_name in class_names:\n",
    "        class_dir = os.path.join(test_data_path, class_name)\n",
    "        for img_name in os.listdir(class_dir):\n",
    "            img_path = os.path.join(class_dir, img_name)\n",
    "            \n",
    "            # Load the image and run the model prediction\n",
    "            img = cv2.imread(img_path)\n",
    "            img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert to RGB for matplotlib\n",
    "            results = model(img)\n",
    "            \n",
    "            # Get the predicted class index\n",
    "            predicted_idx = int(results[0].probs.data.argmax())\n",
    "            \n",
    "            # Append true and predicted labels\n",
    "            y_test.append(class_to_idx[class_name])\n",
    "            y_pred.append(predicted_idx)\n",
    "            \n",
    "            # Store the image, true label, and predicted label for plotting\n",
    "            images_for_plotting.append((img_rgb, class_name, class_names[predicted_idx]))\n",
    "\n",
    "    # Evaluate using classification metrics\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred, target_names=class_names))\n",
    "\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "def plot_results(images_for_plotting):\n",
    "    # Plot images with true and predicted labels\n",
    "    plt.figure(figsize=(12, 12))\n",
    "    num_images = len(images_for_plotting)  # Display all images (adjust as needed)\n",
    "    rows = (num_images // 4) + 1  # Adjust rows based on the number of images\n",
    "\n",
    "    for i in range(num_images):\n",
    "        img, true_label, pred_label = images_for_plotting[i]\n",
    "        plt.subplot(rows, 4, i + 1)  # Dynamic row setting\n",
    "        plt.imshow(img)\n",
    "        plt.title(f\"True: {true_label}\\nPred: {pred_label}\", color=\"green\" if true_label == pred_label else \"red\")\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training YOLOv8 Nano model...\n",
      "Ultralytics 8.3.27 ðŸš€ Python-3.10.13 torch-2.1.1+cu121 CUDA:0 (NVIDIA GeForce RTX 3090, 24161MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=classify, mode=train, model=yolov8n-cls.pt, data=/home/etaylor/code_projects/thesis/segments/etaylor_cannabis_patches_train_26-04-2024_15-44-44/ground_truth_trichomes_datasets/trichome_dataset_125_good_quality/train_test_balanced, epochs=10, time=None, patience=100, batch=16, imgsz=128, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train11, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=/home/etaylor/runs/classify/train11\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m /sise/home/etaylor/code_projects/thesis/segments/etaylor_cannabis_patches_train_26-04-2024_15-44-44/ground_truth_trichomes_datasets/trichome_dataset_125_good_quality/train_test_balanced/train... found 600 images in 3 classes âœ… \n",
      "\u001b[34m\u001b[1mval:\u001b[0m /sise/home/etaylor/code_projects/thesis/segments/etaylor_cannabis_patches_train_26-04-2024_15-44-44/ground_truth_trichomes_datasets/trichome_dataset_125_good_quality/train_test_balanced/val... found 223 images in 3 classes âœ… \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m /sise/home/etaylor/code_projects/thesis/segments/etaylor_cannabis_patches_train_26-04-2024_15-44-44/ground_truth_trichomes_datasets/trichome_dataset_125_good_quality/train_test_balanced/test... found 54 images in 3 classes âœ… \n",
      "Overriding model.yaml nc=1000 with nc=3\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    334083  ultralytics.nn.modules.head.Classify         [256, 3]                      \n",
      "YOLOv8n-cls summary: 99 layers, 1,442,131 parameters, 1,442,131 gradients, 3.4 GFLOPs\n",
      "Transferred 156/158 items from pretrained weights\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /sise/home/etaylor/code_projects/thesis/segments/etaylor_cannabis_patches_train_26-04-2024_15-44-44/ground_truth_trichomes_datasets/trichome_dataset_125_good_quality/train_test_balanced/train... 600 images, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 600/600 [00:00<?, ?it/s]\n",
      "/home/etaylor/.conda/envs/yolo8/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 6, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /sise/home/etaylor/code_projects/thesis/segments/etaylor_cannabis_patches_train_26-04-2024_15-44-44/ground_truth_trichomes_datasets/trichome_dataset_125_good_quality/train_test_balanced/val... 223 images, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 223/223 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000714, momentum=0.9) with parameter groups 26 weight(decay=0.0), 27 weight(decay=0.0005), 27 bias(decay=0.0)\n",
      "Image sizes 128 train, 128 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1m/home/etaylor/runs/classify/train11\u001b[0m\n",
      "Starting training for 10 epochs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/etaylor/.conda/envs/yolo8/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 6, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/10     0.694G       1.05          8        128: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 38/38 [00:01<00:00, 28.82it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:00<00:00, 112.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.686          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/10     0.675G     0.6817          8        128: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 38/38 [00:00<00:00, 38.12it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:00<00:00, 122.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.865          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/10     0.673G     0.5037          8        128: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 38/38 [00:00<00:00, 40.17it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:00<00:00, 117.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.879          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/10     0.673G     0.4244          8        128: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 38/38 [00:00<00:00, 40.98it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:00<00:00, 113.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.933          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/10     0.673G       0.38          8        128: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 38/38 [00:00<00:00, 41.91it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:00<00:00, 113.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       0.91          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/10     0.673G      0.441          8        128: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 38/38 [00:00<00:00, 38.16it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:00<00:00, 121.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.924          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/10     0.673G     0.4001          8        128: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 38/38 [00:00<00:00, 40.59it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:00<00:00, 130.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.919          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/10     0.673G     0.3735          8        128: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 38/38 [00:00<00:00, 41.12it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:00<00:00, 113.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.915          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/10     0.673G     0.3951          8        128: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 38/38 [00:00<00:00, 40.72it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:00<00:00, 121.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.928          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/10     0.673G      0.368          8        128: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 38/38 [00:00<00:00, 40.62it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:00<00:00, 112.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.928          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "10 epochs completed in 0.026 hours.\n",
      "Optimizer stripped from /home/etaylor/runs/classify/train11/weights/last.pt, 3.0MB\n",
      "Optimizer stripped from /home/etaylor/runs/classify/train11/weights/best.pt, 3.0MB\n",
      "\n",
      "Validating /home/etaylor/runs/classify/train11/weights/best.pt...\n",
      "Ultralytics 8.3.27 ðŸš€ Python-3.10.13 torch-2.1.1+cu121 CUDA:0 (NVIDIA GeForce RTX 3090, 24161MiB)\n",
      "YOLOv8n-cls summary (fused): 73 layers, 1,438,723 parameters, 0 gradients, 3.3 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m /sise/home/etaylor/code_projects/thesis/segments/etaylor_cannabis_patches_train_26-04-2024_15-44-44/ground_truth_trichomes_datasets/trichome_dataset_125_good_quality/train_test_balanced/train... found 600 images in 3 classes âœ… \n",
      "\u001b[34m\u001b[1mval:\u001b[0m /sise/home/etaylor/code_projects/thesis/segments/etaylor_cannabis_patches_train_26-04-2024_15-44-44/ground_truth_trichomes_datasets/trichome_dataset_125_good_quality/train_test_balanced/val... found 223 images in 3 classes âœ… \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m /sise/home/etaylor/code_projects/thesis/segments/etaylor_cannabis_patches_train_26-04-2024_15-44-44/ground_truth_trichomes_datasets/trichome_dataset_125_good_quality/train_test_balanced/test... found 54 images in 3 classes âœ… \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:00<00:00, 13.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.933          1\n",
      "Speed: 0.1ms preprocess, 2.2ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1m/home/etaylor/runs/classify/train11\u001b[0m\n",
      "Evaluating YOLOv8 Nano model...\n",
      "\n",
      "0: 128x128 amber 1.00, cloudy 0.00, clear 0.00, 3.2ms\n",
      "Speed: 103.0ms preprocess, 3.2ms inference, 0.1ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 cloudy 0.98, amber 0.01, clear 0.01, 3.3ms\n",
      "Speed: 1.4ms preprocess, 3.3ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 amber 0.99, cloudy 0.01, clear 0.00, 3.0ms\n",
      "Speed: 1.3ms preprocess, 3.0ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 amber 1.00, cloudy 0.00, clear 0.00, 3.1ms\n",
      "Speed: 1.3ms preprocess, 3.1ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 cloudy 0.51, amber 0.25, clear 0.24, 3.1ms\n",
      "Speed: 1.3ms preprocess, 3.1ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 amber 1.00, cloudy 0.00, clear 0.00, 3.1ms\n",
      "Speed: 1.3ms preprocess, 3.1ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 amber 0.83, clear 0.14, cloudy 0.04, 3.1ms\n",
      "Speed: 1.3ms preprocess, 3.1ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 cloudy 0.47, amber 0.40, clear 0.13, 3.1ms\n",
      "Speed: 1.3ms preprocess, 3.1ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 amber 1.00, cloudy 0.00, clear 0.00, 3.1ms\n",
      "Speed: 1.3ms preprocess, 3.1ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 amber 1.00, cloudy 0.00, clear 0.00, 3.2ms\n",
      "Speed: 1.3ms preprocess, 3.2ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 amber 1.00, clear 0.00, cloudy 0.00, 3.4ms\n",
      "Speed: 1.4ms preprocess, 3.4ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 amber 1.00, cloudy 0.00, clear 0.00, 3.1ms\n",
      "Speed: 1.4ms preprocess, 3.1ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 amber 0.98, cloudy 0.02, clear 0.00, 3.1ms\n",
      "Speed: 1.3ms preprocess, 3.1ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 amber 0.99, cloudy 0.01, clear 0.00, 3.1ms\n",
      "Speed: 1.3ms preprocess, 3.1ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 amber 1.00, cloudy 0.00, clear 0.00, 3.2ms\n",
      "Speed: 1.3ms preprocess, 3.2ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 cloudy 0.82, amber 0.17, clear 0.01, 3.1ms\n",
      "Speed: 1.3ms preprocess, 3.1ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 amber 1.00, cloudy 0.00, clear 0.00, 3.2ms\n",
      "Speed: 1.3ms preprocess, 3.2ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 amber 1.00, cloudy 0.00, clear 0.00, 3.2ms\n",
      "Speed: 1.3ms preprocess, 3.2ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 cloudy 0.88, clear 0.10, amber 0.02, 3.1ms\n",
      "Speed: 1.4ms preprocess, 3.1ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 clear 0.61, cloudy 0.38, amber 0.00, 3.0ms\n",
      "Speed: 1.4ms preprocess, 3.0ms inference, 0.1ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 clear 0.99, cloudy 0.01, amber 0.00, 3.1ms\n",
      "Speed: 1.3ms preprocess, 3.1ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 clear 0.95, cloudy 0.05, amber 0.00, 3.1ms\n",
      "Speed: 1.3ms preprocess, 3.1ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 cloudy 0.52, clear 0.47, amber 0.00, 3.2ms\n",
      "Speed: 1.2ms preprocess, 3.2ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 cloudy 0.92, clear 0.07, amber 0.00, 3.1ms\n",
      "Speed: 1.3ms preprocess, 3.1ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 clear 1.00, cloudy 0.00, amber 0.00, 3.1ms\n",
      "Speed: 1.3ms preprocess, 3.1ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 clear 0.80, cloudy 0.19, amber 0.01, 3.2ms\n",
      "Speed: 1.5ms preprocess, 3.2ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 clear 0.93, cloudy 0.07, amber 0.00, 3.1ms\n",
      "Speed: 1.3ms preprocess, 3.1ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 clear 0.96, cloudy 0.04, amber 0.00, 3.3ms\n",
      "Speed: 1.4ms preprocess, 3.3ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 cloudy 1.00, clear 0.00, amber 0.00, 3.1ms\n",
      "Speed: 1.4ms preprocess, 3.1ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 cloudy 0.99, clear 0.01, amber 0.00, 3.1ms\n",
      "Speed: 1.5ms preprocess, 3.1ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 clear 0.74, cloudy 0.26, amber 0.00, 3.1ms\n",
      "Speed: 1.3ms preprocess, 3.1ms inference, 0.1ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 cloudy 0.99, clear 0.01, amber 0.00, 3.0ms\n",
      "Speed: 1.3ms preprocess, 3.0ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 cloudy 1.00, clear 0.00, amber 0.00, 3.4ms\n",
      "Speed: 1.4ms preprocess, 3.4ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 cloudy 0.90, clear 0.09, amber 0.01, 3.3ms\n",
      "Speed: 1.5ms preprocess, 3.3ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 cloudy 0.85, clear 0.12, amber 0.04, 3.1ms\n",
      "Speed: 1.3ms preprocess, 3.1ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 cloudy 0.69, clear 0.27, amber 0.04, 3.1ms\n",
      "Speed: 1.3ms preprocess, 3.1ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 cloudy 0.99, clear 0.01, amber 0.00, 3.1ms\n",
      "Speed: 1.3ms preprocess, 3.1ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 cloudy 0.93, clear 0.07, amber 0.00, 3.2ms\n",
      "Speed: 1.4ms preprocess, 3.2ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 cloudy 0.92, clear 0.08, amber 0.00, 3.2ms\n",
      "Speed: 1.3ms preprocess, 3.2ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 amber 0.98, cloudy 0.02, clear 0.00, 3.3ms\n",
      "Speed: 1.5ms preprocess, 3.3ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 cloudy 1.00, clear 0.00, amber 0.00, 3.1ms\n",
      "Speed: 1.2ms preprocess, 3.1ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 cloudy 0.99, clear 0.01, amber 0.00, 3.2ms\n",
      "Speed: 1.2ms preprocess, 3.2ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 cloudy 1.00, clear 0.00, amber 0.00, 3.1ms\n",
      "Speed: 1.4ms preprocess, 3.1ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 cloudy 0.42, clear 0.34, amber 0.24, 3.1ms\n",
      "Speed: 1.3ms preprocess, 3.1ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 clear 0.58, cloudy 0.42, amber 0.00, 3.1ms\n",
      "Speed: 1.3ms preprocess, 3.1ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 cloudy 0.98, clear 0.02, amber 0.00, 3.1ms\n",
      "Speed: 1.2ms preprocess, 3.1ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 cloudy 0.91, clear 0.08, amber 0.01, 3.1ms\n",
      "Speed: 1.3ms preprocess, 3.1ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 cloudy 0.99, clear 0.00, amber 0.00, 3.1ms\n",
      "Speed: 1.4ms preprocess, 3.1ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 cloudy 0.97, clear 0.03, amber 0.00, 3.1ms\n",
      "Speed: 1.1ms preprocess, 3.1ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 cloudy 0.86, clear 0.11, amber 0.03, 3.2ms\n",
      "Speed: 1.3ms preprocess, 3.2ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 cloudy 1.00, clear 0.00, amber 0.00, 3.1ms\n",
      "Speed: 1.4ms preprocess, 3.1ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 cloudy 0.93, clear 0.07, amber 0.00, 3.1ms\n",
      "Speed: 1.3ms preprocess, 3.1ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 cloudy 0.99, clear 0.01, amber 0.00, 3.1ms\n",
      "Speed: 1.4ms preprocess, 3.1ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 cloudy 0.99, clear 0.01, amber 0.00, 3.0ms\n",
      "Speed: 1.3ms preprocess, 3.0ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       amber       0.93      0.78      0.85        18\n",
      "       clear       0.78      0.70      0.74        10\n",
      "      cloudy       0.77      0.88      0.82        26\n",
      "\n",
      "    accuracy                           0.81        54\n",
      "   macro avg       0.83      0.79      0.80        54\n",
      "weighted avg       0.82      0.81      0.81        54\n",
      "\n",
      "Accuracy: 0.8148148148148148\n",
      "Confusion Matrix:\n",
      " [[14  0  4]\n",
      " [ 0  7  3]\n",
      " [ 1  2 23]]\n",
      "Training YOLOv8 Small model...\n",
      "Ultralytics 8.3.27 ðŸš€ Python-3.10.13 torch-2.1.1+cu121 CUDA:0 (NVIDIA GeForce RTX 3090, 24161MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=classify, mode=train, model=yolov8s-cls.pt, data=/home/etaylor/code_projects/thesis/segments/etaylor_cannabis_patches_train_26-04-2024_15-44-44/ground_truth_trichomes_datasets/trichome_dataset_125_good_quality/train_test_balanced, epochs=10, time=None, patience=100, batch=16, imgsz=128, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train12, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=/home/etaylor/runs/classify/train12\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m /sise/home/etaylor/code_projects/thesis/segments/etaylor_cannabis_patches_train_26-04-2024_15-44-44/ground_truth_trichomes_datasets/trichome_dataset_125_good_quality/train_test_balanced/train... found 600 images in 3 classes âœ… \n",
      "\u001b[34m\u001b[1mval:\u001b[0m /sise/home/etaylor/code_projects/thesis/segments/etaylor_cannabis_patches_train_26-04-2024_15-44-44/ground_truth_trichomes_datasets/trichome_dataset_125_good_quality/train_test_balanced/val... found 223 images in 3 classes âœ… \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m /sise/home/etaylor/code_projects/thesis/segments/etaylor_cannabis_patches_train_26-04-2024_15-44-44/ground_truth_trichomes_datasets/trichome_dataset_125_good_quality/train_test_balanced/test... found 54 images in 3 classes âœ… \n",
      "Overriding model.yaml nc=1000 with nc=3\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
      "  9                  -1  1    661763  ultralytics.nn.modules.head.Classify         [512, 3]                      \n",
      "YOLOv8s-cls summary: 99 layers, 5,084,579 parameters, 5,084,579 gradients, 12.6 GFLOPs\n",
      "Transferred 156/158 items from pretrained weights\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /sise/home/etaylor/code_projects/thesis/segments/etaylor_cannabis_patches_train_26-04-2024_15-44-44/ground_truth_trichomes_datasets/trichome_dataset_125_good_quality/train_test_balanced/train... 600 images, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 600/600 [00:00<?, ?it/s]\n",
      "/home/etaylor/.conda/envs/yolo8/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 6, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /sise/home/etaylor/code_projects/thesis/segments/etaylor_cannabis_patches_train_26-04-2024_15-44-44/ground_truth_trichomes_datasets/trichome_dataset_125_good_quality/train_test_balanced/val... 223 images, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 223/223 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000714, momentum=0.9) with parameter groups 26 weight(decay=0.0), 27 weight(decay=0.0005), 27 bias(decay=0.0)\n",
      "Image sizes 128 train, 128 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1m/home/etaylor/runs/classify/train12\u001b[0m\n",
      "Starting training for 10 epochs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/etaylor/.conda/envs/yolo8/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 6, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/10     0.575G     0.9933          8        128: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 38/38 [00:01<00:00, 23.76it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:00<00:00, 34.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.713          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/10     0.703G     0.6574          8        128: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 38/38 [00:01<00:00, 33.01it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:00<00:00, 114.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.865          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/10       0.7G     0.5131          8        128: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 38/38 [00:00<00:00, 41.29it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:00<00:00, 113.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.892          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/10     0.703G     0.4462          8        128: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 38/38 [00:00<00:00, 41.35it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:00<00:00, 113.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.883          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/10     0.703G     0.3831          8        128: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 38/38 [00:00<00:00, 39.79it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:00<00:00, 112.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.906          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/10      0.61G     0.3886          8        128: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 38/38 [00:00<00:00, 39.97it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:00<00:00, 117.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       0.91          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/10      0.61G     0.3613          8        128: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 38/38 [00:00<00:00, 41.52it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:00<00:00, 112.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.879          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/10     0.608G     0.3422          8        128: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 38/38 [00:00<00:00, 38.62it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:00<00:00, 106.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.892          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/10     0.608G      0.372          8        128: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 38/38 [00:00<00:00, 41.85it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:00<00:00, 110.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.942          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/10     0.608G     0.3266          8        128: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 38/38 [00:00<00:00, 41.13it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:00<00:00, 116.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.933          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "10 epochs completed in 0.004 hours.\n",
      "Optimizer stripped from /home/etaylor/runs/classify/train12/weights/last.pt, 10.3MB\n",
      "Optimizer stripped from /home/etaylor/runs/classify/train12/weights/best.pt, 10.3MB\n",
      "\n",
      "Validating /home/etaylor/runs/classify/train12/weights/best.pt...\n",
      "Ultralytics 8.3.27 ðŸš€ Python-3.10.13 torch-2.1.1+cu121 CUDA:0 (NVIDIA GeForce RTX 3090, 24161MiB)\n",
      "YOLOv8s-cls summary (fused): 73 layers, 5,079,043 parameters, 0 gradients, 12.5 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m /sise/home/etaylor/code_projects/thesis/segments/etaylor_cannabis_patches_train_26-04-2024_15-44-44/ground_truth_trichomes_datasets/trichome_dataset_125_good_quality/train_test_balanced/train... found 600 images in 3 classes âœ… \n",
      "\u001b[34m\u001b[1mval:\u001b[0m /sise/home/etaylor/code_projects/thesis/segments/etaylor_cannabis_patches_train_26-04-2024_15-44-44/ground_truth_trichomes_datasets/trichome_dataset_125_good_quality/train_test_balanced/val... found 223 images in 3 classes âœ… \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m /sise/home/etaylor/code_projects/thesis/segments/etaylor_cannabis_patches_train_26-04-2024_15-44-44/ground_truth_trichomes_datasets/trichome_dataset_125_good_quality/train_test_balanced/test... found 54 images in 3 classes âœ… \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:00<00:00, 14.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.942          1\n",
      "Speed: 0.0ms preprocess, 2.1ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1m/home/etaylor/runs/classify/train12\u001b[0m\n",
      "Evaluating YOLOv8 Small model...\n",
      "\n",
      "0: 128x128 amber 0.95, cloudy 0.04, clear 0.01, 3.2ms\n",
      "Speed: 1.6ms preprocess, 3.2ms inference, 0.1ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 cloudy 0.55, amber 0.41, clear 0.04, 3.4ms\n",
      "Speed: 1.3ms preprocess, 3.4ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 amber 0.86, cloudy 0.13, clear 0.00, 3.4ms\n",
      "Speed: 1.2ms preprocess, 3.4ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 amber 1.00, cloudy 0.00, clear 0.00, 3.3ms\n",
      "Speed: 1.3ms preprocess, 3.3ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 amber 0.60, cloudy 0.35, clear 0.05, 3.3ms\n",
      "Speed: 1.3ms preprocess, 3.3ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 amber 0.95, cloudy 0.05, clear 0.00, 3.4ms\n",
      "Speed: 1.2ms preprocess, 3.4ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 amber 0.99, cloudy 0.01, clear 0.00, 3.3ms\n",
      "Speed: 1.3ms preprocess, 3.3ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 amber 0.97, cloudy 0.02, clear 0.00, 3.3ms\n",
      "Speed: 1.3ms preprocess, 3.3ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 amber 0.87, cloudy 0.12, clear 0.01, 3.3ms\n",
      "Speed: 1.4ms preprocess, 3.3ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 amber 0.89, cloudy 0.10, clear 0.00, 3.3ms\n",
      "Speed: 1.4ms preprocess, 3.3ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 amber 0.97, cloudy 0.03, clear 0.00, 3.3ms\n",
      "Speed: 1.3ms preprocess, 3.3ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 amber 0.91, cloudy 0.08, clear 0.01, 3.3ms\n",
      "Speed: 1.3ms preprocess, 3.3ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 amber 0.57, cloudy 0.42, clear 0.00, 3.3ms\n",
      "Speed: 1.4ms preprocess, 3.3ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 amber 0.95, cloudy 0.04, clear 0.00, 3.4ms\n",
      "Speed: 1.3ms preprocess, 3.4ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 amber 1.00, cloudy 0.00, clear 0.00, 3.5ms\n",
      "Speed: 1.5ms preprocess, 3.5ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 cloudy 0.54, amber 0.45, clear 0.01, 3.4ms\n",
      "Speed: 1.5ms preprocess, 3.4ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 amber 1.00, cloudy 0.00, clear 0.00, 3.4ms\n",
      "Speed: 1.3ms preprocess, 3.4ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 amber 1.00, cloudy 0.00, clear 0.00, 3.4ms\n",
      "Speed: 1.4ms preprocess, 3.4ms inference, 0.1ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 cloudy 0.90, clear 0.07, amber 0.03, 3.4ms\n",
      "Speed: 1.3ms preprocess, 3.4ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 clear 0.67, cloudy 0.33, amber 0.00, 3.3ms\n",
      "Speed: 1.3ms preprocess, 3.3ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 clear 1.00, cloudy 0.00, amber 0.00, 3.3ms\n",
      "Speed: 1.4ms preprocess, 3.3ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 clear 1.00, cloudy 0.00, amber 0.00, 3.4ms\n",
      "Speed: 1.3ms preprocess, 3.4ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 clear 0.96, cloudy 0.04, amber 0.00, 3.4ms\n",
      "Speed: 1.3ms preprocess, 3.4ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 cloudy 0.52, clear 0.48, amber 0.00, 3.3ms\n",
      "Speed: 1.3ms preprocess, 3.3ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 clear 1.00, cloudy 0.00, amber 0.00, 3.3ms\n",
      "Speed: 1.3ms preprocess, 3.3ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 clear 0.99, cloudy 0.01, amber 0.00, 3.3ms\n",
      "Speed: 1.3ms preprocess, 3.3ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 clear 0.96, cloudy 0.04, amber 0.00, 3.3ms\n",
      "Speed: 1.3ms preprocess, 3.3ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 clear 0.93, cloudy 0.06, amber 0.01, 3.3ms\n",
      "Speed: 1.3ms preprocess, 3.3ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 cloudy 1.00, clear 0.00, amber 0.00, 3.3ms\n",
      "Speed: 1.3ms preprocess, 3.3ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 cloudy 0.94, clear 0.05, amber 0.01, 3.5ms\n",
      "Speed: 1.4ms preprocess, 3.5ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 clear 0.78, cloudy 0.22, amber 0.00, 3.4ms\n",
      "Speed: 1.3ms preprocess, 3.4ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 cloudy 1.00, clear 0.00, amber 0.00, 3.3ms\n",
      "Speed: 1.3ms preprocess, 3.3ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 cloudy 0.99, clear 0.00, amber 0.00, 3.3ms\n",
      "Speed: 1.3ms preprocess, 3.3ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 cloudy 0.63, amber 0.30, clear 0.07, 3.4ms\n",
      "Speed: 1.4ms preprocess, 3.4ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 cloudy 0.62, clear 0.38, amber 0.01, 3.6ms\n",
      "Speed: 1.6ms preprocess, 3.6ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 cloudy 0.57, clear 0.33, amber 0.10, 3.4ms\n",
      "Speed: 1.5ms preprocess, 3.4ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 cloudy 0.96, clear 0.03, amber 0.01, 3.7ms\n",
      "Speed: 1.4ms preprocess, 3.7ms inference, 0.1ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 clear 0.88, cloudy 0.12, amber 0.00, 3.3ms\n",
      "Speed: 1.4ms preprocess, 3.3ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 clear 0.73, cloudy 0.24, amber 0.03, 3.4ms\n",
      "Speed: 1.3ms preprocess, 3.4ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 amber 0.93, cloudy 0.06, clear 0.01, 3.4ms\n",
      "Speed: 1.5ms preprocess, 3.4ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 cloudy 0.81, clear 0.16, amber 0.03, 3.3ms\n",
      "Speed: 1.3ms preprocess, 3.3ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 cloudy 0.68, clear 0.32, amber 0.00, 3.3ms\n",
      "Speed: 1.3ms preprocess, 3.3ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 cloudy 0.93, clear 0.06, amber 0.01, 3.3ms\n",
      "Speed: 1.3ms preprocess, 3.3ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 cloudy 0.78, clear 0.16, amber 0.06, 3.4ms\n",
      "Speed: 1.3ms preprocess, 3.4ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 clear 0.89, cloudy 0.11, amber 0.00, 3.3ms\n",
      "Speed: 1.3ms preprocess, 3.3ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 cloudy 0.77, clear 0.23, amber 0.00, 3.4ms\n",
      "Speed: 1.4ms preprocess, 3.4ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 cloudy 0.97, clear 0.03, amber 0.00, 3.5ms\n",
      "Speed: 1.4ms preprocess, 3.5ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 cloudy 1.00, amber 0.00, clear 0.00, 3.4ms\n",
      "Speed: 1.4ms preprocess, 3.4ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 cloudy 0.98, clear 0.01, amber 0.00, 3.6ms\n",
      "Speed: 1.4ms preprocess, 3.6ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 cloudy 0.82, clear 0.14, amber 0.03, 3.7ms\n",
      "Speed: 1.4ms preprocess, 3.7ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 cloudy 1.00, clear 0.00, amber 0.00, 3.4ms\n",
      "Speed: 1.5ms preprocess, 3.4ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 cloudy 0.93, clear 0.07, amber 0.00, 3.5ms\n",
      "Speed: 1.3ms preprocess, 3.5ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 cloudy 0.99, clear 0.01, amber 0.00, 3.3ms\n",
      "Speed: 1.4ms preprocess, 3.3ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 cloudy 0.74, clear 0.26, amber 0.00, 3.4ms\n",
      "Speed: 1.4ms preprocess, 3.4ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       amber       0.94      0.89      0.91        18\n",
      "       clear       0.67      0.80      0.73        10\n",
      "      cloudy       0.84      0.81      0.82        26\n",
      "\n",
      "    accuracy                           0.83        54\n",
      "   macro avg       0.82      0.83      0.82        54\n",
      "weighted avg       0.84      0.83      0.84        54\n",
      "\n",
      "Accuracy: 0.8333333333333334\n",
      "Confusion Matrix:\n",
      " [[16  0  2]\n",
      " [ 0  8  2]\n",
      " [ 1  4 21]]\n",
      "Training YOLOv8 Medium model...\n",
      "Ultralytics 8.3.27 ðŸš€ Python-3.10.13 torch-2.1.1+cu121 CUDA:0 (NVIDIA GeForce RTX 3090, 24161MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=classify, mode=train, model=yolov8m-cls.pt, data=/home/etaylor/code_projects/thesis/segments/etaylor_cannabis_patches_train_26-04-2024_15-44-44/ground_truth_trichomes_datasets/trichome_dataset_125_good_quality/train_test_balanced, epochs=10, time=None, patience=100, batch=16, imgsz=128, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train13, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=/home/etaylor/runs/classify/train13\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m /sise/home/etaylor/code_projects/thesis/segments/etaylor_cannabis_patches_train_26-04-2024_15-44-44/ground_truth_trichomes_datasets/trichome_dataset_125_good_quality/train_test_balanced/train... found 600 images in 3 classes âœ… \n",
      "\u001b[34m\u001b[1mval:\u001b[0m /sise/home/etaylor/code_projects/thesis/segments/etaylor_cannabis_patches_train_26-04-2024_15-44-44/ground_truth_trichomes_datasets/trichome_dataset_125_good_quality/train_test_balanced/val... found 223 images in 3 classes âœ… \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m /sise/home/etaylor/code_projects/thesis/segments/etaylor_cannabis_patches_train_26-04-2024_15-44-44/ground_truth_trichomes_datasets/trichome_dataset_125_good_quality/train_test_balanced/test... found 54 images in 3 classes âœ… \n",
      "Overriding model.yaml nc=1000 with nc=3\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   2655744  ultralytics.nn.modules.conv.Conv             [384, 768, 3, 2]              \n",
      "  8                  -1  2   7084032  ultralytics.nn.modules.block.C2f             [768, 768, 2, True]           \n",
      "  9                  -1  1    989443  ultralytics.nn.modules.head.Classify         [768, 3]                      \n",
      "YOLOv8m-cls summary: 141 layers, 15,776,179 parameters, 15,776,179 gradients, 41.9 GFLOPs\n",
      "Transferred 228/230 items from pretrained weights\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /sise/home/etaylor/code_projects/thesis/segments/etaylor_cannabis_patches_train_26-04-2024_15-44-44/ground_truth_trichomes_datasets/trichome_dataset_125_good_quality/train_test_balanced/train... 600 images, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 600/600 [00:00<?, ?it/s]\n",
      "/home/etaylor/.conda/envs/yolo8/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 6, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /sise/home/etaylor/code_projects/thesis/segments/etaylor_cannabis_patches_train_26-04-2024_15-44-44/ground_truth_trichomes_datasets/trichome_dataset_125_good_quality/train_test_balanced/val... 223 images, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 223/223 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000714, momentum=0.9) with parameter groups 38 weight(decay=0.0), 39 weight(decay=0.0005), 39 bias(decay=0.0)\n",
      "Image sizes 128 train, 128 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1m/home/etaylor/runs/classify/train13\u001b[0m\n",
      "Starting training for 10 epochs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/etaylor/.conda/envs/yolo8/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 6, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/10     0.904G      1.025          8        128: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 38/38 [00:01<00:00, 19.05it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:00<00:00, 33.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.726          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/10     0.885G     0.6157          8        128: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 38/38 [00:01<00:00, 29.18it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:00<00:00, 101.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.785          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/10     0.885G     0.4621          8        128: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 38/38 [00:01<00:00, 31.42it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:00<00:00, 80.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       0.91          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/10     0.885G     0.4284          8        128: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 38/38 [00:01<00:00, 32.11it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:00<00:00, 91.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.888          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/10     0.885G     0.3553          8        128: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 38/38 [00:01<00:00, 31.08it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:00<00:00, 88.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.915          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/10     0.885G     0.3887          8        128: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 38/38 [00:01<00:00, 32.73it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:00<00:00, 83.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.924          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/10     0.885G     0.3775          8        128: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 38/38 [00:01<00:00, 32.36it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:00<00:00, 88.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.919          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/10     0.885G     0.3692          8        128: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 38/38 [00:01<00:00, 31.72it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:00<00:00, 83.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.924          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/10     0.885G     0.3692          8        128: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 38/38 [00:01<00:00, 31.33it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:00<00:00, 85.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.942          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/10     0.885G      0.295          8        128: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 38/38 [00:01<00:00, 30.68it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:00<00:00, 82.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.928          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "10 epochs completed in 0.028 hours.\n",
      "Optimizer stripped from /home/etaylor/runs/classify/train13/weights/last.pt, 31.7MB\n",
      "Optimizer stripped from /home/etaylor/runs/classify/train13/weights/best.pt, 31.7MB\n",
      "\n",
      "Validating /home/etaylor/runs/classify/train13/weights/best.pt...\n",
      "Ultralytics 8.3.27 ðŸš€ Python-3.10.13 torch-2.1.1+cu121 CUDA:0 (NVIDIA GeForce RTX 3090, 24161MiB)\n",
      "YOLOv8m-cls summary (fused): 103 layers, 15,766,499 parameters, 0 gradients, 41.6 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m /sise/home/etaylor/code_projects/thesis/segments/etaylor_cannabis_patches_train_26-04-2024_15-44-44/ground_truth_trichomes_datasets/trichome_dataset_125_good_quality/train_test_balanced/train... found 600 images in 3 classes âœ… \n",
      "\u001b[34m\u001b[1mval:\u001b[0m /sise/home/etaylor/code_projects/thesis/segments/etaylor_cannabis_patches_train_26-04-2024_15-44-44/ground_truth_trichomes_datasets/trichome_dataset_125_good_quality/train_test_balanced/val... found 223 images in 3 classes âœ… \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m /sise/home/etaylor/code_projects/thesis/segments/etaylor_cannabis_patches_train_26-04-2024_15-44-44/ground_truth_trichomes_datasets/trichome_dataset_125_good_quality/train_test_balanced/test... found 54 images in 3 classes âœ… \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:00<00:00, 13.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.942          1\n",
      "Speed: 0.0ms preprocess, 2.2ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1m/home/etaylor/runs/classify/train13\u001b[0m\n",
      "Evaluating YOLOv8 Medium model...\n",
      "\n",
      "0: 128x128 amber 0.91, cloudy 0.08, clear 0.01, 4.9ms\n",
      "Speed: 1.6ms preprocess, 4.9ms inference, 0.1ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 amber 0.84, cloudy 0.16, clear 0.00, 4.9ms\n",
      "Speed: 1.4ms preprocess, 4.9ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 cloudy 0.51, amber 0.49, clear 0.00, 4.9ms\n",
      "Speed: 1.4ms preprocess, 4.9ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 amber 1.00, cloudy 0.00, clear 0.00, 5.1ms\n",
      "Speed: 1.4ms preprocess, 5.1ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 amber 0.95, cloudy 0.05, clear 0.00, 5.0ms\n",
      "Speed: 1.3ms preprocess, 5.0ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 amber 1.00, cloudy 0.00, clear 0.00, 5.0ms\n",
      "Speed: 1.3ms preprocess, 5.0ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 amber 1.00, cloudy 0.00, clear 0.00, 5.1ms\n",
      "Speed: 1.4ms preprocess, 5.1ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 amber 0.99, cloudy 0.01, clear 0.00, 4.9ms\n",
      "Speed: 1.4ms preprocess, 4.9ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 amber 0.99, cloudy 0.01, clear 0.00, 5.2ms\n",
      "Speed: 1.4ms preprocess, 5.2ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 amber 0.99, cloudy 0.01, clear 0.00, 5.1ms\n",
      "Speed: 1.5ms preprocess, 5.1ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 amber 0.87, cloudy 0.13, clear 0.00, 4.9ms\n",
      "Speed: 1.3ms preprocess, 4.9ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 amber 0.99, cloudy 0.01, clear 0.00, 5.1ms\n",
      "Speed: 1.4ms preprocess, 5.1ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 amber 1.00, cloudy 0.00, clear 0.00, 5.1ms\n",
      "Speed: 1.4ms preprocess, 5.1ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 amber 0.97, cloudy 0.03, clear 0.00, 4.9ms\n",
      "Speed: 1.4ms preprocess, 4.9ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 amber 1.00, cloudy 0.00, clear 0.00, 5.0ms\n",
      "Speed: 1.4ms preprocess, 5.0ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 cloudy 0.63, amber 0.37, clear 0.01, 4.9ms\n",
      "Speed: 1.4ms preprocess, 4.9ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 amber 1.00, cloudy 0.00, clear 0.00, 4.9ms\n",
      "Speed: 1.4ms preprocess, 4.9ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 amber 0.99, cloudy 0.01, clear 0.00, 5.0ms\n",
      "Speed: 1.5ms preprocess, 5.0ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 cloudy 0.67, amber 0.22, clear 0.11, 5.0ms\n",
      "Speed: 1.4ms preprocess, 5.0ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 clear 0.64, cloudy 0.35, amber 0.01, 5.0ms\n",
      "Speed: 1.5ms preprocess, 5.0ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 clear 1.00, amber 0.00, cloudy 0.00, 5.0ms\n",
      "Speed: 1.4ms preprocess, 5.0ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 clear 0.96, cloudy 0.03, amber 0.00, 5.0ms\n",
      "Speed: 1.4ms preprocess, 5.0ms inference, 0.1ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 cloudy 0.56, clear 0.43, amber 0.00, 4.9ms\n",
      "Speed: 1.4ms preprocess, 4.9ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 cloudy 0.79, clear 0.21, amber 0.00, 5.0ms\n",
      "Speed: 1.4ms preprocess, 5.0ms inference, 0.1ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 clear 0.99, cloudy 0.00, amber 0.00, 4.9ms\n",
      "Speed: 1.3ms preprocess, 4.9ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 clear 0.99, cloudy 0.01, amber 0.00, 5.0ms\n",
      "Speed: 1.4ms preprocess, 5.0ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 clear 1.00, cloudy 0.00, amber 0.00, 5.0ms\n",
      "Speed: 1.4ms preprocess, 5.0ms inference, 0.1ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 clear 0.99, cloudy 0.00, amber 0.00, 5.1ms\n",
      "Speed: 1.4ms preprocess, 5.1ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 cloudy 1.00, amber 0.00, clear 0.00, 4.9ms\n",
      "Speed: 1.3ms preprocess, 4.9ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 cloudy 0.92, amber 0.04, clear 0.04, 5.0ms\n",
      "Speed: 1.5ms preprocess, 5.0ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 cloudy 0.82, clear 0.18, amber 0.00, 5.0ms\n",
      "Speed: 1.4ms preprocess, 5.0ms inference, 0.1ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 cloudy 1.00, amber 0.00, clear 0.00, 4.9ms\n",
      "Speed: 1.4ms preprocess, 4.9ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 cloudy 0.93, amber 0.06, clear 0.02, 5.0ms\n",
      "Speed: 1.4ms preprocess, 5.0ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 cloudy 0.97, clear 0.02, amber 0.01, 4.9ms\n",
      "Speed: 1.4ms preprocess, 4.9ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 cloudy 0.71, clear 0.27, amber 0.01, 5.0ms\n",
      "Speed: 1.4ms preprocess, 5.0ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 cloudy 0.61, clear 0.36, amber 0.04, 5.0ms\n",
      "Speed: 1.4ms preprocess, 5.0ms inference, 0.1ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 cloudy 0.99, amber 0.01, clear 0.00, 5.1ms\n",
      "Speed: 1.4ms preprocess, 5.1ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 clear 0.76, cloudy 0.24, amber 0.00, 4.9ms\n",
      "Speed: 1.4ms preprocess, 4.9ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 cloudy 0.95, clear 0.04, amber 0.01, 5.0ms\n",
      "Speed: 1.3ms preprocess, 5.0ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 amber 0.52, cloudy 0.48, clear 0.00, 4.9ms\n",
      "Speed: 1.5ms preprocess, 4.9ms inference, 0.1ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 cloudy 0.95, clear 0.04, amber 0.01, 5.1ms\n",
      "Speed: 1.4ms preprocess, 5.1ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 cloudy 0.99, clear 0.01, amber 0.00, 4.9ms\n",
      "Speed: 1.2ms preprocess, 4.9ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 cloudy 0.98, amber 0.01, clear 0.01, 4.9ms\n",
      "Speed: 1.4ms preprocess, 4.9ms inference, 0.1ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 cloudy 0.57, amber 0.28, clear 0.15, 4.9ms\n",
      "Speed: 1.4ms preprocess, 4.9ms inference, 0.1ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 clear 0.69, cloudy 0.31, amber 0.00, 4.9ms\n",
      "Speed: 1.4ms preprocess, 4.9ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 cloudy 0.88, clear 0.12, amber 0.00, 4.9ms\n",
      "Speed: 1.4ms preprocess, 4.9ms inference, 0.1ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 cloudy 0.88, clear 0.12, amber 0.01, 4.9ms\n",
      "Speed: 1.4ms preprocess, 4.9ms inference, 0.1ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 cloudy 1.00, amber 0.00, clear 0.00, 5.1ms\n",
      "Speed: 1.4ms preprocess, 5.1ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 cloudy 0.92, amber 0.07, clear 0.02, 5.0ms\n",
      "Speed: 1.4ms preprocess, 5.0ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 cloudy 0.70, clear 0.23, amber 0.06, 5.2ms\n",
      "Speed: 1.4ms preprocess, 5.2ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 cloudy 1.00, amber 0.00, clear 0.00, 5.1ms\n",
      "Speed: 1.4ms preprocess, 5.1ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 cloudy 0.66, clear 0.34, amber 0.00, 5.1ms\n",
      "Speed: 1.3ms preprocess, 5.1ms inference, 0.1ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 cloudy 1.00, amber 0.00, clear 0.00, 5.2ms\n",
      "Speed: 1.4ms preprocess, 5.2ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 cloudy 1.00, clear 0.00, amber 0.00, 5.1ms\n",
      "Speed: 1.4ms preprocess, 5.1ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       amber       0.94      0.89      0.91        18\n",
      "       clear       0.78      0.70      0.74        10\n",
      "      cloudy       0.82      0.88      0.85        26\n",
      "\n",
      "    accuracy                           0.85        54\n",
      "   macro avg       0.85      0.82      0.83        54\n",
      "weighted avg       0.85      0.85      0.85        54\n",
      "\n",
      "Accuracy: 0.8518518518518519\n",
      "Confusion Matrix:\n",
      " [[16  0  2]\n",
      " [ 0  7  3]\n",
      " [ 1  2 23]]\n",
      "Training YOLOv8 Large model...\n",
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8l-cls.pt to 'yolov8l-cls.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 71.7M/71.7M [00:03<00:00, 23.2MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.27 ðŸš€ Python-3.10.13 torch-2.1.1+cu121 CUDA:0 (NVIDIA GeForce RTX 3090, 24161MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=classify, mode=train, model=yolov8l-cls.pt, data=/home/etaylor/code_projects/thesis/segments/etaylor_cannabis_patches_train_26-04-2024_15-44-44/ground_truth_trichomes_datasets/trichome_dataset_125_good_quality/train_test_balanced, epochs=10, time=None, patience=100, batch=16, imgsz=128, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train14, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=/home/etaylor/runs/classify/train14\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m /sise/home/etaylor/code_projects/thesis/segments/etaylor_cannabis_patches_train_26-04-2024_15-44-44/ground_truth_trichomes_datasets/trichome_dataset_125_good_quality/train_test_balanced/train... found 600 images in 3 classes âœ… \n",
      "\u001b[34m\u001b[1mval:\u001b[0m /sise/home/etaylor/code_projects/thesis/segments/etaylor_cannabis_patches_train_26-04-2024_15-44-44/ground_truth_trichomes_datasets/trichome_dataset_125_good_quality/train_test_balanced/val... found 223 images in 3 classes âœ… \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m /sise/home/etaylor/code_projects/thesis/segments/etaylor_cannabis_patches_train_26-04-2024_15-44-44/ground_truth_trichomes_datasets/trichome_dataset_125_good_quality/train_test_balanced/test... found 54 images in 3 classes âœ… \n",
      "Overriding model.yaml nc=1000 with nc=3\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
      "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  2                  -1  3    279808  ultralytics.nn.modules.block.C2f             [128, 128, 3, True]           \n",
      "  3                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  4                  -1  6   2101248  ultralytics.nn.modules.block.C2f             [256, 256, 6, True]           \n",
      "  5                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  6                  -1  6   8396800  ultralytics.nn.modules.block.C2f             [512, 512, 6, True]           \n",
      "  7                  -1  1   4720640  ultralytics.nn.modules.conv.Conv             [512, 1024, 3, 2]             \n",
      "  8                  -1  3  17836032  ultralytics.nn.modules.block.C2f             [1024, 1024, 3, True]         \n",
      "  9                  -1  1   1317123  ultralytics.nn.modules.head.Classify         [1024, 3]                     \n",
      "YOLOv8l-cls summary: 183 layers, 36,203,587 parameters, 36,203,587 gradients, 99.1 GFLOPs\n",
      "Transferred 300/302 items from pretrained weights\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /sise/home/etaylor/code_projects/thesis/segments/etaylor_cannabis_patches_train_26-04-2024_15-44-44/ground_truth_trichomes_datasets/trichome_dataset_125_good_quality/train_test_balanced/train... 600 images, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 600/600 [00:00<?, ?it/s]\n",
      "/home/etaylor/.conda/envs/yolo8/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 6, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /sise/home/etaylor/code_projects/thesis/segments/etaylor_cannabis_patches_train_26-04-2024_15-44-44/ground_truth_trichomes_datasets/trichome_dataset_125_good_quality/train_test_balanced/val... 223 images, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 223/223 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000714, momentum=0.9) with parameter groups 50 weight(decay=0.0), 51 weight(decay=0.0005), 51 bias(decay=0.0)\n",
      "Image sizes 128 train, 128 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1m/home/etaylor/runs/classify/train14\u001b[0m\n",
      "Starting training for 10 epochs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/etaylor/.conda/envs/yolo8/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 6, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/10      1.74G      1.001          8        128: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 38/38 [00:02<00:00, 14.98it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:00<00:00, 28.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.744          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/10      1.71G     0.6104          8        128: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 38/38 [00:01<00:00, 23.00it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:00<00:00, 68.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.906          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/10      1.71G      0.411          8        128: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 38/38 [00:01<00:00, 24.59it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:00<00:00, 72.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.946          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/10      1.71G     0.3627          8        128: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 38/38 [00:01<00:00, 25.30it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:00<00:00, 76.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.942          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/10      1.71G     0.2772          8        128: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 38/38 [00:01<00:00, 24.85it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:00<00:00, 64.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.897          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/10      1.71G     0.2733          8        128: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 38/38 [00:01<00:00, 25.96it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:00<00:00, 78.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.928          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/10      1.71G     0.2666          8        128: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 38/38 [00:01<00:00, 25.41it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:00<00:00, 71.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       0.91          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/10      1.71G       0.25          8        128: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 38/38 [00:01<00:00, 25.39it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:00<00:00, 64.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.928          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/10      1.71G     0.2777          8        128: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 38/38 [00:01<00:00, 25.21it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:00<00:00, 64.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.946          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/10      1.71G      0.227          8        128: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 38/38 [00:01<00:00, 25.94it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:00<00:00, 76.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.942          1\n",
      "\n",
      "10 epochs completed in 0.030 hours.\n",
      "Optimizer stripped from /home/etaylor/runs/classify/train14/weights/last.pt, 72.6MB\n",
      "Optimizer stripped from /home/etaylor/runs/classify/train14/weights/best.pt, 72.6MB\n",
      "\n",
      "Validating /home/etaylor/runs/classify/train14/weights/best.pt...\n",
      "Ultralytics 8.3.27 ðŸš€ Python-3.10.13 torch-2.1.1+cu121 CUDA:0 (NVIDIA GeForce RTX 3090, 24161MiB)\n",
      "YOLOv8l-cls summary (fused): 133 layers, 36,188,419 parameters, 0 gradients, 98.7 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m /sise/home/etaylor/code_projects/thesis/segments/etaylor_cannabis_patches_train_26-04-2024_15-44-44/ground_truth_trichomes_datasets/trichome_dataset_125_good_quality/train_test_balanced/train... found 600 images in 3 classes âœ… \n",
      "\u001b[34m\u001b[1mval:\u001b[0m /sise/home/etaylor/code_projects/thesis/segments/etaylor_cannabis_patches_train_26-04-2024_15-44-44/ground_truth_trichomes_datasets/trichome_dataset_125_good_quality/train_test_balanced/val... found 223 images in 3 classes âœ… \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m /sise/home/etaylor/code_projects/thesis/segments/etaylor_cannabis_patches_train_26-04-2024_15-44-44/ground_truth_trichomes_datasets/trichome_dataset_125_good_quality/train_test_balanced/test... found 54 images in 3 classes âœ… \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:00<00:00, 13.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.946          1\n",
      "Speed: 0.0ms preprocess, 2.3ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1m/home/etaylor/runs/classify/train14\u001b[0m\n",
      "Evaluating YOLOv8 Large model...\n",
      "\n",
      "0: 128x128 amber 0.97, cloudy 0.02, clear 0.01, 6.6ms\n",
      "Speed: 1.6ms preprocess, 6.6ms inference, 0.1ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 amber 0.98, cloudy 0.02, clear 0.00, 7.3ms\n",
      "Speed: 1.8ms preprocess, 7.3ms inference, 0.1ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 amber 0.98, cloudy 0.02, clear 0.00, 6.8ms\n",
      "Speed: 1.4ms preprocess, 6.8ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 amber 1.00, cloudy 0.00, clear 0.00, 6.6ms\n",
      "Speed: 1.4ms preprocess, 6.6ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 amber 0.73, cloudy 0.26, clear 0.01, 6.7ms\n",
      "Speed: 1.4ms preprocess, 6.7ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 amber 0.99, cloudy 0.01, clear 0.00, 6.8ms\n",
      "Speed: 1.4ms preprocess, 6.8ms inference, 0.1ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 amber 1.00, clear 0.00, cloudy 0.00, 6.9ms\n",
      "Speed: 1.7ms preprocess, 6.9ms inference, 0.1ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 amber 0.99, clear 0.01, cloudy 0.00, 6.7ms\n",
      "Speed: 1.4ms preprocess, 6.7ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 amber 1.00, cloudy 0.00, clear 0.00, 6.7ms\n",
      "Speed: 1.5ms preprocess, 6.7ms inference, 0.1ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 amber 0.94, cloudy 0.05, clear 0.01, 6.9ms\n",
      "Speed: 1.5ms preprocess, 6.9ms inference, 0.1ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 amber 0.98, cloudy 0.01, clear 0.00, 6.6ms\n",
      "Speed: 1.5ms preprocess, 6.6ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 amber 0.99, cloudy 0.01, clear 0.00, 7.2ms\n",
      "Speed: 1.5ms preprocess, 7.2ms inference, 0.1ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 amber 0.99, cloudy 0.01, clear 0.00, 6.7ms\n",
      "Speed: 1.6ms preprocess, 6.7ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 amber 0.92, cloudy 0.05, clear 0.03, 6.6ms\n",
      "Speed: 1.4ms preprocess, 6.6ms inference, 0.1ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 amber 1.00, cloudy 0.00, clear 0.00, 6.8ms\n",
      "Speed: 1.4ms preprocess, 6.8ms inference, 0.1ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 amber 0.80, cloudy 0.20, clear 0.00, 6.6ms\n",
      "Speed: 1.4ms preprocess, 6.6ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 amber 1.00, cloudy 0.00, clear 0.00, 7.0ms\n",
      "Speed: 1.5ms preprocess, 7.0ms inference, 0.1ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 amber 1.00, cloudy 0.00, clear 0.00, 6.8ms\n",
      "Speed: 1.4ms preprocess, 6.8ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 cloudy 0.86, clear 0.09, amber 0.05, 6.7ms\n",
      "Speed: 1.5ms preprocess, 6.7ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 cloudy 0.80, clear 0.20, amber 0.01, 7.1ms\n",
      "Speed: 1.4ms preprocess, 7.1ms inference, 0.1ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 clear 1.00, cloudy 0.00, amber 0.00, 6.7ms\n",
      "Speed: 1.4ms preprocess, 6.7ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 clear 1.00, cloudy 0.00, amber 0.00, 6.8ms\n",
      "Speed: 1.4ms preprocess, 6.8ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 clear 0.98, cloudy 0.02, amber 0.00, 6.9ms\n",
      "Speed: 1.5ms preprocess, 6.9ms inference, 0.1ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 cloudy 0.93, clear 0.07, amber 0.00, 6.7ms\n",
      "Speed: 1.5ms preprocess, 6.7ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 clear 1.00, cloudy 0.00, amber 0.00, 6.7ms\n",
      "Speed: 1.5ms preprocess, 6.7ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 clear 0.96, cloudy 0.04, amber 0.00, 6.8ms\n",
      "Speed: 1.6ms preprocess, 6.8ms inference, 0.1ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 clear 0.96, cloudy 0.04, amber 0.00, 6.8ms\n",
      "Speed: 1.4ms preprocess, 6.8ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 clear 1.00, amber 0.00, cloudy 0.00, 7.3ms\n",
      "Speed: 1.9ms preprocess, 7.3ms inference, 0.1ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 cloudy 1.00, amber 0.00, clear 0.00, 6.9ms\n",
      "Speed: 1.5ms preprocess, 6.9ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 cloudy 0.96, clear 0.02, amber 0.02, 6.9ms\n",
      "Speed: 1.5ms preprocess, 6.9ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 clear 0.66, cloudy 0.33, amber 0.00, 6.9ms\n",
      "Speed: 1.4ms preprocess, 6.9ms inference, 0.1ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 cloudy 1.00, amber 0.00, clear 0.00, 6.7ms\n",
      "Speed: 1.5ms preprocess, 6.7ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 cloudy 0.97, clear 0.03, amber 0.00, 7.6ms\n",
      "Speed: 1.9ms preprocess, 7.6ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 cloudy 0.93, clear 0.05, amber 0.01, 7.0ms\n",
      "Speed: 1.5ms preprocess, 7.0ms inference, 0.1ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 cloudy 0.86, clear 0.12, amber 0.02, 6.9ms\n",
      "Speed: 1.5ms preprocess, 6.9ms inference, 0.1ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 cloudy 0.56, clear 0.30, amber 0.14, 6.8ms\n",
      "Speed: 1.4ms preprocess, 6.8ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 cloudy 1.00, amber 0.00, clear 0.00, 6.8ms\n",
      "Speed: 1.4ms preprocess, 6.8ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 clear 0.95, cloudy 0.05, amber 0.00, 6.7ms\n",
      "Speed: 1.4ms preprocess, 6.7ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 cloudy 0.83, clear 0.15, amber 0.02, 6.8ms\n",
      "Speed: 1.4ms preprocess, 6.8ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 amber 0.76, cloudy 0.23, clear 0.01, 9.1ms\n",
      "Speed: 2.3ms preprocess, 9.1ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 cloudy 0.98, clear 0.02, amber 0.00, 6.7ms\n",
      "Speed: 1.5ms preprocess, 6.7ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 cloudy 0.94, clear 0.06, amber 0.00, 7.0ms\n",
      "Speed: 1.5ms preprocess, 7.0ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 cloudy 0.99, clear 0.01, amber 0.00, 6.6ms\n",
      "Speed: 1.4ms preprocess, 6.6ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 cloudy 0.89, amber 0.07, clear 0.04, 6.7ms\n",
      "Speed: 1.4ms preprocess, 6.7ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 clear 0.91, cloudy 0.09, amber 0.00, 6.8ms\n",
      "Speed: 1.4ms preprocess, 6.8ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 cloudy 0.70, clear 0.29, amber 0.01, 6.7ms\n",
      "Speed: 1.4ms preprocess, 6.7ms inference, 0.1ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 cloudy 0.93, clear 0.07, amber 0.00, 6.8ms\n",
      "Speed: 1.8ms preprocess, 6.8ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 cloudy 1.00, amber 0.00, clear 0.00, 7.6ms\n",
      "Speed: 1.9ms preprocess, 7.6ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 cloudy 0.98, clear 0.01, amber 0.01, 7.3ms\n",
      "Speed: 1.6ms preprocess, 7.3ms inference, 0.1ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 cloudy 0.95, amber 0.04, clear 0.02, 6.7ms\n",
      "Speed: 1.5ms preprocess, 6.7ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 cloudy 1.00, amber 0.00, clear 0.00, 6.6ms\n",
      "Speed: 1.5ms preprocess, 6.6ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 cloudy 0.98, clear 0.02, amber 0.00, 6.8ms\n",
      "Speed: 1.5ms preprocess, 6.8ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 cloudy 1.00, clear 0.00, amber 0.00, 7.2ms\n",
      "Speed: 1.5ms preprocess, 7.2ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 cloudy 0.85, clear 0.15, amber 0.00, 6.9ms\n",
      "Speed: 1.5ms preprocess, 6.9ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       amber       0.95      1.00      0.97        18\n",
      "       clear       0.70      0.70      0.70        10\n",
      "      cloudy       0.88      0.85      0.86        26\n",
      "\n",
      "    accuracy                           0.87        54\n",
      "   macro avg       0.84      0.85      0.85        54\n",
      "weighted avg       0.87      0.87      0.87        54\n",
      "\n",
      "Accuracy: 0.8703703703703703\n",
      "Confusion Matrix:\n",
      " [[18  0  0]\n",
      " [ 0  7  3]\n",
      " [ 1  3 22]]\n",
      "Training YOLOv8 XLarge model...\n",
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8x-cls.pt to 'yolov8x-cls.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 110M/110M [00:03<00:00, 29.7MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.27 ðŸš€ Python-3.10.13 torch-2.1.1+cu121 CUDA:0 (NVIDIA GeForce RTX 3090, 24161MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=classify, mode=train, model=yolov8x-cls.pt, data=/home/etaylor/code_projects/thesis/segments/etaylor_cannabis_patches_train_26-04-2024_15-44-44/ground_truth_trichomes_datasets/trichome_dataset_125_good_quality/train_test_balanced, epochs=10, time=None, patience=100, batch=16, imgsz=128, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train15, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=/home/etaylor/runs/classify/train15\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m /sise/home/etaylor/code_projects/thesis/segments/etaylor_cannabis_patches_train_26-04-2024_15-44-44/ground_truth_trichomes_datasets/trichome_dataset_125_good_quality/train_test_balanced/train... found 600 images in 3 classes âœ… \n",
      "\u001b[34m\u001b[1mval:\u001b[0m /sise/home/etaylor/code_projects/thesis/segments/etaylor_cannabis_patches_train_26-04-2024_15-44-44/ground_truth_trichomes_datasets/trichome_dataset_125_good_quality/train_test_balanced/val... found 223 images in 3 classes âœ… \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m /sise/home/etaylor/code_projects/thesis/segments/etaylor_cannabis_patches_train_26-04-2024_15-44-44/ground_truth_trichomes_datasets/trichome_dataset_125_good_quality/train_test_balanced/test... found 54 images in 3 classes âœ… \n",
      "Overriding model.yaml nc=1000 with nc=3\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      2320  ultralytics.nn.modules.conv.Conv             [3, 80, 3, 2]                 \n",
      "  1                  -1  1    115520  ultralytics.nn.modules.conv.Conv             [80, 160, 3, 2]               \n",
      "  2                  -1  3    436800  ultralytics.nn.modules.block.C2f             [160, 160, 3, True]           \n",
      "  3                  -1  1    461440  ultralytics.nn.modules.conv.Conv             [160, 320, 3, 2]              \n",
      "  4                  -1  6   3281920  ultralytics.nn.modules.block.C2f             [320, 320, 6, True]           \n",
      "  5                  -1  1   1844480  ultralytics.nn.modules.conv.Conv             [320, 640, 3, 2]              \n",
      "  6                  -1  6  13117440  ultralytics.nn.modules.block.C2f             [640, 640, 6, True]           \n",
      "  7                  -1  1   7375360  ultralytics.nn.modules.conv.Conv             [640, 1280, 3, 2]             \n",
      "  8                  -1  3  27865600  ultralytics.nn.modules.block.C2f             [1280, 1280, 3, True]         \n",
      "  9                  -1  1   1644803  ultralytics.nn.modules.head.Classify         [1280, 3]                     \n",
      "YOLOv8x-cls summary: 183 layers, 56,145,683 parameters, 56,145,683 gradients, 154.3 GFLOPs\n",
      "Transferred 300/302 items from pretrained weights\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /sise/home/etaylor/code_projects/thesis/segments/etaylor_cannabis_patches_train_26-04-2024_15-44-44/ground_truth_trichomes_datasets/trichome_dataset_125_good_quality/train_test_balanced/train... 600 images, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 600/600 [00:00<?, ?it/s]\n",
      "/home/etaylor/.conda/envs/yolo8/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 6, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /sise/home/etaylor/code_projects/thesis/segments/etaylor_cannabis_patches_train_26-04-2024_15-44-44/ground_truth_trichomes_datasets/trichome_dataset_125_good_quality/train_test_balanced/val... 223 images, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 223/223 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000714, momentum=0.9) with parameter groups 50 weight(decay=0.0), 51 weight(decay=0.0005), 51 bias(decay=0.0)\n",
      "Image sizes 128 train, 128 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1m/home/etaylor/runs/classify/train15\u001b[0m\n",
      "Starting training for 10 epochs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/etaylor/.conda/envs/yolo8/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 6, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/10         3G      1.007          8        128: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 38/38 [00:02<00:00, 15.82it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:00<00:00, 18.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.695          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/10      2.84G     0.6552          8        128: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 38/38 [00:01<00:00, 23.21it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:00<00:00, 67.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.901          1\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/10       2.7G     0.4613          8        128: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 38/38 [00:01<00:00, 25.32it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:00<00:00, 73.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.919          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/10      2.71G     0.3632          8        128: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 38/38 [00:01<00:00, 24.87it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:00<00:00, 66.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.937          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/10      2.67G     0.2837          8        128: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 38/38 [00:01<00:00, 24.80it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:00<00:00, 66.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.955          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/10      2.65G     0.3383          8        128: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 38/38 [00:01<00:00, 24.82it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:00<00:00, 66.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.937          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/10      2.62G     0.2943          8        128: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 38/38 [00:01<00:00, 24.93it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:00<00:00, 65.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.906          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/10      2.63G     0.2528          8        128: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 38/38 [00:01<00:00, 24.94it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:00<00:00, 71.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.942          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/10      2.62G     0.2758          8        128: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 38/38 [00:01<00:00, 24.81it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:00<00:00, 71.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.928          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/10      2.63G     0.2248          8        128: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 38/38 [00:01<00:00, 24.44it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:00<00:00, 69.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.937          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "10 epochs completed in 0.032 hours.\n",
      "Optimizer stripped from /home/etaylor/runs/classify/train15/weights/last.pt, 112.5MB\n",
      "Optimizer stripped from /home/etaylor/runs/classify/train15/weights/best.pt, 112.5MB\n",
      "\n",
      "Validating /home/etaylor/runs/classify/train15/weights/best.pt...\n",
      "Ultralytics 8.3.27 ðŸš€ Python-3.10.13 torch-2.1.1+cu121 CUDA:0 (NVIDIA GeForce RTX 3090, 24161MiB)\n",
      "YOLOv8x-cls summary (fused): 133 layers, 56,127,043 parameters, 0 gradients, 153.8 GFLOPs\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m /sise/home/etaylor/code_projects/thesis/segments/etaylor_cannabis_patches_train_26-04-2024_15-44-44/ground_truth_trichomes_datasets/trichome_dataset_125_good_quality/train_test_balanced/train... found 600 images in 3 classes âœ… \n",
      "\u001b[34m\u001b[1mval:\u001b[0m /sise/home/etaylor/code_projects/thesis/segments/etaylor_cannabis_patches_train_26-04-2024_15-44-44/ground_truth_trichomes_datasets/trichome_dataset_125_good_quality/train_test_balanced/val... found 223 images in 3 classes âœ… \n",
      "\u001b[34m\u001b[1mtest:\u001b[0m /sise/home/etaylor/code_projects/thesis/segments/etaylor_cannabis_patches_train_26-04-2024_15-44-44/ground_truth_trichomes_datasets/trichome_dataset_125_good_quality/train_test_balanced/test... found 54 images in 3 classes âœ… \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:00<00:00, 13.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.951          1\n",
      "Speed: 0.0ms preprocess, 2.3ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1m/home/etaylor/runs/classify/train15\u001b[0m\n",
      "Evaluating YOLOv8 XLarge model...\n",
      "\n",
      "0: 128x128 amber 1.00, cloudy 0.00, clear 0.00, 6.9ms\n",
      "Speed: 1.8ms preprocess, 6.9ms inference, 0.1ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 amber 0.91, cloudy 0.08, clear 0.00, 7.0ms\n",
      "Speed: 1.6ms preprocess, 7.0ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 amber 0.98, cloudy 0.01, clear 0.00, 6.9ms\n",
      "Speed: 1.4ms preprocess, 6.9ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 amber 1.00, cloudy 0.00, clear 0.00, 7.1ms\n",
      "Speed: 1.3ms preprocess, 7.1ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 amber 0.88, cloudy 0.11, clear 0.02, 7.7ms\n",
      "Speed: 1.7ms preprocess, 7.7ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 amber 1.00, cloudy 0.00, clear 0.00, 6.9ms\n",
      "Speed: 1.2ms preprocess, 6.9ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 amber 1.00, cloudy 0.00, clear 0.00, 7.0ms\n",
      "Speed: 1.4ms preprocess, 7.0ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 amber 1.00, cloudy 0.00, clear 0.00, 6.9ms\n",
      "Speed: 1.4ms preprocess, 6.9ms inference, 0.1ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 amber 1.00, cloudy 0.00, clear 0.00, 6.9ms\n",
      "Speed: 1.5ms preprocess, 6.9ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 amber 0.99, cloudy 0.01, clear 0.00, 6.9ms\n",
      "Speed: 1.4ms preprocess, 6.9ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 amber 0.99, cloudy 0.01, clear 0.00, 7.0ms\n",
      "Speed: 1.4ms preprocess, 7.0ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 amber 1.00, cloudy 0.00, clear 0.00, 7.0ms\n",
      "Speed: 1.4ms preprocess, 7.0ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 amber 0.94, cloudy 0.06, clear 0.00, 7.0ms\n",
      "Speed: 1.5ms preprocess, 7.0ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 amber 1.00, cloudy 0.00, clear 0.00, 7.1ms\n",
      "Speed: 1.5ms preprocess, 7.1ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 amber 1.00, cloudy 0.00, clear 0.00, 6.9ms\n",
      "Speed: 1.5ms preprocess, 6.9ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 amber 0.58, cloudy 0.41, clear 0.00, 7.0ms\n",
      "Speed: 1.3ms preprocess, 7.0ms inference, 0.1ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 amber 1.00, cloudy 0.00, clear 0.00, 7.1ms\n",
      "Speed: 1.4ms preprocess, 7.1ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 amber 1.00, cloudy 0.00, clear 0.00, 7.2ms\n",
      "Speed: 1.6ms preprocess, 7.2ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 cloudy 0.85, amber 0.09, clear 0.07, 7.6ms\n",
      "Speed: 1.9ms preprocess, 7.6ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 cloudy 0.63, clear 0.37, amber 0.00, 7.9ms\n",
      "Speed: 1.5ms preprocess, 7.9ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 clear 1.00, cloudy 0.00, amber 0.00, 7.6ms\n",
      "Speed: 1.4ms preprocess, 7.6ms inference, 0.1ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 clear 0.94, cloudy 0.05, amber 0.00, 7.4ms\n",
      "Speed: 1.5ms preprocess, 7.4ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 clear 0.73, cloudy 0.27, amber 0.00, 6.9ms\n",
      "Speed: 1.2ms preprocess, 6.9ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 cloudy 0.79, clear 0.20, amber 0.00, 7.1ms\n",
      "Speed: 1.4ms preprocess, 7.1ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 clear 0.97, cloudy 0.03, amber 0.00, 7.0ms\n",
      "Speed: 1.3ms preprocess, 7.0ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 clear 0.99, cloudy 0.01, amber 0.00, 7.1ms\n",
      "Speed: 1.5ms preprocess, 7.1ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 clear 0.68, cloudy 0.32, amber 0.00, 7.2ms\n",
      "Speed: 1.6ms preprocess, 7.2ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 clear 0.91, cloudy 0.09, amber 0.00, 7.1ms\n",
      "Speed: 1.3ms preprocess, 7.1ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 cloudy 0.99, clear 0.01, amber 0.00, 7.1ms\n",
      "Speed: 1.4ms preprocess, 7.1ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 cloudy 0.97, clear 0.03, amber 0.00, 6.9ms\n",
      "Speed: 1.5ms preprocess, 6.9ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 clear 0.95, cloudy 0.05, amber 0.00, 7.0ms\n",
      "Speed: 1.4ms preprocess, 7.0ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 cloudy 1.00, clear 0.00, amber 0.00, 7.0ms\n",
      "Speed: 1.4ms preprocess, 7.0ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 cloudy 0.97, clear 0.03, amber 0.00, 7.1ms\n",
      "Speed: 1.4ms preprocess, 7.1ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 cloudy 0.82, clear 0.16, amber 0.02, 7.0ms\n",
      "Speed: 1.3ms preprocess, 7.0ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 cloudy 0.74, clear 0.25, amber 0.01, 7.0ms\n",
      "Speed: 1.4ms preprocess, 7.0ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 cloudy 0.72, clear 0.25, amber 0.03, 7.0ms\n",
      "Speed: 1.4ms preprocess, 7.0ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 cloudy 0.99, clear 0.00, amber 0.00, 7.0ms\n",
      "Speed: 1.4ms preprocess, 7.0ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 cloudy 0.55, clear 0.44, amber 0.00, 7.0ms\n",
      "Speed: 1.4ms preprocess, 7.0ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 cloudy 0.86, clear 0.13, amber 0.00, 7.3ms\n",
      "Speed: 1.5ms preprocess, 7.3ms inference, 0.1ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 amber 0.94, cloudy 0.06, clear 0.00, 7.3ms\n",
      "Speed: 1.7ms preprocess, 7.3ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 cloudy 0.98, clear 0.02, amber 0.00, 8.0ms\n",
      "Speed: 1.6ms preprocess, 8.0ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 cloudy 0.68, clear 0.32, amber 0.00, 7.0ms\n",
      "Speed: 1.4ms preprocess, 7.0ms inference, 0.1ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 cloudy 0.99, clear 0.01, amber 0.00, 6.9ms\n",
      "Speed: 1.4ms preprocess, 6.9ms inference, 0.1ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 cloudy 0.75, amber 0.20, clear 0.05, 6.9ms\n",
      "Speed: 1.4ms preprocess, 6.9ms inference, 0.1ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 cloudy 0.62, clear 0.38, amber 0.00, 6.9ms\n",
      "Speed: 1.4ms preprocess, 6.9ms inference, 0.1ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 cloudy 0.72, clear 0.28, amber 0.00, 6.9ms\n",
      "Speed: 1.5ms preprocess, 6.9ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 cloudy 0.97, clear 0.02, amber 0.00, 7.2ms\n",
      "Speed: 1.4ms preprocess, 7.2ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 cloudy 1.00, clear 0.00, amber 0.00, 7.0ms\n",
      "Speed: 1.4ms preprocess, 7.0ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 cloudy 0.96, clear 0.03, amber 0.00, 7.0ms\n",
      "Speed: 1.4ms preprocess, 7.0ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 cloudy 0.58, clear 0.38, amber 0.05, 7.1ms\n",
      "Speed: 1.4ms preprocess, 7.1ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 cloudy 1.00, clear 0.00, amber 0.00, 7.0ms\n",
      "Speed: 1.4ms preprocess, 7.0ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 cloudy 0.95, clear 0.05, amber 0.00, 7.1ms\n",
      "Speed: 1.4ms preprocess, 7.1ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 cloudy 0.99, clear 0.01, amber 0.00, 7.0ms\n",
      "Speed: 1.4ms preprocess, 7.0ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "\n",
      "0: 128x128 cloudy 0.89, clear 0.11, amber 0.00, 7.1ms\n",
      "Speed: 1.4ms preprocess, 7.1ms inference, 0.0ms postprocess per image at shape (1, 3, 128, 128)\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       amber       0.95      1.00      0.97        18\n",
      "       clear       0.88      0.70      0.78        10\n",
      "      cloudy       0.89      0.92      0.91        26\n",
      "\n",
      "    accuracy                           0.91        54\n",
      "   macro avg       0.90      0.87      0.89        54\n",
      "weighted avg       0.91      0.91      0.90        54\n",
      "\n",
      "Accuracy: 0.9074074074074074\n",
      "Confusion Matrix:\n",
      " [[18  0  0]\n",
      " [ 0  7  3]\n",
      " [ 1  1 24]]\n",
      "Training YOLOv11 Nano model...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'yolov11n-cls.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model_size \u001b[38;5;129;01min\u001b[39;00m yolo_classification_checkpoints[model_name]:\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m model...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimgsz\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEvaluating \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m model...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      8\u001b[0m     eval_model(model, test_data_path)\n",
      "Cell \u001b[0;32mIn[8], line 4\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(data_path, model_name, model_size, epochs, imgsz)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_model\u001b[39m(data_path, model_name, model_size, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, imgsz\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;66;03m# Load the model checkpoint\u001b[39;00m\n\u001b[1;32m      3\u001b[0m     checkpoint \u001b[38;5;241m=\u001b[39m yolo_classification_checkpoints[model_name][model_size]\n\u001b[0;32m----> 4\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mYOLO\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     model\u001b[38;5;241m.\u001b[39mtrain(data\u001b[38;5;241m=\u001b[39mdata_path, epochs\u001b[38;5;241m=\u001b[39mepochs, imgsz\u001b[38;5;241m=\u001b[39mimgsz)\n",
      "File \u001b[0;32m~/.conda/envs/yolo8/lib/python3.10/site-packages/ultralytics/models/yolo/model.py:23\u001b[0m, in \u001b[0;36mYOLO.__init__\u001b[0;34m(self, model, task, verbose)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m \u001b[38;5;241m=\u001b[39m new_instance\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;66;03m# Continue with default YOLO initialization\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/yolo8/lib/python3.10/site-packages/ultralytics/engine/model.py:145\u001b[0m, in \u001b[0;36mModel.__init__\u001b[0;34m(self, model, task, verbose)\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_new(model, task\u001b[38;5;241m=\u001b[39mtask, verbose\u001b[38;5;241m=\u001b[39mverbose)\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 145\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/yolo8/lib/python3.10/site-packages/ultralytics/engine/model.py:285\u001b[0m, in \u001b[0;36mModel._load\u001b[0;34m(self, weights, task)\u001b[0m\n\u001b[1;32m    282\u001b[0m weights \u001b[38;5;241m=\u001b[39m checks\u001b[38;5;241m.\u001b[39mcheck_model_file_from_stem(weights)  \u001b[38;5;66;03m# add suffix, i.e. yolov8n -> yolov8n.pt\u001b[39;00m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m Path(weights)\u001b[38;5;241m.\u001b[39msuffix \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 285\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mckpt \u001b[38;5;241m=\u001b[39m \u001b[43mattempt_load_one_weight\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweights\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtask\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moverrides \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39margs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset_ckpt_args(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39margs)\n",
      "File \u001b[0;32m~/.conda/envs/yolo8/lib/python3.10/site-packages/ultralytics/nn/tasks.py:910\u001b[0m, in \u001b[0;36mattempt_load_one_weight\u001b[0;34m(weight, device, inplace, fuse)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mattempt_load_one_weight\u001b[39m(weight, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, fuse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    909\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Loads a single model weights.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 910\u001b[0m     ckpt, weight \u001b[38;5;241m=\u001b[39m \u001b[43mtorch_safe_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# load ckpt\u001b[39;00m\n\u001b[1;32m    911\u001b[0m     args \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mDEFAULT_CFG_DICT, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m(ckpt\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_args\u001b[39m\u001b[38;5;124m\"\u001b[39m, {}))}  \u001b[38;5;66;03m# combine model and default args, preferring model args\u001b[39;00m\n\u001b[1;32m    912\u001b[0m     model \u001b[38;5;241m=\u001b[39m (ckpt\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mema\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m ckpt[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mto(device)\u001b[38;5;241m.\u001b[39mfloat()  \u001b[38;5;66;03m# FP32 model\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/yolo8/lib/python3.10/site-packages/ultralytics/nn/tasks.py:837\u001b[0m, in \u001b[0;36mtorch_safe_load\u001b[0;34m(weight, safe_only)\u001b[0m\n\u001b[1;32m    835\u001b[0m                 ckpt \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(f, pickle_module\u001b[38;5;241m=\u001b[39msafe_pickle)\n\u001b[1;32m    836\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 837\u001b[0m             ckpt \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    839\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# e.name is missing module name\u001b[39;00m\n\u001b[1;32m    840\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m e\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodels\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/.conda/envs/yolo8/lib/python3.10/site-packages/ultralytics/utils/patches.py:86\u001b[0m, in \u001b[0;36mtorch_load\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m TORCH_1_13 \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweights_only\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[1;32m     84\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweights_only\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m---> 86\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_torch_load\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/yolo8/lib/python3.10/site-packages/torch/serialization.py:986\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m    983\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    984\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 986\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[1;32m    987\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m    988\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m    989\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m    990\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m    991\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[0;32m~/.conda/envs/yolo8/lib/python3.10/site-packages/torch/serialization.py:435\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    434\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 435\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    436\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    437\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[0;32m~/.conda/envs/yolo8/lib/python3.10/site-packages/torch/serialization.py:416\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[0;32m--> 416\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'yolov11n-cls.pt'"
     ]
    }
   ],
   "source": [
    "# run the functions for each of the models\n",
    "for model_name in yolo_classification_checkpoints:\n",
    "    for model_size in yolo_classification_checkpoints[model_name]:\n",
    "        print(f\"Training {model_name} {model_size} model...\")\n",
    "        model = train_model(data_path, model_name, model_size, epochs=10, imgsz=128)\n",
    "        \n",
    "        print(f\"Evaluating {model_name} {model_size} model...\")\n",
    "        eval_model(model, test_data_path)\n",
    "        \n",
    "        # print(f\"Plotting results for {model_name} {model_size} model...\")\n",
    "        # plot_results(images_for_plotting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolo8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
