{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert COCO to YOLO for object detection - Not working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics.data.converter import convert_coco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "segments_base_folder = '/home/etaylor/code_projects/thesis/segments'\n",
    "segments_folder_name = \"\"\n",
    "\n",
    "annotations_dir = '/home/etaylor/code_projects/thesis/segments/etaylor_cannabis_patches_week9_15_06_2023_3x_regular_IMG_2157/annotations'\n",
    "output_dir = \"/home/etaylor/code_projects/thesis/segments/etaylor_cannabis_patches_week9_15_06_2023_3x_regular_IMG_2157/annotations/yolo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Annotations /sise/home/etaylor/code_projects/thesis/segments/etaylor_cannabis_patches_week9_15_06_2023_3x_regular_IMG_2157/annotations/export_coco-instance_etaylor_cannabis_patches_week9_15_06_2023_3x_regular_IMG_2157_v0.3.json: 100%|██████████| 11/11 [00:00<00:00, 322.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COCO data converted successfully.\n",
      "Results saved to /sise/home/etaylor/code_projects/thesis/segments/etaylor_cannabis_patches_week9_15_06_2023_3x_regular_IMG_2157/annotations/yolo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "convert_coco(\n",
    "    labels_dir=annotations_dir,\n",
    "    save_dir=output_dir, \n",
    "    use_segments=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert COCO to YOLO Instance Segmentation format - Working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/etaylor/code_projects')\n",
    "sys.path.append('/home/etaylor/code_projects/coco2yolo')\n",
    "from coco2yolo import general_json2yolo as c2y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Annotations /sise/home/etaylor/code_projects/thesis/segments/etaylor_document_segmentation/annotations/export_coco-instance_etaylor_document_segmentation_v0.1.json: 100%|██████████| 120/120 [00:04<00:00, 29.63it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "\n",
    "annotations_dir = '/home/etaylor/code_projects/thesis/segments/etaylor_document_segmentation/annotations'\n",
    "output_dir = \"/home/etaylor/code_projects/thesis/segments/etaylor_document_segmentation/yolo\"\n",
    "\n",
    "# convert the RLE coco json to yolo format\n",
    "c2y.convert_coco_json(\n",
    "    json_dir=annotations_dir,\n",
    "    use_segments=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fix mapping of class from -1 to 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 112 files. All '-1' class labels have been replaced with '0'.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "# Path to the annotation files\n",
    "annotations_dir = '/home/etaylor/code_projects/thesis/segments/etaylor_stigmas_dataset/yolo/labels/export_coco-instance_etaylor_stigmas_dataset_v0.2'\n",
    "\n",
    "# Get all .txt files in the directory\n",
    "txt_files = glob.glob(os.path.join(annotations_dir, '*.txt'))\n",
    "\n",
    "# Iterate through each file and replace -1 with 0\n",
    "for txt_file in txt_files:\n",
    "    with open(txt_file, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "    \n",
    "    # Replace class labels\n",
    "    updated_lines = [line.replace('-1', '0', 1) for line in lines]\n",
    "    \n",
    "    # Write the updated content back to the file\n",
    "    with open(txt_file, 'w') as file:\n",
    "        file.writelines(updated_lines)\n",
    "\n",
    "print(f\"Processed {len(txt_files)} files. All '-1' class labels have been replaced with '0'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use this after converting to YOLO to split to train and val splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "def split_and_organize_yolo_dataset(dataset_path, output_path, train_ratio=0.8, image_exts=['.jpg', '.png']):\n",
    "    \"\"\"\n",
    "    Organize and split a YOLO dataset into train and validation sets.\n",
    "\n",
    "    Args:\n",
    "        dataset_path (str): Path to the root of the dataset containing images and labels.\n",
    "        output_path (str): Path to save the organized dataset.\n",
    "        train_ratio (float): Ratio of the dataset to use for training.\n",
    "        image_exts (list): List of acceptable image file extensions.\n",
    "    \"\"\"\n",
    "    # Define paths\n",
    "    images_path = Path(dataset_path) / 'v0.1'\n",
    "    labels_path = Path(dataset_path) / 'yolo/labels/export_coco-instance_etaylor_document_segmentation_v0.1'\n",
    "\n",
    "    train_image_output = Path(output_path) / 'images/train'\n",
    "    val_image_output = Path(output_path) / 'images/val'\n",
    "    train_label_output = Path(output_path) / 'labels/train'\n",
    "    val_label_output = Path(output_path) / 'labels/val'\n",
    "\n",
    "    # Create output directories if they don't exist\n",
    "    for dir_path in [train_image_output, val_image_output, train_label_output, val_label_output]:\n",
    "        dir_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Get all image files\n",
    "    image_files = [f for f in images_path.iterdir() if f.suffix in image_exts]\n",
    "    random.shuffle(image_files)\n",
    "\n",
    "    # Split the dataset\n",
    "    num_train = int(len(image_files) * train_ratio)\n",
    "    train_files = image_files[:num_train]\n",
    "    val_files = image_files[num_train:]\n",
    "\n",
    "    # Move or copy files to train/val\n",
    "    for img_file in train_files:\n",
    "        label_file = labels_path / f\"{img_file.stem}.txt\"\n",
    "        if label_file.exists():\n",
    "            shutil.copy(img_file, train_image_output / img_file.name)\n",
    "            shutil.copy(label_file, train_label_output / label_file.name)\n",
    "\n",
    "    for img_file in val_files:\n",
    "        label_file = labels_path / f\"{img_file.stem}.txt\"\n",
    "        if label_file.exists():\n",
    "            shutil.copy(img_file, val_image_output / img_file.name)\n",
    "            shutil.copy(label_file, val_label_output / label_file.name)\n",
    "\n",
    "    print(f\"✅ Dataset organized: {len(train_files)} train, {len(val_files)} val\")\n",
    "\n",
    "    # Return paths for registration or further use\n",
    "    return {\n",
    "        'train_images': train_image_output,\n",
    "        'val_images': val_image_output,\n",
    "        'train_labels': train_label_output,\n",
    "        'val_labels': val_label_output\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset organized: 192 train, 48 val\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train_images': PosixPath('/home/etaylor/code_projects/thesis/segments/etaylor_document_segmentation/yolo_formatted/images/train'),\n",
       " 'val_images': PosixPath('/home/etaylor/code_projects/thesis/segments/etaylor_document_segmentation/yolo_formatted/images/val'),\n",
       " 'train_labels': PosixPath('/home/etaylor/code_projects/thesis/segments/etaylor_document_segmentation/yolo_formatted/labels/train'),\n",
       " 'val_labels': PosixPath('/home/etaylor/code_projects/thesis/segments/etaylor_document_segmentation/yolo_formatted/labels/val')}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_path = \"/home/etaylor/code_projects/thesis/segments/etaylor_document_segmentation\"\n",
    "output_path = \"/home/etaylor/code_projects/thesis/segments/etaylor_document_segmentation/yolo_formatted\"\n",
    "split_and_organize_yolo_dataset(dataset_path, output_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolo8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
