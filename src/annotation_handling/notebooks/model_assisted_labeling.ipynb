{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Wnygc-uoVLfx"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/etaylor/.conda/envs/detectron/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "from src.annotation_handling.segmentsai_handler import SegmentsAIHandler\n",
        "from src.pipelines import model_assist_label_pipeline as pipe \n",
        "import config"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kw2JEh1Sk52I"
      },
      "source": [
        "#### Setup Global Variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "zgjm9kb2M9lL"
      },
      "outputs": [],
      "source": [
        "segmentsai_handler = SegmentsAIHandler()\n",
        "TRAIN_DATASET_NAME = 'etaylor/cannabis_patches_all_images'\n",
        "\n",
        "# New dataset to upload variables\n",
        "image_name = \"IMG_2263\"\n",
        "week = 'week9'\n",
        "zoom_type = '3xr'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4bPRHcMrLm7l"
      },
      "source": [
        "#### 1. Upload your images and label a small subset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20NDp5ubdoX5"
      },
      "source": [
        "##### Vizualize dataset images with masks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "FhD9WUM0Vv40",
        "outputId": "d76e231a-e4df-4e0e-b63d-6eed4dfc7f8c"
      },
      "outputs": [],
      "source": [
        "# Visualize the dataset\n",
        "segmentsai_handler.visualize_dataset(TRAIN_DATASET_NAME)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rotyn89DLm7m"
      },
      "source": [
        "#### 2. Train a segmentation model on the labeled images\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RWWJKe0YfarR",
        "outputId": "0bc3cbea-c69c-4fc0-9c25-b6293ae5f760"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initializing dataset...\n",
            "Preloading all samples. This may take a while...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|\u001b[38;2;255;153;0m██████████\u001b[0m| 95/95 [00:05<00:00, 18.82it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initialized dataset with 95 images.\n",
            "Exporting dataset. This may take a while...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 81%|\u001b[38;2;255;153;0m████████  \u001b[0m| 77/95 [00:02<00:00, 37.22it/s]Skipping instance with 0 labeled pixels: IMG_2305_p7.jpg, instance_id: 3, category_id: 1\n",
            "100%|\u001b[38;2;255;153;0m██████████\u001b[0m| 95/95 [00:03<00:00, 29.85it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exported to ./export_coco-instance_etaylor_cannabis_patches_all_images_v0.2.json. Images in segments/etaylor_cannabis_patches_all_images/v0.2\n",
            "Metadata(name='my_dataset', json_file='./export_coco-instance_etaylor_cannabis_patches_all_images_v0.2.json', image_root='segments/etaylor_cannabis_patches_all_images/v0.2', evaluator_type='coco', thing_classes=['trichome'])\n",
            "\u001b[32m[11/13 16:45:38 d2.engine.defaults]: \u001b[0mModel:\n",
            "GeneralizedRCNN(\n",
            "  (backbone): FPN(\n",
            "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (top_block): LastLevelMaxPool()\n",
            "    (bottom_up): ResNet(\n",
            "      (stem): BasicStem(\n",
            "        (conv1): Conv2d(\n",
            "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (res2): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res3): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res4): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (4): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (5): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res5): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (proposal_generator): RPN(\n",
            "    (rpn_head): StandardRPNHead(\n",
            "      (conv): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "    (anchor_generator): DefaultAnchorGenerator(\n",
            "      (cell_anchors): BufferList()\n",
            "    )\n",
            "  )\n",
            "  (roi_heads): StandardROIHeads(\n",
            "    (box_pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
            "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
            "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (box_head): FastRCNNConvFCHead(\n",
            "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
            "      (fc_relu1): ReLU()\n",
            "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "      (fc_relu2): ReLU()\n",
            "    )\n",
            "    (box_predictor): FastRCNNOutputLayers(\n",
            "      (cls_score): Linear(in_features=1024, out_features=2, bias=True)\n",
            "      (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)\n",
            "    )\n",
            "    (mask_pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
            "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
            "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (mask_head): MaskRCNNConvUpsampleHead(\n",
            "      (mask_fcn1): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (mask_fcn2): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (mask_fcn3): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (mask_fcn4): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
            "      (deconv_relu): ReLU()\n",
            "      (predictor): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "  )\n",
            ")\n",
            "\u001b[32m[11/13 16:45:39 d2.data.datasets.coco]: \u001b[0mLoaded 92 images in COCO format from ./export_coco-instance_etaylor_cannabis_patches_all_images_v0.2.json\n",
            "\u001b[32m[11/13 16:45:39 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 92 images left.\n",
            "\u001b[32m[11/13 16:45:39 d2.data.build]: \u001b[0mDistribution of instances among all 1 categories:\n",
            "\u001b[36m|  category  | #instances   |\n",
            "|:----------:|:-------------|\n",
            "|  trichome  | 2185         |\n",
            "|            |              |\u001b[0m\n",
            "\u001b[32m[11/13 16:45:39 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
            "\u001b[32m[11/13 16:45:39 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
            "\u001b[32m[11/13 16:45:39 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
            "\u001b[32m[11/13 16:45:39 d2.data.common]: \u001b[0mSerializing 92 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[11/13 16:45:39 d2.data.common]: \u001b[0mSerialized dataset takes 0.32 MiB\n",
            "\u001b[32m[11/13 16:45:39 d2.data.build]: \u001b[0mMaking batched data loader with batch_size=2\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[11/13 16:45:39 d2.solver.build]: \u001b[0mSOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n",
            "\u001b[32m[11/13 16:45:39 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from https://dl.fbaipublicfiles.com/detectron2/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x/137849600/model_final_f10217.pkl ...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (2, 1024) in the model! You might want to double check if this is expected.\n",
            "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (2,) in the model! You might want to double check if this is expected.\n",
            "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (4, 1024) in the model! You might want to double check if this is expected.\n",
            "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (4,) in the model! You might want to double check if this is expected.\n",
            "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (1, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
            "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (1,) in the model! You might want to double check if this is expected.\n",
            "Some model parameters or buffers are not found in the checkpoint:\n",
            "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
            "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n",
            "\u001b[34mroi_heads.mask_head.predictor.{bias, weight}\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32m[11/13 16:45:42 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/etaylor/.conda/envs/detectron/lib/python3.9/site-packages/detectron2/data/detection_utils.py:446: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:180.)\n",
            "  torch.stack([torch.from_numpy(np.ascontiguousarray(x)) for x in masks])\n",
            "/home/etaylor/.conda/envs/detectron/lib/python3.9/site-packages/detectron2/data/detection_utils.py:446: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:180.)\n",
            "  torch.stack([torch.from_numpy(np.ascontiguousarray(x)) for x in masks])\n",
            "/home/etaylor/.conda/envs/detectron/lib/python3.9/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32m[11/13 16:45:48 d2.utils.events]: \u001b[0m eta: 0:00:50  iter: 19  total_loss: 3.877  loss_cls: 0.5899  loss_box_reg: 0.6108  loss_mask: 0.6931  loss_rpn_cls: 1.893  loss_rpn_loc: 0.1614    time: 0.1846  last_time: 0.2056  data_time: 0.0328  last_data_time: 0.0076   lr: 1.6068e-05  max_mem: 2009M\n",
            "\u001b[32m[11/13 16:45:56 d2.utils.events]: \u001b[0m eta: 0:00:47  iter: 39  total_loss: 2.234  loss_cls: 0.5555  loss_box_reg: 0.6792  loss_mask: 0.6616  loss_rpn_cls: 0.2181  loss_rpn_loc: 0.09586    time: 0.1902  last_time: 0.1601  data_time: 0.0056  last_data_time: 0.0043   lr: 3.2718e-05  max_mem: 2014M\n",
            "\u001b[32m[11/13 16:46:00 d2.utils.events]: \u001b[0m eta: 0:00:46  iter: 59  total_loss: 1.994  loss_cls: 0.5122  loss_box_reg: 0.7078  loss_mask: 0.5967  loss_rpn_cls: 0.1003  loss_rpn_loc: 0.09245    time: 0.1932  last_time: 0.2004  data_time: 0.0102  last_data_time: 0.0064   lr: 4.9367e-05  max_mem: 2014M\n",
            "\u001b[32m[11/13 16:46:04 d2.utils.events]: \u001b[0m eta: 0:00:42  iter: 79  total_loss: 1.872  loss_cls: 0.4724  loss_box_reg: 0.726  loss_mask: 0.5034  loss_rpn_cls: 0.09642  loss_rpn_loc: 0.08693    time: 0.1941  last_time: 0.1906  data_time: 0.0082  last_data_time: 0.0045   lr: 6.6017e-05  max_mem: 2016M\n",
            "\u001b[32m[11/13 16:46:08 d2.utils.events]: \u001b[0m eta: 0:00:38  iter: 99  total_loss: 1.768  loss_cls: 0.4253  loss_box_reg: 0.7482  loss_mask: 0.4263  loss_rpn_cls: 0.07193  loss_rpn_loc: 0.08287    time: 0.1931  last_time: 0.1988  data_time: 0.0081  last_data_time: 0.0054   lr: 8.2668e-05  max_mem: 2026M\n",
            "\u001b[32m[11/13 16:46:12 d2.utils.events]: \u001b[0m eta: 0:00:34  iter: 119  total_loss: 1.651  loss_cls: 0.3889  loss_box_reg: 0.6895  loss_mask: 0.3816  loss_rpn_cls: 0.07375  loss_rpn_loc: 0.08726    time: 0.1931  last_time: 0.1938  data_time: 0.0064  last_data_time: 0.0050   lr: 9.9318e-05  max_mem: 2026M\n",
            "\u001b[32m[11/13 16:46:16 d2.utils.events]: \u001b[0m eta: 0:00:31  iter: 139  total_loss: 1.523  loss_cls: 0.3555  loss_box_reg: 0.7063  loss_mask: 0.3419  loss_rpn_cls: 0.06155  loss_rpn_loc: 0.07059    time: 0.1937  last_time: 0.1586  data_time: 0.0071  last_data_time: 0.0036   lr: 0.00011597  max_mem: 2026M\n",
            "\u001b[32m[11/13 16:46:20 d2.utils.events]: \u001b[0m eta: 0:00:27  iter: 159  total_loss: 1.43  loss_cls: 0.3231  loss_box_reg: 0.665  loss_mask: 0.3113  loss_rpn_cls: 0.05087  loss_rpn_loc: 0.06881    time: 0.1940  last_time: 0.1841  data_time: 0.0084  last_data_time: 0.0061   lr: 0.00013262  max_mem: 2026M\n",
            "\u001b[32m[11/13 16:46:24 d2.utils.events]: \u001b[0m eta: 0:00:23  iter: 179  total_loss: 1.267  loss_cls: 0.2854  loss_box_reg: 0.5574  loss_mask: 0.2684  loss_rpn_cls: 0.05508  loss_rpn_loc: 0.0813    time: 0.1940  last_time: 0.1843  data_time: 0.0055  last_data_time: 0.0045   lr: 0.00014927  max_mem: 2026M\n",
            "\u001b[32m[11/13 16:46:28 d2.utils.events]: \u001b[0m eta: 0:00:19  iter: 199  total_loss: 1.131  loss_cls: 0.2564  loss_box_reg: 0.4674  loss_mask: 0.2258  loss_rpn_cls: 0.04689  loss_rpn_loc: 0.0711    time: 0.1945  last_time: 0.2240  data_time: 0.0080  last_data_time: 0.0111   lr: 0.00016592  max_mem: 2026M\n",
            "\u001b[32m[11/13 16:46:32 d2.utils.events]: \u001b[0m eta: 0:00:15  iter: 219  total_loss: 0.9717  loss_cls: 0.252  loss_box_reg: 0.413  loss_mask: 0.1908  loss_rpn_cls: 0.05214  loss_rpn_loc: 0.0664    time: 0.1934  last_time: 0.1993  data_time: 0.0048  last_data_time: 0.0041   lr: 0.00018257  max_mem: 2026M\n",
            "\u001b[32m[11/13 16:46:35 d2.utils.events]: \u001b[0m eta: 0:00:11  iter: 239  total_loss: 0.9085  loss_cls: 0.2437  loss_box_reg: 0.3654  loss_mask: 0.1899  loss_rpn_cls: 0.03973  loss_rpn_loc: 0.05988    time: 0.1933  last_time: 0.1981  data_time: 0.0062  last_data_time: 0.0045   lr: 0.00019922  max_mem: 2026M\n",
            "\u001b[32m[11/13 16:46:39 d2.utils.events]: \u001b[0m eta: 0:00:07  iter: 259  total_loss: 0.9053  loss_cls: 0.2132  loss_box_reg: 0.3472  loss_mask: 0.1794  loss_rpn_cls: 0.05177  loss_rpn_loc: 0.07335    time: 0.1932  last_time: 0.1904  data_time: 0.0064  last_data_time: 0.0046   lr: 0.00021587  max_mem: 2026M\n",
            "\u001b[32m[11/13 16:46:43 d2.utils.events]: \u001b[0m eta: 0:00:03  iter: 279  total_loss: 0.8762  loss_cls: 0.2251  loss_box_reg: 0.3167  loss_mask: 0.1682  loss_rpn_cls: 0.03391  loss_rpn_loc: 0.0648    time: 0.1928  last_time: 0.1967  data_time: 0.0067  last_data_time: 0.0049   lr: 0.00023252  max_mem: 2026M\n",
            "\u001b[32m[11/13 16:46:52 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 299  total_loss: 0.7435  loss_cls: 0.2103  loss_box_reg: 0.2906  loss_mask: 0.1534  loss_rpn_cls: 0.04652  loss_rpn_loc: 0.07423    time: 0.1928  last_time: 0.1816  data_time: 0.0102  last_data_time: 0.0033   lr: 0.00024917  max_mem: 2026M\n",
            "\u001b[32m[11/13 16:46:52 d2.engine.hooks]: \u001b[0mOverall training speed: 298 iterations in 0:00:57 (0.1928 s / it)\n",
            "\u001b[32m[11/13 16:46:52 d2.engine.hooks]: \u001b[0mTotal training time: 0:01:06 (0:00:09 on hooks)\n",
            "\u001b[32m[11/13 16:46:52 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from ./output/model_final.pth ...\n"
          ]
        }
      ],
      "source": [
        "# Initialize a dataset from the release file\n",
        "model = pipe.train_segmentation_model(TRAIN_DATASET_NAME)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8MsoYDLduR8"
      },
      "source": [
        "#### Create a new dataset and upload images to him"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pK8SfINidxzP",
        "outputId": "3438e95d-4c34-4fb5-e573-5069fd59d4bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "name='cannabis_patches_week9_15_06_2023_3x_regular_IMG_2263_v2' full_name='etaylor/cannabis_patches_week9_15_06_2023_3x_regular_IMG_2263_v2' cloned_from=None description='cannabis patches week=week9_15_06_2023 zoom_type=3x_regular of image=IMG_2263_v2.' category='other' public=False owner=Owner(username='etaylor', created_at='2022-12-28T12:53:18Z', email=None) created_at='2023-11-13T15:02:52.964595Z' enable_ratings=False enable_skip_labeling=True enable_skip_reviewing=False enable_save_button=False enable_label_status_verified=False enable_same_dimensions_track_constraint=False enable_interpolation=True task_type='segmentation-bitmap' label_stats=LabelStats(REVIEWED=None, REVIEWING_IN_PROGRESS=None, LABELED=None, LABELING_IN_PROGRESS=None, REJECTED=None, PRELABELED=None, SKIPPED=None, VERIFIED=None, UNLABELED=None, TOTAL=None) labeling_inactivity_timeout_seconds=None samples_count=0 collaborators_count=None task_attributes=TaskAttributes(format_version='0.1', categories=[TaskAttributeCategory(name='trichome', id=1, color=None, has_instances=None, attributes=None, dimensions=None)], image_attributes=None) labelsets=None role=None readme='' metadata={} noncollaborator_can_label=False noncollaborator_can_review=False insights_urls=None embeddings_enabled=None\n",
            "Uploaded IMG_2263_p0.png and added as sample: uuid='412cb3c8-f9d8-4c6e-9a91-0aafe60f7695' name='IMG_2263_p0.png' attributes=ImageSampleAttributes(image=URL(url='https://segmentsai-prod.s3.eu-west-2.amazonaws.com/assets/etaylor/5aae49c2-96dd-49ec-a10f-01e51c243a28.png')) metadata={} created_at='2023-11-13T15:02:54.103741Z' created_by='etaylor' assigned_labeler=None assigned_reviewer=None comments=[] priority=0.0 has_embedding=False label=None issues=None dataset_full_name=None\n",
            "Uploaded IMG_2263_p1.png and added as sample: uuid='d2160aaa-5dff-484b-a63c-370641712af8' name='IMG_2263_p1.png' attributes=ImageSampleAttributes(image=URL(url='https://segmentsai-prod.s3.eu-west-2.amazonaws.com/assets/etaylor/ef479f79-0d6e-4d30-bfe2-c19db9853adc.png')) metadata={} created_at='2023-11-13T15:02:54.607782Z' created_by='etaylor' assigned_labeler=None assigned_reviewer=None comments=[] priority=0.0 has_embedding=False label=None issues=None dataset_full_name=None\n",
            "Uploaded IMG_2263_p2.png and added as sample: uuid='b1b73861-1b09-4878-b76d-c9ad896b7665' name='IMG_2263_p2.png' attributes=ImageSampleAttributes(image=URL(url='https://segmentsai-prod.s3.eu-west-2.amazonaws.com/assets/etaylor/c4151cf8-3e3a-484a-9d30-76b9c2f4fc50.png')) metadata={} created_at='2023-11-13T15:02:55.134555Z' created_by='etaylor' assigned_labeler=None assigned_reviewer=None comments=[] priority=0.0 has_embedding=False label=None issues=None dataset_full_name=None\n",
            "Uploaded IMG_2263_p3.png and added as sample: uuid='440b3db1-e7d8-4b6a-84c3-042223e283fe' name='IMG_2263_p3.png' attributes=ImageSampleAttributes(image=URL(url='https://segmentsai-prod.s3.eu-west-2.amazonaws.com/assets/etaylor/869de7b1-ba9c-4537-8217-bb9c07b00306.png')) metadata={} created_at='2023-11-13T15:02:55.629660Z' created_by='etaylor' assigned_labeler=None assigned_reviewer=None comments=[] priority=0.0 has_embedding=False label=None issues=None dataset_full_name=None\n",
            "Uploaded IMG_2263_p4.png and added as sample: uuid='24a6feed-c115-4700-8e47-aa0a89004937' name='IMG_2263_p4.png' attributes=ImageSampleAttributes(image=URL(url='https://segmentsai-prod.s3.eu-west-2.amazonaws.com/assets/etaylor/2d7f77b2-166c-4a13-88af-748f52838587.png')) metadata={} created_at='2023-11-13T15:02:56.111956Z' created_by='etaylor' assigned_labeler=None assigned_reviewer=None comments=[] priority=0.0 has_embedding=False label=None issues=None dataset_full_name=None\n",
            "Uploaded IMG_2263_p5.png and added as sample: uuid='6a33a59b-c234-4fb6-92d6-29f1f167618d' name='IMG_2263_p5.png' attributes=ImageSampleAttributes(image=URL(url='https://segmentsai-prod.s3.eu-west-2.amazonaws.com/assets/etaylor/49fbeff0-261b-47e8-a06d-0f2dbb24ff44.png')) metadata={} created_at='2023-11-13T15:02:56.605176Z' created_by='etaylor' assigned_labeler=None assigned_reviewer=None comments=[] priority=0.0 has_embedding=False label=None issues=None dataset_full_name=None\n",
            "Uploaded IMG_2263_p6.png and added as sample: uuid='12df966c-1dcf-40e2-9358-d2c427d304fe' name='IMG_2263_p6.png' attributes=ImageSampleAttributes(image=URL(url='https://segmentsai-prod.s3.eu-west-2.amazonaws.com/assets/etaylor/f509f8c9-6bbe-4e17-8c73-ca54f3d27db9.png')) metadata={} created_at='2023-11-13T15:02:57.078148Z' created_by='etaylor' assigned_labeler=None assigned_reviewer=None comments=[] priority=0.0 has_embedding=False label=None issues=None dataset_full_name=None\n",
            "Uploaded IMG_2263_p7.png and added as sample: uuid='3724ed46-3369-4e3f-ab83-b69c5c5586a4' name='IMG_2263_p7.png' attributes=ImageSampleAttributes(image=URL(url='https://segmentsai-prod.s3.eu-west-2.amazonaws.com/assets/etaylor/373e3234-a90b-4246-a0ef-9361f156a8e0.png')) metadata={} created_at='2023-11-13T15:02:57.588996Z' created_by='etaylor' assigned_labeler=None assigned_reviewer=None comments=[] priority=0.0 has_embedding=False label=None issues=None dataset_full_name=None\n",
            "Uploaded IMG_2263_p8.png and added as sample: uuid='f9e25486-8eda-4fd9-bda9-342a0ffc28b1' name='IMG_2263_p8.png' attributes=ImageSampleAttributes(image=URL(url='https://segmentsai-prod.s3.eu-west-2.amazonaws.com/assets/etaylor/bc3a3551-1ea4-4838-afa3-6f991c34a56a.png')) metadata={} created_at='2023-11-13T15:02:58.060032Z' created_by='etaylor' assigned_labeler=None assigned_reviewer=None comments=[] priority=0.0 has_embedding=False label=None issues=None dataset_full_name=None\n",
            "Uploaded IMG_2263_p9.png and added as sample: uuid='b6242fc2-a5f5-49cc-8db9-138c15abde36' name='IMG_2263_p9.png' attributes=ImageSampleAttributes(image=URL(url='https://segmentsai-prod.s3.eu-west-2.amazonaws.com/assets/etaylor/7917fa8a-c37b-44f9-befd-571f2b8f1a47.png')) metadata={} created_at='2023-11-13T15:02:58.515378Z' created_by='etaylor' assigned_labeler=None assigned_reviewer=None comments=[] priority=0.0 has_embedding=False label=None issues=None dataset_full_name=None\n",
            "Uploaded IMG_2263_p10.png and added as sample: uuid='86a2b710-8001-494a-83fc-b8c8f5a62821' name='IMG_2263_p10.png' attributes=ImageSampleAttributes(image=URL(url='https://segmentsai-prod.s3.eu-west-2.amazonaws.com/assets/etaylor/2f9348e4-e4c0-4395-8e73-9f50e3b6411a.png')) metadata={} created_at='2023-11-13T15:02:59.009615Z' created_by='etaylor' assigned_labeler=None assigned_reviewer=None comments=[] priority=0.0 has_embedding=False label=None issues=None dataset_full_name=None\n",
            "Uploaded IMG_2263_p11.png and added as sample: uuid='6230a280-82ab-4291-8e56-609cce23f160' name='IMG_2263_p11.png' attributes=ImageSampleAttributes(image=URL(url='https://segmentsai-prod.s3.eu-west-2.amazonaws.com/assets/etaylor/a0feece4-0a35-4fd5-88fe-108e1045f5f7.png')) metadata={} created_at='2023-11-13T15:02:59.478970Z' created_by='etaylor' assigned_labeler=None assigned_reviewer=None comments=[] priority=0.0 has_embedding=False label=None issues=None dataset_full_name=None\n",
            "Uploaded IMG_2263_p12.png and added as sample: uuid='4e1674f6-cfbf-4cde-815f-5e85d916da43' name='IMG_2263_p12.png' attributes=ImageSampleAttributes(image=URL(url='https://segmentsai-prod.s3.eu-west-2.amazonaws.com/assets/etaylor/eb664e51-0d8d-48e2-9dc5-5123398b4191.png')) metadata={} created_at='2023-11-13T15:02:59.980714Z' created_by='etaylor' assigned_labeler=None assigned_reviewer=None comments=[] priority=0.0 has_embedding=False label=None issues=None dataset_full_name=None\n"
          ]
        }
      ],
      "source": [
        "# Create a new test dataset for the specified image, week, and zoom type\n",
        "test_dataset = pipe.create_new_test_dataset(image_name, config.WEEKS_DIR[week], config.ZOOM_TYPES_DIR[zoom_type])\n",
        "# Get the absolute path to the processed image\n",
        "abs_images_path = f\"{config.get_processed_cannabis_image_path(week, zoom_type)}/{image_name}\"\n",
        "\n",
        "# Upload the images that are not annotated to the dataset\n",
        "segmentsai_handler.upload_images(test_dataset, abs_images_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "release_name = \"v0.1\"\n",
        "description = \"upload predictions to dataset.\"\n",
        "segmentsai_handler.client.add_release(test_dataset, release_name, description)\n",
        "test_release = segmentsai_handler.client.get_release(test_dataset, \"v0.1\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Release(uuid='b79c169b-8ad3-41ad-99a9-eb3562c2e4d6', name='v0.1', description='upload predictions to dataset.', release_type='JSON', attributes=URL(url=''), status='PENDING', created_at='2023-11-13T14:51:44.611766Z', samples_count=13)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_release"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lpX-71UwlW6o"
      },
      "source": [
        "### Upload the Images that are not annotaed to the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gozhWa6Ahvxm",
        "outputId": "f73115aa-9519-491c-ac9d-8da8a6b8b70b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "release=uuid='b79c169b-8ad3-41ad-99a9-eb3562c2e4d6' name='v0.1' description='upload predictions to dataset.' release_type='JSON' attributes=URL(url='') status='PENDING' created_at='2023-11-13T14:51:44.611766Z' samples_count=13\n"
          ]
        },
        {
          "ename": "MissingSchema",
          "evalue": "Invalid URL '': No scheme supplied. Perhaps you meant https://?",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMissingSchema\u001b[0m                             Traceback (most recent call last)",
            "\u001b[1;32m/home/etaylor/code_projects/thesis/src/annotation_handling/notebooks/model_assisted_labeling.ipynb Cell 13\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a223133322e37322e36372e313536222c2275736572223a22657461796c6f72227d/home/etaylor/code_projects/thesis/src/annotation_handling/notebooks/model_assisted_labeling.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m pipe\u001b[39m.\u001b[39;49mupload_predictions(test_release, model)\n",
            "File \u001b[0;32m/sise/home/etaylor/code_projects/thesis/src/pipelines/model_assist_label_pipeline.py:60\u001b[0m, in \u001b[0;36mupload_predictions\u001b[0;34m(release, model)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mupload_predictions\u001b[39m(release, model):\n\u001b[1;32m     59\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mrelease=\u001b[39m\u001b[39m{\u001b[39;00mrelease\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 60\u001b[0m     dataset \u001b[39m=\u001b[39m SegmentsDataset(release)\n\u001b[1;32m     63\u001b[0m     \u001b[39mfor\u001b[39;00m sample \u001b[39min\u001b[39;00m dataset:\n\u001b[1;32m     64\u001b[0m         \u001b[39m# Generate label predictions\u001b[39;00m\n\u001b[1;32m     65\u001b[0m         image \u001b[39m=\u001b[39m sample[\u001b[39m\"\u001b[39m\u001b[39mimage\u001b[39m\u001b[39m\"\u001b[39m]\n",
            "File \u001b[0;32m~/.conda/envs/detectron/lib/python3.9/site-packages/segments/dataset.py:122\u001b[0m, in \u001b[0;36mSegmentsDataset.__init__\u001b[0;34m(self, release_file, labelset, filter_by, filter_by_metadata, segments_dir, preload, s3_client)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[39melse\u001b[39;00m:  \u001b[39m# If it's a release object\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     release_file_url \u001b[39m=\u001b[39m release_file\u001b[39m.\u001b[39mattributes\u001b[39m.\u001b[39murl\n\u001b[0;32m--> 122\u001b[0m     content \u001b[39m=\u001b[39m requests\u001b[39m.\u001b[39;49mget(cast(\u001b[39mstr\u001b[39;49m, release_file_url))  \u001b[39m# TODO Fix in backend.\u001b[39;00m\n\u001b[1;32m    123\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelease \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39mloads(content\u001b[39m.\u001b[39mcontent)\n\u001b[1;32m    124\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelease_file \u001b[39m=\u001b[39m release_file\n",
            "File \u001b[0;32m~/.conda/envs/detectron/lib/python3.9/site-packages/requests/api.py:73\u001b[0m, in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget\u001b[39m(url, params\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     63\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \n\u001b[1;32m     65\u001b[0m \u001b[39m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[39m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m     \u001b[39mreturn\u001b[39;00m request(\u001b[39m\"\u001b[39;49m\u001b[39mget\u001b[39;49m\u001b[39m\"\u001b[39;49m, url, params\u001b[39m=\u001b[39;49mparams, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[0;32m~/.conda/envs/detectron/lib/python3.9/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[39m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[39m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[39m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[39mwith\u001b[39;00m sessions\u001b[39m.\u001b[39mSession() \u001b[39mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[39mreturn\u001b[39;00m session\u001b[39m.\u001b[39;49mrequest(method\u001b[39m=\u001b[39;49mmethod, url\u001b[39m=\u001b[39;49murl, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[0;32m~/.conda/envs/detectron/lib/python3.9/site-packages/requests/sessions.py:575\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    562\u001b[0m \u001b[39m# Create the Request.\u001b[39;00m\n\u001b[1;32m    563\u001b[0m req \u001b[39m=\u001b[39m Request(\n\u001b[1;32m    564\u001b[0m     method\u001b[39m=\u001b[39mmethod\u001b[39m.\u001b[39mupper(),\n\u001b[1;32m    565\u001b[0m     url\u001b[39m=\u001b[39murl,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    573\u001b[0m     hooks\u001b[39m=\u001b[39mhooks,\n\u001b[1;32m    574\u001b[0m )\n\u001b[0;32m--> 575\u001b[0m prep \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprepare_request(req)\n\u001b[1;32m    577\u001b[0m proxies \u001b[39m=\u001b[39m proxies \u001b[39mor\u001b[39;00m {}\n\u001b[1;32m    579\u001b[0m settings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmerge_environment_settings(\n\u001b[1;32m    580\u001b[0m     prep\u001b[39m.\u001b[39murl, proxies, stream, verify, cert\n\u001b[1;32m    581\u001b[0m )\n",
            "File \u001b[0;32m~/.conda/envs/detectron/lib/python3.9/site-packages/requests/sessions.py:486\u001b[0m, in \u001b[0;36mSession.prepare_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    483\u001b[0m     auth \u001b[39m=\u001b[39m get_netrc_auth(request\u001b[39m.\u001b[39murl)\n\u001b[1;32m    485\u001b[0m p \u001b[39m=\u001b[39m PreparedRequest()\n\u001b[0;32m--> 486\u001b[0m p\u001b[39m.\u001b[39;49mprepare(\n\u001b[1;32m    487\u001b[0m     method\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mmethod\u001b[39m.\u001b[39;49mupper(),\n\u001b[1;32m    488\u001b[0m     url\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49murl,\n\u001b[1;32m    489\u001b[0m     files\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mfiles,\n\u001b[1;32m    490\u001b[0m     data\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mdata,\n\u001b[1;32m    491\u001b[0m     json\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mjson,\n\u001b[1;32m    492\u001b[0m     headers\u001b[39m=\u001b[39;49mmerge_setting(\n\u001b[1;32m    493\u001b[0m         request\u001b[39m.\u001b[39;49mheaders, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mheaders, dict_class\u001b[39m=\u001b[39;49mCaseInsensitiveDict\n\u001b[1;32m    494\u001b[0m     ),\n\u001b[1;32m    495\u001b[0m     params\u001b[39m=\u001b[39;49mmerge_setting(request\u001b[39m.\u001b[39;49mparams, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparams),\n\u001b[1;32m    496\u001b[0m     auth\u001b[39m=\u001b[39;49mmerge_setting(auth, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mauth),\n\u001b[1;32m    497\u001b[0m     cookies\u001b[39m=\u001b[39;49mmerged_cookies,\n\u001b[1;32m    498\u001b[0m     hooks\u001b[39m=\u001b[39;49mmerge_hooks(request\u001b[39m.\u001b[39;49mhooks, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhooks),\n\u001b[1;32m    499\u001b[0m )\n\u001b[1;32m    500\u001b[0m \u001b[39mreturn\u001b[39;00m p\n",
            "File \u001b[0;32m~/.conda/envs/detectron/lib/python3.9/site-packages/requests/models.py:368\u001b[0m, in \u001b[0;36mPreparedRequest.prepare\u001b[0;34m(self, method, url, headers, files, data, params, auth, cookies, hooks, json)\u001b[0m\n\u001b[1;32m    365\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Prepares the entire request with the given parameters.\"\"\"\u001b[39;00m\n\u001b[1;32m    367\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprepare_method(method)\n\u001b[0;32m--> 368\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprepare_url(url, params)\n\u001b[1;32m    369\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprepare_headers(headers)\n\u001b[1;32m    370\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprepare_cookies(cookies)\n",
            "File \u001b[0;32m~/.conda/envs/detectron/lib/python3.9/site-packages/requests/models.py:439\u001b[0m, in \u001b[0;36mPreparedRequest.prepare_url\u001b[0;34m(self, url, params)\u001b[0m\n\u001b[1;32m    436\u001b[0m     \u001b[39mraise\u001b[39;00m InvalidURL(\u001b[39m*\u001b[39me\u001b[39m.\u001b[39margs)\n\u001b[1;32m    438\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m scheme:\n\u001b[0;32m--> 439\u001b[0m     \u001b[39mraise\u001b[39;00m MissingSchema(\n\u001b[1;32m    440\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mInvalid URL \u001b[39m\u001b[39m{\u001b[39;00murl\u001b[39m!r}\u001b[39;00m\u001b[39m: No scheme supplied. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    441\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mPerhaps you meant https://\u001b[39m\u001b[39m{\u001b[39;00murl\u001b[39m}\u001b[39;00m\u001b[39m?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    442\u001b[0m     )\n\u001b[1;32m    444\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m host:\n\u001b[1;32m    445\u001b[0m     \u001b[39mraise\u001b[39;00m InvalidURL(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mInvalid URL \u001b[39m\u001b[39m{\u001b[39;00murl\u001b[39m!r}\u001b[39;00m\u001b[39m: No host supplied\u001b[39m\u001b[39m\"\u001b[39m)\n",
            "\u001b[0;31mMissingSchema\u001b[0m: Invalid URL '': No scheme supplied. Perhaps you meant https://?"
          ]
        }
      ],
      "source": [
        "pipe.upload_predictions(test_release, model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Delete the dataset - ONLY IF YOU WANT TO DELETE THE DATASET!!!\n",
        "DELETE_DATASET_NAME = \"\"\n",
        "segmentsai_handler.client.delete_dataset(DELETE_DATASET_NAME)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
