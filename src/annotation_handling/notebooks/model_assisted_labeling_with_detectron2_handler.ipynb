{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Wnygc-uoVLfx"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/etaylor/.conda/envs/detectron/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "from src.annotation_handling.segmentsai_handler import SegmentsAIHandler\n",
        "from src.pipelines import model_assist_label_pipeline as pipe \n",
        "from src.segmentation.framework_handlers.detectron2_handler import Detectron2Handler\n",
        "import config\n",
        "\n",
        "from segments import SegmentsDataset\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "segmentsai_handler = SegmentsAIHandler()\n",
        "TRAIN_DATASET_NAME = 'etaylor/all_cannabis_patches_multi_class'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rotyn89DLm7m"
      },
      "source": [
        "#### Train a segmentation model on the labeled images\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Setup Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RWWJKe0YfarR",
        "outputId": "0bc3cbea-c69c-4fc0-9c25-b6293ae5f760"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initializing dataset...\n",
            "Preloading all samples. This may take a while...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|\u001b[38;2;255;153;0m██████████\u001b[0m| 50/50 [00:04<00:00, 10.59it/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initialized dataset with 50 images.\n",
            "Exporting dataset. This may take a while...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|\u001b[38;2;255;153;0m██████████\u001b[0m| 50/50 [00:01<00:00, 36.93it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exported to checkpoints/detectron2/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x/06-12-2023_11-09-44/export_coco-instance_etaylor_all_cannabis_patches_multi_class_v0.1.json. Images in segments/etaylor_all_cannabis_patches_multi_class/v0.1\n",
            "\u001b[32m[12/06 11:09:51 d2.data.datasets.coco]: \u001b[0mLoaded 50 images in COCO format from checkpoints/detectron2/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x/06-12-2023_11-09-44/export_coco-instance_etaylor_all_cannabis_patches_multi_class_v0.1.json\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32m[12/06 11:09:56 d2.engine.defaults]: \u001b[0mModel:\n",
            "GeneralizedRCNN(\n",
            "  (backbone): FPN(\n",
            "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (top_block): LastLevelMaxPool()\n",
            "    (bottom_up): ResNet(\n",
            "      (stem): BasicStem(\n",
            "        (conv1): Conv2d(\n",
            "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (res2): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res3): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res4): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (4): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (5): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res5): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (proposal_generator): RPN(\n",
            "    (rpn_head): StandardRPNHead(\n",
            "      (conv): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "    (anchor_generator): DefaultAnchorGenerator(\n",
            "      (cell_anchors): BufferList()\n",
            "    )\n",
            "  )\n",
            "  (roi_heads): StandardROIHeads(\n",
            "    (box_pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
            "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
            "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (box_head): FastRCNNConvFCHead(\n",
            "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
            "      (fc_relu1): ReLU()\n",
            "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "      (fc_relu2): ReLU()\n",
            "    )\n",
            "    (box_predictor): FastRCNNOutputLayers(\n",
            "      (cls_score): Linear(in_features=1024, out_features=5, bias=True)\n",
            "      (bbox_pred): Linear(in_features=1024, out_features=16, bias=True)\n",
            "    )\n",
            "    (mask_pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
            "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
            "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (mask_head): MaskRCNNConvUpsampleHead(\n",
            "      (mask_fcn1): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (mask_fcn2): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (mask_fcn3): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (mask_fcn4): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
            "      (deconv_relu): ReLU()\n",
            "      (predictor): Conv2d(256, 4, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "  )\n",
            ")\n",
            "\u001b[32m[12/06 11:09:56 d2.data.datasets.coco]: \u001b[0mLoaded 50 images in COCO format from checkpoints/detectron2/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x/06-12-2023_11-09-44/export_coco-instance_etaylor_all_cannabis_patches_multi_class_v0.1.json\n",
            "\u001b[32m[12/06 11:09:56 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 50 images left.\n",
            "\u001b[32m[12/06 11:09:56 d2.data.build]: \u001b[0mDistribution of instances among all 4 categories:\n",
            "\u001b[36m|  category  | #instances   |  category  | #instances   |  category  | #instances   |\n",
            "|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|\n",
            "|  trichome  | 0            |   clear    | 183          |   cloudy   | 509          |\n",
            "|   amber    | 167          |            |              |            |              |\n",
            "|   total    | 859          |            |              |            |              |\u001b[0m\n",
            "\u001b[32m[12/06 11:09:56 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
            "\u001b[32m[12/06 11:09:56 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
            "\u001b[32m[12/06 11:09:56 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
            "\u001b[32m[12/06 11:09:56 d2.data.common]: \u001b[0mSerializing 50 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[12/06 11:09:56 d2.data.common]: \u001b[0mSerialized dataset takes 0.13 MiB\n",
            "\u001b[32m[12/06 11:09:56 d2.data.build]: \u001b[0mMaking batched data loader with batch_size=2\n",
            "\u001b[32m[12/06 11:09:56 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from https://dl.fbaipublicfiles.com/detectron2/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x/137849600/model_final_f10217.pkl ...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (5, 1024) in the model! You might want to double check if this is expected.\n",
            "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (5,) in the model! You might want to double check if this is expected.\n",
            "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (16, 1024) in the model! You might want to double check if this is expected.\n",
            "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (16,) in the model! You might want to double check if this is expected.\n",
            "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (4, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
            "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (4,) in the model! You might want to double check if this is expected.\n",
            "Some model parameters or buffers are not found in the checkpoint:\n",
            "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
            "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n",
            "\u001b[34mroi_heads.mask_head.predictor.{bias, weight}\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# Setup config for detectron2 model\n",
        "model_config = {\n",
        "'task_type': 'COCO-InstanceSegmentation',\n",
        "'model_type': 'mask_rcnn_R_50_FPN_3x',\n",
        "'dataset_name': TRAIN_DATASET_NAME,\n",
        "'release_version': \"v0.1\",\n",
        "'export_format': \"coco-instance\",\n",
        "'model_device': \"cuda\",\n",
        "}\n",
        "\n",
        "model = Detectron2Handler(**model_config)\n",
        "\n",
        "model.setup_training(\n",
        "    score_thresh_test=0.5,\n",
        "    num_workers=2,\n",
        "    ims_per_batch=2,\n",
        "    base_lr=0.00025,\n",
        "    max_iter=300,\n",
        "    batch_size_per_image=256,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Vizualize dataset images with masks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Optional - Visualize the train dataset\n",
        "model.plot_samples()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Train Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32m[12/06 11:10:14 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/etaylor/.conda/envs/detectron/lib/python3.9/site-packages/detectron2/data/detection_utils.py:446: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:180.)\n",
            "  torch.stack([torch.from_numpy(np.ascontiguousarray(x)) for x in masks])\n",
            "/home/etaylor/.conda/envs/detectron/lib/python3.9/site-packages/detectron2/data/detection_utils.py:446: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:180.)\n",
            "  torch.stack([torch.from_numpy(np.ascontiguousarray(x)) for x in masks])\n",
            "/home/etaylor/.conda/envs/detectron/lib/python3.9/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32m[12/06 11:10:19 d2.utils.events]: \u001b[0m eta: 0:00:39  iter: 19  total_loss: 4.205  loss_cls: 1.807  loss_box_reg: 0.5668  loss_mask: 0.6924  loss_rpn_cls: 1.135  loss_rpn_loc: 0.1041    time: 0.1419  last_time: 0.1558  data_time: 0.0215  last_data_time: 0.0049   lr: 1.6068e-05  max_mem: 2476M\n",
            "\u001b[32m[12/06 11:10:25 d2.utils.events]: \u001b[0m eta: 0:00:36  iter: 39  total_loss: 2.967  loss_cls: 1.363  loss_box_reg: 0.629  loss_mask: 0.6756  loss_rpn_cls: 0.2635  loss_rpn_loc: 0.08478    time: 0.1408  last_time: 0.1348  data_time: 0.0047  last_data_time: 0.0044   lr: 3.2718e-05  max_mem: 2476M\n",
            "\u001b[32m[12/06 11:10:28 d2.utils.events]: \u001b[0m eta: 0:00:33  iter: 59  total_loss: 2.527  loss_cls: 1.015  loss_box_reg: 0.7039  loss_mask: 0.6354  loss_rpn_cls: 0.1012  loss_rpn_loc: 0.07722    time: 0.1418  last_time: 0.1208  data_time: 0.0049  last_data_time: 0.0039   lr: 4.9367e-05  max_mem: 2505M\n",
            "\u001b[32m[12/06 11:10:31 d2.utils.events]: \u001b[0m eta: 0:00:30  iter: 79  total_loss: 2.238  loss_cls: 0.7769  loss_box_reg: 0.7354  loss_mask: 0.5727  loss_rpn_cls: 0.07871  loss_rpn_loc: 0.05948    time: 0.1414  last_time: 0.1616  data_time: 0.0052  last_data_time: 0.0098   lr: 6.6017e-05  max_mem: 2505M\n",
            "\u001b[32m[12/06 11:10:34 d2.utils.events]: \u001b[0m eta: 0:00:28  iter: 99  total_loss: 2.068  loss_cls: 0.6998  loss_box_reg: 0.7355  loss_mask: 0.5081  loss_rpn_cls: 0.0614  loss_rpn_loc: 0.06099    time: 0.1408  last_time: 0.1271  data_time: 0.0047  last_data_time: 0.0036   lr: 8.2668e-05  max_mem: 2505M\n",
            "\u001b[32m[12/06 11:10:37 d2.utils.events]: \u001b[0m eta: 0:00:25  iter: 119  total_loss: 1.992  loss_cls: 0.633  loss_box_reg: 0.7557  loss_mask: 0.4307  loss_rpn_cls: 0.07458  loss_rpn_loc: 0.0613    time: 0.1408  last_time: 0.1581  data_time: 0.0058  last_data_time: 0.0107   lr: 9.9318e-05  max_mem: 2505M\n",
            "\u001b[32m[12/06 11:10:40 d2.utils.events]: \u001b[0m eta: 0:00:22  iter: 139  total_loss: 1.902  loss_cls: 0.6216  loss_box_reg: 0.7497  loss_mask: 0.3924  loss_rpn_cls: 0.04483  loss_rpn_loc: 0.0635    time: 0.1412  last_time: 0.1456  data_time: 0.0053  last_data_time: 0.0085   lr: 0.00011597  max_mem: 2517M\n",
            "\u001b[32m[12/06 11:10:42 d2.utils.events]: \u001b[0m eta: 0:00:19  iter: 159  total_loss: 1.763  loss_cls: 0.5887  loss_box_reg: 0.713  loss_mask: 0.3731  loss_rpn_cls: 0.04524  loss_rpn_loc: 0.05388    time: 0.1411  last_time: 0.1504  data_time: 0.0050  last_data_time: 0.0031   lr: 0.00013262  max_mem: 2517M\n",
            "\u001b[32m[12/06 11:10:45 d2.utils.events]: \u001b[0m eta: 0:00:16  iter: 179  total_loss: 1.611  loss_cls: 0.5216  loss_box_reg: 0.6488  loss_mask: 0.3235  loss_rpn_cls: 0.04217  loss_rpn_loc: 0.05475    time: 0.1414  last_time: 0.1544  data_time: 0.0068  last_data_time: 0.0052   lr: 0.00014927  max_mem: 2517M\n",
            "\u001b[32m[12/06 11:10:48 d2.utils.events]: \u001b[0m eta: 0:00:14  iter: 199  total_loss: 1.548  loss_cls: 0.5141  loss_box_reg: 0.6446  loss_mask: 0.3105  loss_rpn_cls: 0.03684  loss_rpn_loc: 0.05118    time: 0.1412  last_time: 0.1361  data_time: 0.0051  last_data_time: 0.0064   lr: 0.00016592  max_mem: 2517M\n",
            "\u001b[32m[12/06 11:10:51 d2.utils.events]: \u001b[0m eta: 0:00:11  iter: 219  total_loss: 1.434  loss_cls: 0.4824  loss_box_reg: 0.576  loss_mask: 0.2754  loss_rpn_cls: 0.0317  loss_rpn_loc: 0.05849    time: 0.1408  last_time: 0.1273  data_time: 0.0048  last_data_time: 0.0037   lr: 0.00018257  max_mem: 2517M\n",
            "\u001b[32m[12/06 11:10:54 d2.utils.events]: \u001b[0m eta: 0:00:08  iter: 239  total_loss: 1.273  loss_cls: 0.4503  loss_box_reg: 0.4973  loss_mask: 0.2491  loss_rpn_cls: 0.02697  loss_rpn_loc: 0.06401    time: 0.1412  last_time: 0.1552  data_time: 0.0064  last_data_time: 0.0045   lr: 0.00019922  max_mem: 2517M\n",
            "\u001b[32m[12/06 11:10:57 d2.utils.events]: \u001b[0m eta: 0:00:05  iter: 259  total_loss: 1.247  loss_cls: 0.4454  loss_box_reg: 0.4535  loss_mask: 0.2237  loss_rpn_cls: 0.02974  loss_rpn_loc: 0.0556    time: 0.1412  last_time: 0.1512  data_time: 0.0048  last_data_time: 0.0046   lr: 0.00021587  max_mem: 2517M\n",
            "\u001b[32m[12/06 11:10:59 d2.utils.events]: \u001b[0m eta: 0:00:02  iter: 279  total_loss: 1.235  loss_cls: 0.4266  loss_box_reg: 0.4607  loss_mask: 0.2135  loss_rpn_cls: 0.03341  loss_rpn_loc: 0.05912    time: 0.1410  last_time: 0.1307  data_time: 0.0054  last_data_time: 0.0108   lr: 0.00023252  max_mem: 2517M\n",
            "\u001b[32m[12/06 11:11:03 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 299  total_loss: 1.127  loss_cls: 0.4288  loss_box_reg: 0.4093  loss_mask: 0.2198  loss_rpn_cls: 0.0296  loss_rpn_loc: 0.07089    time: 0.1412  last_time: 0.1415  data_time: 0.0044  last_data_time: 0.0047   lr: 0.00024917  max_mem: 2517M\n",
            "\u001b[32m[12/06 11:11:03 d2.engine.hooks]: \u001b[0mOverall training speed: 298 iterations in 0:00:42 (0.1412 s / it)\n",
            "\u001b[32m[12/06 11:11:03 d2.engine.hooks]: \u001b[0mTotal training time: 0:00:46 (0:00:04 on hooks)\n",
            "\u001b[32m[12/06 11:11:04 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from checkpoints/detectron2/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x/06-12-2023_11-09-44/model_final.pth ...\n"
          ]
        }
      ],
      "source": [
        "# Train the model\n",
        "model.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8MsoYDLduR8"
      },
      "source": [
        "#### Create a new dataset and upload images to him"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pK8SfINidxzP",
        "outputId": "3438e95d-4c34-4fb5-e573-5069fd59d4bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "name='cannabis_patches_week8_07_06_2023_3x_regular_IMG_1875' full_name='etaylor/cannabis_patches_week8_07_06_2023_3x_regular_IMG_1875' cloned_from=None description='cannabis patches week=week8_07_06_2023 zoom_type=3x_regular of image=IMG_1875.' category='other' public=False owner=Owner(username='etaylor', created_at='2022-12-28T12:53:18Z', email=None) created_at='2023-12-06T09:11:55.509751Z' enable_ratings=False enable_skip_labeling=True enable_skip_reviewing=False enable_save_button=False enable_label_status_verified=False enable_same_dimensions_track_constraint=False enable_interpolation=True task_type='segmentation-bitmap' label_stats=LabelStats(REVIEWED=None, REVIEWING_IN_PROGRESS=None, LABELED=None, LABELING_IN_PROGRESS=None, REJECTED=None, PRELABELED=None, SKIPPED=None, VERIFIED=None, UNLABELED=None, TOTAL=None) labeling_inactivity_timeout_seconds=None samples_count=0 collaborators_count=None task_attributes=TaskAttributes(format_version='0.1', categories=[TaskAttributeCategory(name='trichome', id=1, color=(65, 117, 5), has_instances=None, attributes=None, dimensions=None), TaskAttributeCategory(name='clear', id=2, color=(155, 155, 155), has_instances=None, attributes=None, dimensions=None), TaskAttributeCategory(name='cloudy', id=3, color=(255, 255, 255), has_instances=None, attributes=None, dimensions=None), TaskAttributeCategory(name='amber', id=4, color=(245, 166, 35), has_instances=None, attributes=None, dimensions=None)], image_attributes=None) labelsets=None role=None readme='' metadata={} noncollaborator_can_label=False noncollaborator_can_review=False insights_urls=None embeddings_enabled=None\n",
            "Uploaded IMG_1875.JPG and added as sample: uuid='01ab0a61-a5b3-4fcc-94b3-df5e6f77fec7' name='IMG_1875.JPG' attributes=ImageSampleAttributes(image=URL(url='https://segmentsai-prod.s3.eu-west-2.amazonaws.com/assets/etaylor/1cb6260c-0772-4fba-8d8a-0afcef14d708.jpg')) metadata={} created_at='2023-12-06T09:11:57.796279Z' created_by='etaylor' assigned_labeler=None assigned_reviewer=None comments=[] priority=0.0 has_embedding=False label=None issues=None dataset_full_name=None\n",
            "Uploaded IMG_1875_p0.png and added as sample: uuid='eb3a2f24-aa0b-4ba4-8161-a0f23fe2ee34' name='IMG_1875_p0.png' attributes=ImageSampleAttributes(image=URL(url='https://segmentsai-prod.s3.eu-west-2.amazonaws.com/assets/etaylor/a7702952-75f9-4a74-936a-922da6329c81.png')) metadata={} created_at='2023-12-06T09:11:58.332749Z' created_by='etaylor' assigned_labeler=None assigned_reviewer=None comments=[] priority=0.0 has_embedding=False label=None issues=None dataset_full_name=None\n",
            "Uploaded IMG_1875_p1.png and added as sample: uuid='4ddebc57-cc16-4d78-b830-5ad499486407' name='IMG_1875_p1.png' attributes=ImageSampleAttributes(image=URL(url='https://segmentsai-prod.s3.eu-west-2.amazonaws.com/assets/etaylor/dc78abbc-80d4-4b1a-8930-232e7c31e3a0.png')) metadata={} created_at='2023-12-06T09:11:59.046446Z' created_by='etaylor' assigned_labeler=None assigned_reviewer=None comments=[] priority=0.0 has_embedding=False label=None issues=None dataset_full_name=None\n",
            "Uploaded IMG_1875_p2.png and added as sample: uuid='d65e6101-e7af-4612-a9d7-abe2fcac285c' name='IMG_1875_p2.png' attributes=ImageSampleAttributes(image=URL(url='https://segmentsai-prod.s3.eu-west-2.amazonaws.com/assets/etaylor/22b5f0e7-3bab-4656-beeb-f772dcfafd30.png')) metadata={} created_at='2023-12-06T09:11:59.665313Z' created_by='etaylor' assigned_labeler=None assigned_reviewer=None comments=[] priority=0.0 has_embedding=False label=None issues=None dataset_full_name=None\n",
            "Uploaded IMG_1875_p3.png and added as sample: uuid='24b7a7f8-439d-4374-a4ad-81739e29432d' name='IMG_1875_p3.png' attributes=ImageSampleAttributes(image=URL(url='https://segmentsai-prod.s3.eu-west-2.amazonaws.com/assets/etaylor/8e3cf3df-92df-4322-8326-2e55325e4cc5.png')) metadata={} created_at='2023-12-06T09:12:00.224872Z' created_by='etaylor' assigned_labeler=None assigned_reviewer=None comments=[] priority=0.0 has_embedding=False label=None issues=None dataset_full_name=None\n",
            "Uploaded IMG_1875_p4.png and added as sample: uuid='79bedfa1-fa61-4333-8a48-88f98d80db2f' name='IMG_1875_p4.png' attributes=ImageSampleAttributes(image=URL(url='https://segmentsai-prod.s3.eu-west-2.amazonaws.com/assets/etaylor/afe46878-3071-4c76-a434-1d2e0eb77180.png')) metadata={} created_at='2023-12-06T09:12:00.807311Z' created_by='etaylor' assigned_labeler=None assigned_reviewer=None comments=[] priority=0.0 has_embedding=False label=None issues=None dataset_full_name=None\n",
            "Uploaded IMG_1875_p5.png and added as sample: uuid='0fa27e4f-0aa5-4350-84f0-a203cfb90f83' name='IMG_1875_p5.png' attributes=ImageSampleAttributes(image=URL(url='https://segmentsai-prod.s3.eu-west-2.amazonaws.com/assets/etaylor/773ee198-3049-4748-a193-3ad2deb55d70.png')) metadata={} created_at='2023-12-06T09:12:01.357370Z' created_by='etaylor' assigned_labeler=None assigned_reviewer=None comments=[] priority=0.0 has_embedding=False label=None issues=None dataset_full_name=None\n",
            "Uploaded IMG_1875_p6.png and added as sample: uuid='ccedfdb7-5b10-4deb-8824-930a4f040592' name='IMG_1875_p6.png' attributes=ImageSampleAttributes(image=URL(url='https://segmentsai-prod.s3.eu-west-2.amazonaws.com/assets/etaylor/0df1f2d8-071d-496d-aef7-a8b5fe7c6327.png')) metadata={} created_at='2023-12-06T09:12:01.945918Z' created_by='etaylor' assigned_labeler=None assigned_reviewer=None comments=[] priority=0.0 has_embedding=False label=None issues=None dataset_full_name=None\n",
            "Uploaded IMG_1875_p7.png and added as sample: uuid='00556f79-1413-4e37-a863-54afa5936e41' name='IMG_1875_p7.png' attributes=ImageSampleAttributes(image=URL(url='https://segmentsai-prod.s3.eu-west-2.amazonaws.com/assets/etaylor/650a967f-2e3e-40b3-bdd0-601c1fdf0e06.png')) metadata={} created_at='2023-12-06T09:12:02.499331Z' created_by='etaylor' assigned_labeler=None assigned_reviewer=None comments=[] priority=0.0 has_embedding=False label=None issues=None dataset_full_name=None\n",
            "Uploaded IMG_1875_p8.png and added as sample: uuid='5c89435a-0ab5-484a-8e77-e18d2eb53d30' name='IMG_1875_p8.png' attributes=ImageSampleAttributes(image=URL(url='https://segmentsai-prod.s3.eu-west-2.amazonaws.com/assets/etaylor/964a168e-1bf9-4e63-b958-6732fa1a85c0.png')) metadata={} created_at='2023-12-06T09:12:03.276716Z' created_by='etaylor' assigned_labeler=None assigned_reviewer=None comments=[] priority=0.0 has_embedding=False label=None issues=None dataset_full_name=None\n",
            "Uploaded IMG_1875_p9.png and added as sample: uuid='8fc1826f-57d8-43ae-8d86-1cabc0ed8f71' name='IMG_1875_p9.png' attributes=ImageSampleAttributes(image=URL(url='https://segmentsai-prod.s3.eu-west-2.amazonaws.com/assets/etaylor/b532dad5-acfd-4aed-9f10-3b0aaf4c4817.png')) metadata={} created_at='2023-12-06T09:12:03.905536Z' created_by='etaylor' assigned_labeler=None assigned_reviewer=None comments=[] priority=0.0 has_embedding=False label=None issues=None dataset_full_name=None\n",
            "Uploaded IMG_1875_p10.png and added as sample: uuid='c7fe1830-2f1b-467f-9eaf-9050636e0b68' name='IMG_1875_p10.png' attributes=ImageSampleAttributes(image=URL(url='https://segmentsai-prod.s3.eu-west-2.amazonaws.com/assets/etaylor/f28afd4f-a411-4055-ab0c-bb52626bc8ac.png')) metadata={} created_at='2023-12-06T09:12:04.513476Z' created_by='etaylor' assigned_labeler=None assigned_reviewer=None comments=[] priority=0.0 has_embedding=False label=None issues=None dataset_full_name=None\n",
            "Uploaded IMG_1875_p11.png and added as sample: uuid='190e116b-b4c9-4532-832c-3a45fff97cd6' name='IMG_1875_p11.png' attributes=ImageSampleAttributes(image=URL(url='https://segmentsai-prod.s3.eu-west-2.amazonaws.com/assets/etaylor/037c5d3c-cdeb-445d-b4e3-94d6fff4ea05.png')) metadata={} created_at='2023-12-06T09:12:04.988426Z' created_by='etaylor' assigned_labeler=None assigned_reviewer=None comments=[] priority=0.0 has_embedding=False label=None issues=None dataset_full_name=None\n"
          ]
        }
      ],
      "source": [
        "# New dataset to upload variables\n",
        "image_name = \"IMG_1875\"\n",
        "week = 'week8'\n",
        "zoom_type = '3xr'\n",
        "\n",
        "# Create a new test dataset for the specified image, week, and zoom type\n",
        "test_dataset = pipe.create_new_test_dataset(image_name, config.WEEKS_DIR[week], config.ZOOM_TYPES_DIR[zoom_type], single_category=False)\n",
        "# # Get the absolute path to the processed image\n",
        "abs_images_path = f\"{config.get_processed_cannabis_image_path(week, zoom_type)}/{image_name}\"\n",
        "raw_images_path = f\"{config.get_raw_image_path(week, zoom_type)}/{image_name}.JPG\"\n",
        "\n",
        "# Upload the images that are not annotated to the dataset\n",
        "segmentsai_handler.upload_single_image(test_dataset, raw_images_path) # upload the raw image path\n",
        "segmentsai_handler.upload_images(test_dataset, abs_images_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Waiting 5 seconds that the release is created...\n",
            "uuid='af151ebb-0729-4c61-b309-f53013f5807f' name='v0.1' description='upload predictions to dataset.' release_type='JSON' attributes=URL(url='https://segmentsai-prod.s3.amazonaws.com/releases/af151ebb-0729-4c61-b309-f53013f5807f.json?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIA5RYRXRX22Y5Q2VMR%2F20231206%2Feu-west-2%2Fs3%2Faws4_request&X-Amz-Date=20231206T091213Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=8d313214f86edca98a2ed61363f97d4d244d4d24b32745a8b045e1512138cccf') status='SUCCEEDED' created_at='2023-12-06T09:12:08.026044Z' samples_count=13\n"
          ]
        }
      ],
      "source": [
        "release_name = \"v0.1\"\n",
        "description = \"upload predictions to dataset.\"\n",
        "segmentsai_handler.client.add_release(test_dataset, release_name, description)\n",
        "print(\"Waiting 5 seconds that the release is created...\")\n",
        "time.sleep(5)\n",
        "test_release = segmentsai_handler.client.get_release(test_dataset, \"v0.1\")\n",
        "print(test_release)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Optional - Load a model checkpoint without training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "# checkpoint_path = \"checkpoints/detectron2/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x/01-12-2023_20-50-03/model_final.pth\"\n",
        "# model.load_checkpoint(checkpoint_path=checkpoint_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lpX-71UwlW6o"
      },
      "source": [
        "### Upload the Images that are not annotated to the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gozhWa6Ahvxm",
        "outputId": "f73115aa-9519-491c-ac9d-8da8a6b8b70b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initializing dataset...\n",
            "Preloading all samples. This may take a while...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|\u001b[38;2;255;153;0m██████████\u001b[0m| 13/13 [00:00<00:00, 106.37it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initialized dataset with 13 images.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "test_dataset_instance = SegmentsDataset(test_release)\n",
        "\n",
        "for sample in test_dataset_instance:\n",
        "    # Generate label predictions\n",
        "    image = np.array(sample[\"image\"])\n",
        "    segmentation_bitmap, annotations = model.predict_image(image)\n",
        "    segmentsai_handler.upload_annotation_for_sample(sample['uuid'], segmentation_bitmap, annotations)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Delete the dataset - ONLY IF YOU WANT TO DELETE THE DATASET!!!\n",
        "DELETE_DATASET_NAME = \"etaylor/cannabis_patches_week9_15_06_2023_3x_regular_IMG_2155\"\n",
        "segmentsai_handler.client.delete_dataset(DELETE_DATASET_NAME)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
