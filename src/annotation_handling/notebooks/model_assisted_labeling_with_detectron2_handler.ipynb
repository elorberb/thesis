{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Wnygc-uoVLfx"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/etaylor/.conda/envs/detectron/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "from src.annotation_handling.segmentsai_handler import SegmentsAIHandler\n",
        "from src.pipelines import model_assist_label_pipeline as pipe \n",
        "from src.segmentation.framework_handlers.detectron2_handler import Detectron2Handler\n",
        "import config\n",
        "\n",
        "from segments import SegmentsDataset\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "segmentsai_handler = SegmentsAIHandler()\n",
        "TRAIN_DATASET_NAME = 'etaylor/all_cannabis_patches_multi_class'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rotyn89DLm7m"
      },
      "source": [
        "#### Train a segmentation model on the labeled images\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Setup Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RWWJKe0YfarR",
        "outputId": "0bc3cbea-c69c-4fc0-9c25-b6293ae5f760"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initializing dataset...\n",
            "Preloading all samples. This may take a while...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|\u001b[38;2;255;153;0m██████████\u001b[0m| 50/50 [00:00<00:00, 226.40it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initialized dataset with 50 images.\n",
            "Exporting dataset. This may take a while...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|\u001b[38;2;255;153;0m██████████\u001b[0m| 50/50 [00:01<00:00, 36.31it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exported to checkpoints/detectron2/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x/06-12-2023_18-47-26/export_coco-instance_etaylor_all_cannabis_patches_multi_class_v0.1.json. Images in segments/etaylor_all_cannabis_patches_multi_class/v0.1\n",
            "\u001b[32m[12/06 18:47:30 d2.data.datasets.coco]: \u001b[0mLoaded 50 images in COCO format from checkpoints/detectron2/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x/06-12-2023_18-47-26/export_coco-instance_etaylor_all_cannabis_patches_multi_class_v0.1.json\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32m[12/06 18:47:56 d2.engine.defaults]: \u001b[0mModel:\n",
            "GeneralizedRCNN(\n",
            "  (backbone): FPN(\n",
            "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (top_block): LastLevelMaxPool()\n",
            "    (bottom_up): ResNet(\n",
            "      (stem): BasicStem(\n",
            "        (conv1): Conv2d(\n",
            "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (res2): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res3): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res4): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (4): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (5): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res5): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (proposal_generator): RPN(\n",
            "    (rpn_head): StandardRPNHead(\n",
            "      (conv): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "    (anchor_generator): DefaultAnchorGenerator(\n",
            "      (cell_anchors): BufferList()\n",
            "    )\n",
            "  )\n",
            "  (roi_heads): StandardROIHeads(\n",
            "    (box_pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
            "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
            "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (box_head): FastRCNNConvFCHead(\n",
            "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
            "      (fc_relu1): ReLU()\n",
            "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "      (fc_relu2): ReLU()\n",
            "    )\n",
            "    (box_predictor): FastRCNNOutputLayers(\n",
            "      (cls_score): Linear(in_features=1024, out_features=5, bias=True)\n",
            "      (bbox_pred): Linear(in_features=1024, out_features=16, bias=True)\n",
            "    )\n",
            "    (mask_pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
            "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
            "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (mask_head): MaskRCNNConvUpsampleHead(\n",
            "      (mask_fcn1): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (mask_fcn2): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (mask_fcn3): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (mask_fcn4): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
            "      (deconv_relu): ReLU()\n",
            "      (predictor): Conv2d(256, 4, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "  )\n",
            ")\n",
            "\u001b[32m[12/06 18:47:56 d2.data.datasets.coco]: \u001b[0mLoaded 50 images in COCO format from checkpoints/detectron2/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x/06-12-2023_18-47-26/export_coco-instance_etaylor_all_cannabis_patches_multi_class_v0.1.json\n",
            "\u001b[32m[12/06 18:47:56 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 50 images left.\n",
            "\u001b[32m[12/06 18:47:56 d2.data.build]: \u001b[0mDistribution of instances among all 4 categories:\n",
            "\u001b[36m|  category  | #instances   |  category  | #instances   |  category  | #instances   |\n",
            "|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|\n",
            "|  trichome  | 0            |   clear    | 183          |   cloudy   | 509          |\n",
            "|   amber    | 167          |            |              |            |              |\n",
            "|   total    | 859          |            |              |            |              |\u001b[0m\n",
            "\u001b[32m[12/06 18:47:56 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
            "\u001b[32m[12/06 18:47:56 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
            "\u001b[32m[12/06 18:47:56 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
            "\u001b[32m[12/06 18:47:56 d2.data.common]: \u001b[0mSerializing 50 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[12/06 18:47:56 d2.data.common]: \u001b[0mSerialized dataset takes 0.13 MiB\n",
            "\u001b[32m[12/06 18:47:56 d2.data.build]: \u001b[0mMaking batched data loader with batch_size=2\n",
            "\u001b[32m[12/06 18:47:56 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from https://dl.fbaipublicfiles.com/detectron2/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x/137849600/model_final_f10217.pkl ...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (5, 1024) in the model! You might want to double check if this is expected.\n",
            "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (5,) in the model! You might want to double check if this is expected.\n",
            "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (16, 1024) in the model! You might want to double check if this is expected.\n",
            "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (16,) in the model! You might want to double check if this is expected.\n",
            "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (4, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
            "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (4,) in the model! You might want to double check if this is expected.\n",
            "Some model parameters or buffers are not found in the checkpoint:\n",
            "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
            "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n",
            "\u001b[34mroi_heads.mask_head.predictor.{bias, weight}\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# Setup config for detectron2 model\n",
        "model_config = {\n",
        "'task_type': 'COCO-InstanceSegmentation',\n",
        "'model_type': 'mask_rcnn_R_50_FPN_3x',\n",
        "'dataset_name': TRAIN_DATASET_NAME,\n",
        "'release_version': \"v0.1\",\n",
        "'export_format': \"coco-instance\",\n",
        "'model_device': \"cuda\",\n",
        "}\n",
        "\n",
        "model = Detectron2Handler(**model_config)\n",
        "\n",
        "model.setup_training(\n",
        "    score_thresh_test=0.5,\n",
        "    num_workers=2,\n",
        "    ims_per_batch=2,\n",
        "    base_lr=0.00025,\n",
        "    max_iter=750,\n",
        "    batch_size_per_image=256,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Vizualize dataset images with masks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Optional - Visualize the train dataset\n",
        "model.plot_samples()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Train Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32m[12/06 18:47:58 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/etaylor/.conda/envs/detectron/lib/python3.9/site-packages/detectron2/data/detection_utils.py:446: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:180.)\n",
            "  torch.stack([torch.from_numpy(np.ascontiguousarray(x)) for x in masks])\n",
            "/home/etaylor/.conda/envs/detectron/lib/python3.9/site-packages/detectron2/data/detection_utils.py:446: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:180.)\n",
            "  torch.stack([torch.from_numpy(np.ascontiguousarray(x)) for x in masks])\n",
            "/home/etaylor/.conda/envs/detectron/lib/python3.9/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32m[12/06 18:48:04 d2.utils.events]: \u001b[0m eta: 0:03:05  iter: 19  total_loss: 4.387  loss_cls: 1.651  loss_box_reg: 0.5132  loss_mask: 0.6895  loss_rpn_cls: 1.368  loss_rpn_loc: 0.1253    time: 0.2569  last_time: 0.2805  data_time: 0.0147  last_data_time: 0.0036   lr: 6.577e-06  max_mem: 2497M\n",
            "\u001b[32m[12/06 18:48:09 d2.utils.events]: \u001b[0m eta: 0:02:56  iter: 39  total_loss: 3.444  loss_cls: 1.496  loss_box_reg: 0.563  loss_mask: 0.6836  loss_rpn_cls: 0.5936  loss_rpn_loc: 0.06943    time: 0.2500  last_time: 0.2483  data_time: 0.0041  last_data_time: 0.0054   lr: 1.3237e-05  max_mem: 2497M\n",
            "\u001b[32m[12/06 18:48:14 d2.utils.events]: \u001b[0m eta: 0:02:55  iter: 59  total_loss: 3.034  loss_cls: 1.281  loss_box_reg: 0.7093  loss_mask: 0.668  loss_rpn_cls: 0.3072  loss_rpn_loc: 0.09509    time: 0.2542  last_time: 0.2682  data_time: 0.0043  last_data_time: 0.0037   lr: 1.9897e-05  max_mem: 2508M\n",
            "\u001b[32m[12/06 18:48:19 d2.utils.events]: \u001b[0m eta: 0:02:50  iter: 79  total_loss: 2.607  loss_cls: 1.061  loss_box_reg: 0.7199  loss_mask: 0.6432  loss_rpn_cls: 0.1304  loss_rpn_loc: 0.0759    time: 0.2538  last_time: 0.2327  data_time: 0.0044  last_data_time: 0.0048   lr: 2.6557e-05  max_mem: 2508M\n",
            "\u001b[32m[12/06 18:48:25 d2.utils.events]: \u001b[0m eta: 0:02:46  iter: 99  total_loss: 2.392  loss_cls: 0.8548  loss_box_reg: 0.7399  loss_mask: 0.6116  loss_rpn_cls: 0.07906  loss_rpn_loc: 0.05632    time: 0.2565  last_time: 0.2439  data_time: 0.0042  last_data_time: 0.0035   lr: 3.3217e-05  max_mem: 2508M\n",
            "\u001b[32m[12/06 18:48:30 d2.utils.events]: \u001b[0m eta: 0:02:41  iter: 119  total_loss: 2.22  loss_cls: 0.7501  loss_box_reg: 0.7438  loss_mask: 0.5743  loss_rpn_cls: 0.09163  loss_rpn_loc: 0.06818    time: 0.2571  last_time: 0.2622  data_time: 0.0040  last_data_time: 0.0034   lr: 3.9877e-05  max_mem: 2508M\n",
            "\u001b[32m[12/06 18:48:35 d2.utils.events]: \u001b[0m eta: 0:02:37  iter: 139  total_loss: 2.151  loss_cls: 0.7093  loss_box_reg: 0.7749  loss_mask: 0.5213  loss_rpn_cls: 0.07912  loss_rpn_loc: 0.06491    time: 0.2587  last_time: 0.2549  data_time: 0.0042  last_data_time: 0.0039   lr: 4.6537e-05  max_mem: 2510M\n",
            "\u001b[32m[12/06 18:48:41 d2.utils.events]: \u001b[0m eta: 0:02:32  iter: 159  total_loss: 1.981  loss_cls: 0.671  loss_box_reg: 0.7308  loss_mask: 0.479  loss_rpn_cls: 0.06351  loss_rpn_loc: 0.06169    time: 0.2584  last_time: 0.2116  data_time: 0.0040  last_data_time: 0.0040   lr: 5.3197e-05  max_mem: 2510M\n",
            "\u001b[32m[12/06 18:48:46 d2.utils.events]: \u001b[0m eta: 0:02:27  iter: 179  total_loss: 1.946  loss_cls: 0.6523  loss_box_reg: 0.7548  loss_mask: 0.4536  loss_rpn_cls: 0.06008  loss_rpn_loc: 0.06404    time: 0.2587  last_time: 0.2406  data_time: 0.0044  last_data_time: 0.0048   lr: 5.9857e-05  max_mem: 2527M\n",
            "\u001b[32m[12/06 18:48:51 d2.utils.events]: \u001b[0m eta: 0:02:22  iter: 199  total_loss: 1.898  loss_cls: 0.6208  loss_box_reg: 0.74  loss_mask: 0.3955  loss_rpn_cls: 0.05447  loss_rpn_loc: 0.06506    time: 0.2591  last_time: 0.3139  data_time: 0.0052  last_data_time: 0.0280   lr: 6.6517e-05  max_mem: 2527M\n",
            "\u001b[32m[12/06 18:48:56 d2.utils.events]: \u001b[0m eta: 0:02:17  iter: 219  total_loss: 1.8  loss_cls: 0.5903  loss_box_reg: 0.7176  loss_mask: 0.3812  loss_rpn_cls: 0.04606  loss_rpn_loc: 0.05574    time: 0.2591  last_time: 0.2616  data_time: 0.0043  last_data_time: 0.0046   lr: 7.3177e-05  max_mem: 2527M\n",
            "\u001b[32m[12/06 18:49:02 d2.utils.events]: \u001b[0m eta: 0:02:12  iter: 239  total_loss: 1.712  loss_cls: 0.5672  loss_box_reg: 0.6845  loss_mask: 0.3562  loss_rpn_cls: 0.04848  loss_rpn_loc: 0.05965    time: 0.2597  last_time: 0.2408  data_time: 0.0048  last_data_time: 0.0041   lr: 7.9837e-05  max_mem: 2527M\n",
            "\u001b[32m[12/06 18:49:07 d2.utils.events]: \u001b[0m eta: 0:02:07  iter: 259  total_loss: 1.723  loss_cls: 0.5684  loss_box_reg: 0.6987  loss_mask: 0.3546  loss_rpn_cls: 0.04786  loss_rpn_loc: 0.06057    time: 0.2598  last_time: 0.2759  data_time: 0.0041  last_data_time: 0.0041   lr: 8.6497e-05  max_mem: 2527M\n",
            "\u001b[32m[12/06 18:49:12 d2.utils.events]: \u001b[0m eta: 0:02:02  iter: 279  total_loss: 1.595  loss_cls: 0.5256  loss_box_reg: 0.6498  loss_mask: 0.3226  loss_rpn_cls: 0.04024  loss_rpn_loc: 0.06209    time: 0.2599  last_time: 0.2746  data_time: 0.0046  last_data_time: 0.0035   lr: 9.3157e-05  max_mem: 2527M\n",
            "\u001b[32m[12/06 18:49:17 d2.utils.events]: \u001b[0m eta: 0:01:57  iter: 299  total_loss: 1.634  loss_cls: 0.5345  loss_box_reg: 0.6525  loss_mask: 0.3146  loss_rpn_cls: 0.05191  loss_rpn_loc: 0.05788    time: 0.2599  last_time: 0.2830  data_time: 0.0041  last_data_time: 0.0042   lr: 9.9817e-05  max_mem: 2527M\n",
            "\u001b[32m[12/06 18:49:23 d2.utils.events]: \u001b[0m eta: 0:01:51  iter: 319  total_loss: 1.489  loss_cls: 0.4919  loss_box_reg: 0.6007  loss_mask: 0.2982  loss_rpn_cls: 0.04194  loss_rpn_loc: 0.05319    time: 0.2600  last_time: 0.2828  data_time: 0.0045  last_data_time: 0.0045   lr: 0.00010648  max_mem: 2527M\n",
            "\u001b[32m[12/06 18:49:28 d2.utils.events]: \u001b[0m eta: 0:01:46  iter: 339  total_loss: 1.47  loss_cls: 0.5146  loss_box_reg: 0.5845  loss_mask: 0.2797  loss_rpn_cls: 0.04512  loss_rpn_loc: 0.05825    time: 0.2603  last_time: 0.2401  data_time: 0.0039  last_data_time: 0.0039   lr: 0.00011314  max_mem: 2527M\n",
            "\u001b[32m[12/06 18:49:33 d2.utils.events]: \u001b[0m eta: 0:01:41  iter: 359  total_loss: 1.366  loss_cls: 0.4746  loss_box_reg: 0.5065  loss_mask: 0.2602  loss_rpn_cls: 0.0301  loss_rpn_loc: 0.05841    time: 0.2609  last_time: 0.2536  data_time: 0.0041  last_data_time: 0.0047   lr: 0.0001198  max_mem: 2527M\n",
            "\u001b[32m[12/06 18:49:39 d2.utils.events]: \u001b[0m eta: 0:01:36  iter: 379  total_loss: 1.273  loss_cls: 0.4568  loss_box_reg: 0.4703  loss_mask: 0.2433  loss_rpn_cls: 0.03234  loss_rpn_loc: 0.0481    time: 0.2609  last_time: 0.2681  data_time: 0.0040  last_data_time: 0.0036   lr: 0.00012646  max_mem: 2527M\n",
            "\u001b[32m[12/06 18:49:44 d2.utils.events]: \u001b[0m eta: 0:01:31  iter: 399  total_loss: 1.327  loss_cls: 0.4696  loss_box_reg: 0.4693  loss_mask: 0.2349  loss_rpn_cls: 0.03306  loss_rpn_loc: 0.05232    time: 0.2614  last_time: 0.2355  data_time: 0.0041  last_data_time: 0.0045   lr: 0.00013312  max_mem: 2527M\n",
            "\u001b[32m[12/06 18:49:49 d2.utils.events]: \u001b[0m eta: 0:01:26  iter: 419  total_loss: 1.2  loss_cls: 0.4441  loss_box_reg: 0.4653  loss_mask: 0.2255  loss_rpn_cls: 0.0439  loss_rpn_loc: 0.05402    time: 0.2613  last_time: 0.2743  data_time: 0.0039  last_data_time: 0.0036   lr: 0.00013978  max_mem: 2527M\n",
            "\u001b[32m[12/06 18:49:54 d2.utils.events]: \u001b[0m eta: 0:01:21  iter: 439  total_loss: 1.148  loss_cls: 0.4144  loss_box_reg: 0.4174  loss_mask: 0.2105  loss_rpn_cls: 0.02824  loss_rpn_loc: 0.04893    time: 0.2612  last_time: 0.2483  data_time: 0.0044  last_data_time: 0.0055   lr: 0.00014644  max_mem: 2527M\n",
            "\u001b[32m[12/06 18:50:00 d2.utils.events]: \u001b[0m eta: 0:01:15  iter: 459  total_loss: 1.149  loss_cls: 0.4215  loss_box_reg: 0.4071  loss_mask: 0.2032  loss_rpn_cls: 0.03405  loss_rpn_loc: 0.05752    time: 0.2612  last_time: 0.2745  data_time: 0.0040  last_data_time: 0.0035   lr: 0.0001531  max_mem: 2527M\n",
            "\u001b[32m[12/06 18:50:05 d2.utils.events]: \u001b[0m eta: 0:01:10  iter: 479  total_loss: 1.159  loss_cls: 0.4293  loss_box_reg: 0.3842  loss_mask: 0.2114  loss_rpn_cls: 0.03102  loss_rpn_loc: 0.05348    time: 0.2614  last_time: 0.2602  data_time: 0.0041  last_data_time: 0.0044   lr: 0.00015976  max_mem: 2527M\n",
            "\u001b[32m[12/06 18:50:10 d2.utils.events]: \u001b[0m eta: 0:01:05  iter: 499  total_loss: 1.097  loss_cls: 0.4027  loss_box_reg: 0.3725  loss_mask: 0.2116  loss_rpn_cls: 0.02491  loss_rpn_loc: 0.05806    time: 0.2616  last_time: 0.2954  data_time: 0.0043  last_data_time: 0.0037   lr: 0.00016642  max_mem: 2527M\n",
            "\u001b[32m[12/06 18:50:16 d2.utils.events]: \u001b[0m eta: 0:01:00  iter: 519  total_loss: 1.06  loss_cls: 0.3877  loss_box_reg: 0.3744  loss_mask: 0.1955  loss_rpn_cls: 0.0218  loss_rpn_loc: 0.05309    time: 0.2620  last_time: 0.2920  data_time: 0.0041  last_data_time: 0.0041   lr: 0.00017308  max_mem: 2527M\n",
            "\u001b[32m[12/06 18:50:21 d2.utils.events]: \u001b[0m eta: 0:00:55  iter: 539  total_loss: 1.031  loss_cls: 0.3744  loss_box_reg: 0.3491  loss_mask: 0.2061  loss_rpn_cls: 0.02554  loss_rpn_loc: 0.0501    time: 0.2623  last_time: 0.2940  data_time: 0.0045  last_data_time: 0.0044   lr: 0.00017974  max_mem: 2527M\n",
            "\u001b[32m[12/06 18:50:27 d2.utils.events]: \u001b[0m eta: 0:00:49  iter: 559  total_loss: 1.014  loss_cls: 0.3791  loss_box_reg: 0.3653  loss_mask: 0.2014  loss_rpn_cls: 0.0242  loss_rpn_loc: 0.05059    time: 0.2624  last_time: 0.2565  data_time: 0.0050  last_data_time: 0.0034   lr: 0.0001864  max_mem: 2527M\n",
            "\u001b[32m[12/06 18:50:32 d2.utils.events]: \u001b[0m eta: 0:00:44  iter: 579  total_loss: 0.9172  loss_cls: 0.3423  loss_box_reg: 0.3145  loss_mask: 0.1839  loss_rpn_cls: 0.01814  loss_rpn_loc: 0.04328    time: 0.2625  last_time: 0.2490  data_time: 0.0044  last_data_time: 0.0038   lr: 0.00019306  max_mem: 2527M\n",
            "\u001b[32m[12/06 18:50:37 d2.utils.events]: \u001b[0m eta: 0:00:39  iter: 599  total_loss: 1.007  loss_cls: 0.3764  loss_box_reg: 0.3437  loss_mask: 0.1983  loss_rpn_cls: 0.0205  loss_rpn_loc: 0.05398    time: 0.2627  last_time: 0.2840  data_time: 0.0049  last_data_time: 0.0034   lr: 0.00019972  max_mem: 2527M\n",
            "\u001b[32m[12/06 18:50:43 d2.utils.events]: \u001b[0m eta: 0:00:34  iter: 619  total_loss: 0.9331  loss_cls: 0.3491  loss_box_reg: 0.2984  loss_mask: 0.1786  loss_rpn_cls: 0.02053  loss_rpn_loc: 0.04746    time: 0.2627  last_time: 0.3016  data_time: 0.0045  last_data_time: 0.0077   lr: 0.00020638  max_mem: 2527M\n",
            "\u001b[32m[12/06 18:50:48 d2.utils.events]: \u001b[0m eta: 0:00:28  iter: 639  total_loss: 0.942  loss_cls: 0.3449  loss_box_reg: 0.3113  loss_mask: 0.187  loss_rpn_cls: 0.01824  loss_rpn_loc: 0.05207    time: 0.2631  last_time: 0.2690  data_time: 0.0042  last_data_time: 0.0040   lr: 0.00021304  max_mem: 2527M\n",
            "\u001b[32m[12/06 18:50:54 d2.utils.events]: \u001b[0m eta: 0:00:23  iter: 659  total_loss: 0.9085  loss_cls: 0.3376  loss_box_reg: 0.3038  loss_mask: 0.1889  loss_rpn_cls: 0.01996  loss_rpn_loc: 0.04674    time: 0.2634  last_time: 0.2937  data_time: 0.0046  last_data_time: 0.0047   lr: 0.0002197  max_mem: 2527M\n",
            "\u001b[32m[12/06 18:50:59 d2.utils.events]: \u001b[0m eta: 0:00:18  iter: 679  total_loss: 0.9009  loss_cls: 0.3325  loss_box_reg: 0.3192  loss_mask: 0.195  loss_rpn_cls: 0.0191  loss_rpn_loc: 0.04521    time: 0.2635  last_time: 0.2889  data_time: 0.0040  last_data_time: 0.0036   lr: 0.00022636  max_mem: 2527M\n",
            "\u001b[32m[12/06 18:51:04 d2.utils.events]: \u001b[0m eta: 0:00:13  iter: 699  total_loss: 0.9022  loss_cls: 0.3294  loss_box_reg: 0.3068  loss_mask: 0.1896  loss_rpn_cls: 0.0169  loss_rpn_loc: 0.0479    time: 0.2638  last_time: 0.2893  data_time: 0.0042  last_data_time: 0.0059   lr: 0.00023302  max_mem: 2527M\n",
            "\u001b[32m[12/06 18:51:10 d2.utils.events]: \u001b[0m eta: 0:00:07  iter: 719  total_loss: 0.8684  loss_cls: 0.3002  loss_box_reg: 0.2999  loss_mask: 0.1767  loss_rpn_cls: 0.01923  loss_rpn_loc: 0.05282    time: 0.2638  last_time: 0.2373  data_time: 0.0039  last_data_time: 0.0035   lr: 0.00023968  max_mem: 2527M\n",
            "\u001b[32m[12/06 18:51:15 d2.utils.events]: \u001b[0m eta: 0:00:02  iter: 739  total_loss: 0.8998  loss_cls: 0.319  loss_box_reg: 0.2985  loss_mask: 0.1845  loss_rpn_cls: 0.0198  loss_rpn_loc: 0.04879    time: 0.2640  last_time: 0.2880  data_time: 0.0041  last_data_time: 0.0045   lr: 0.00024634  max_mem: 2527M\n",
            "\u001b[32m[12/06 18:51:20 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 749  total_loss: 0.9071  loss_cls: 0.3167  loss_box_reg: 0.3127  loss_mask: 0.1811  loss_rpn_cls: 0.02055  loss_rpn_loc: 0.04902    time: 0.2640  last_time: 0.2538  data_time: 0.0041  last_data_time: 0.0036   lr: 0.00024967  max_mem: 2527M\n",
            "\u001b[32m[12/06 18:51:20 d2.engine.hooks]: \u001b[0mOverall training speed: 748 iterations in 0:03:17 (0.2641 s / it)\n",
            "\u001b[32m[12/06 18:51:20 d2.engine.hooks]: \u001b[0mTotal training time: 0:03:21 (0:00:03 on hooks)\n",
            "\u001b[32m[12/06 18:51:21 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from checkpoints/detectron2/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x/06-12-2023_18-47-26/model_final.pth ...\n"
          ]
        }
      ],
      "source": [
        "# Train the model\n",
        "model.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8MsoYDLduR8"
      },
      "source": [
        "#### Create a new dataset and upload images to him"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pK8SfINidxzP",
        "outputId": "3438e95d-4c34-4fb5-e573-5069fd59d4bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "name='cannabis_patches_week8_07_06_2023_3x_regular_IMG_1800' full_name='etaylor/cannabis_patches_week8_07_06_2023_3x_regular_IMG_1800' cloned_from=None description='cannabis patches week=week8_07_06_2023 zoom_type=3x_regular of image=IMG_1800.' category='other' public=False owner=Owner(username='etaylor', created_at='2022-12-28T12:53:18Z', email=None) created_at='2023-12-06T16:55:00.369579Z' enable_ratings=False enable_skip_labeling=True enable_skip_reviewing=False enable_save_button=False enable_label_status_verified=False enable_same_dimensions_track_constraint=False enable_interpolation=True task_type='segmentation-bitmap' label_stats=LabelStats(REVIEWED=None, REVIEWING_IN_PROGRESS=None, LABELED=None, LABELING_IN_PROGRESS=None, REJECTED=None, PRELABELED=None, SKIPPED=None, VERIFIED=None, UNLABELED=None, TOTAL=None) labeling_inactivity_timeout_seconds=None samples_count=0 collaborators_count=None task_attributes=TaskAttributes(format_version='0.1', categories=[TaskAttributeCategory(name='trichome', id=1, color=(65, 117, 5), has_instances=None, attributes=None, dimensions=None), TaskAttributeCategory(name='clear', id=2, color=(155, 155, 155), has_instances=None, attributes=None, dimensions=None), TaskAttributeCategory(name='cloudy', id=3, color=(255, 255, 255), has_instances=None, attributes=None, dimensions=None), TaskAttributeCategory(name='amber', id=4, color=(245, 166, 35), has_instances=None, attributes=None, dimensions=None)], image_attributes=None) labelsets=None role=None readme='' metadata={} noncollaborator_can_label=False noncollaborator_can_review=False insights_urls=None embeddings_enabled=None\n",
            "Uploaded IMG_1800.JPG and added as sample: uuid='8c3b4d3f-9303-4007-8918-b10baa2ae071' name='IMG_1800.JPG' attributes=ImageSampleAttributes(image=URL(url='https://segmentsai-prod.s3.eu-west-2.amazonaws.com/assets/etaylor/19dba74b-416b-493e-a1ea-3a94fc371d58.jpg')) metadata={} created_at='2023-12-06T16:55:01.744268Z' created_by='etaylor' assigned_labeler=None assigned_reviewer=None comments=[] priority=0.0 has_embedding=False label=None issues=None dataset_full_name=None\n",
            "Uploaded IMG_1800_p0.png and added as sample: uuid='db743f30-556b-4e93-ba4e-bc1d4a15d974' name='IMG_1800_p0.png' attributes=ImageSampleAttributes(image=URL(url='https://segmentsai-prod.s3.eu-west-2.amazonaws.com/assets/etaylor/bc621d3f-2c78-4fa1-bd55-5132cbee8d78.png')) metadata={} created_at='2023-12-06T16:55:02.260711Z' created_by='etaylor' assigned_labeler=None assigned_reviewer=None comments=[] priority=0.0 has_embedding=False label=None issues=None dataset_full_name=None\n",
            "Uploaded IMG_1800_p1.png and added as sample: uuid='800645be-bada-49c9-a213-6461e8d788aa' name='IMG_1800_p1.png' attributes=ImageSampleAttributes(image=URL(url='https://segmentsai-prod.s3.eu-west-2.amazonaws.com/assets/etaylor/687fffda-2ff7-4be0-a03b-e267b5618a6c.png')) metadata={} created_at='2023-12-06T16:55:02.727899Z' created_by='etaylor' assigned_labeler=None assigned_reviewer=None comments=[] priority=0.0 has_embedding=False label=None issues=None dataset_full_name=None\n",
            "Uploaded IMG_1800_p2.png and added as sample: uuid='82ae5f59-4a1f-4ace-8a04-3290dd1d8f0b' name='IMG_1800_p2.png' attributes=ImageSampleAttributes(image=URL(url='https://segmentsai-prod.s3.eu-west-2.amazonaws.com/assets/etaylor/3be51557-d3fb-4c34-87e9-1c5a74cf4a66.png')) metadata={} created_at='2023-12-06T16:55:03.190403Z' created_by='etaylor' assigned_labeler=None assigned_reviewer=None comments=[] priority=0.0 has_embedding=False label=None issues=None dataset_full_name=None\n",
            "Uploaded IMG_1800_p3.png and added as sample: uuid='41419426-d277-494e-8048-fea5337d083b' name='IMG_1800_p3.png' attributes=ImageSampleAttributes(image=URL(url='https://segmentsai-prod.s3.eu-west-2.amazonaws.com/assets/etaylor/827efc32-3f1d-42da-9d5b-5a5c5e8dc351.png')) metadata={} created_at='2023-12-06T16:55:03.756228Z' created_by='etaylor' assigned_labeler=None assigned_reviewer=None comments=[] priority=0.0 has_embedding=False label=None issues=None dataset_full_name=None\n",
            "Uploaded IMG_1800_p4.png and added as sample: uuid='334e3fd2-ccb3-403a-9ab3-42ff535f8d86' name='IMG_1800_p4.png' attributes=ImageSampleAttributes(image=URL(url='https://segmentsai-prod.s3.eu-west-2.amazonaws.com/assets/etaylor/6eeba965-bca8-4617-93f3-1e1f5e319bc6.png')) metadata={} created_at='2023-12-06T16:55:04.291711Z' created_by='etaylor' assigned_labeler=None assigned_reviewer=None comments=[] priority=0.0 has_embedding=False label=None issues=None dataset_full_name=None\n",
            "Uploaded IMG_1800_p5.png and added as sample: uuid='9204e6ac-8ddf-4937-b2de-1a7f2fb151a5' name='IMG_1800_p5.png' attributes=ImageSampleAttributes(image=URL(url='https://segmentsai-prod.s3.eu-west-2.amazonaws.com/assets/etaylor/383b04fb-c36a-4757-a76b-7fed39097eba.png')) metadata={} created_at='2023-12-06T16:55:04.819702Z' created_by='etaylor' assigned_labeler=None assigned_reviewer=None comments=[] priority=0.0 has_embedding=False label=None issues=None dataset_full_name=None\n",
            "Uploaded IMG_1800_p6.png and added as sample: uuid='8dc45ad8-206b-4541-b708-f4eda9da54fb' name='IMG_1800_p6.png' attributes=ImageSampleAttributes(image=URL(url='https://segmentsai-prod.s3.eu-west-2.amazonaws.com/assets/etaylor/875d9087-d227-43d1-97f5-de43090c2491.png')) metadata={} created_at='2023-12-06T16:55:05.320907Z' created_by='etaylor' assigned_labeler=None assigned_reviewer=None comments=[] priority=0.0 has_embedding=False label=None issues=None dataset_full_name=None\n",
            "Uploaded IMG_1800_p7.png and added as sample: uuid='36a05175-34ac-4bd3-8209-d33548d8c2cf' name='IMG_1800_p7.png' attributes=ImageSampleAttributes(image=URL(url='https://segmentsai-prod.s3.eu-west-2.amazonaws.com/assets/etaylor/4e8d1ae1-e2a3-46f0-a8cb-5ebb2589bfc4.png')) metadata={} created_at='2023-12-06T16:55:05.759690Z' created_by='etaylor' assigned_labeler=None assigned_reviewer=None comments=[] priority=0.0 has_embedding=False label=None issues=None dataset_full_name=None\n",
            "Uploaded IMG_1800_p8.png and added as sample: uuid='171ff111-f668-4571-923d-330188ec2bb6' name='IMG_1800_p8.png' attributes=ImageSampleAttributes(image=URL(url='https://segmentsai-prod.s3.eu-west-2.amazonaws.com/assets/etaylor/74f180ec-2c3b-4df0-8d73-d7f2427c6195.png')) metadata={} created_at='2023-12-06T16:55:06.419363Z' created_by='etaylor' assigned_labeler=None assigned_reviewer=None comments=[] priority=0.0 has_embedding=False label=None issues=None dataset_full_name=None\n"
          ]
        }
      ],
      "source": [
        "# New dataset to upload variables\n",
        "image_name = \"IMG_1777\"\n",
        "week = 'week8'\n",
        "zoom_type = '3xr'\n",
        "\n",
        "# Create a new test dataset for the specified image, week, and zoom type\n",
        "test_dataset = pipe.create_new_test_dataset(image_name, config.WEEKS_DIR[week], config.ZOOM_TYPES_DIR[zoom_type], single_category=False)\n",
        "# # Get the absolute path to the processed image\n",
        "abs_images_path = f\"{config.get_processed_cannabis_image_path(week, zoom_type)}/{image_name}\"\n",
        "raw_images_path = f\"{config.get_raw_image_path(week, zoom_type)}/{image_name}.JPG\"\n",
        "\n",
        "# Upload the images that are not annotated to the dataset\n",
        "segmentsai_handler.upload_single_image(test_dataset, raw_images_path) # upload the raw image path\n",
        "segmentsai_handler.upload_images(test_dataset, abs_images_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Waiting 5 seconds that the release is created...\n",
            "uuid='2253edeb-97d5-4876-a5f9-813a05464adf' name='v0.1' description='upload predictions to dataset.' release_type='JSON' attributes=URL(url='https://segmentsai-prod.s3.amazonaws.com/releases/2253edeb-97d5-4876-a5f9-813a05464adf.json?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIA5RYRXRX22Y5Q2VMR%2F20231206%2Feu-west-2%2Fs3%2Faws4_request&X-Amz-Date=20231206T165511Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=a63d4583e24491a49ada43f3067193701ca26665073488a69fa1f0bcc1b16ceb') status='SUCCEEDED' created_at='2023-12-06T16:55:06.598537Z' samples_count=10\n"
          ]
        }
      ],
      "source": [
        "release_name = \"v0.1\"\n",
        "description = \"upload predictions to dataset.\"\n",
        "segmentsai_handler.client.add_release(test_dataset, release_name, description)\n",
        "print(\"Waiting 5 seconds that the release is created...\")\n",
        "time.sleep(5)\n",
        "test_release = segmentsai_handler.client.get_release(test_dataset, \"v0.1\")\n",
        "print(test_release)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Optional - Load a model checkpoint without training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "# checkpoint_path = \"checkpoints/detectron2/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x/01-12-2023_20-50-03/model_final.pth\"\n",
        "# model.load_checkpoint(checkpoint_path=checkpoint_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lpX-71UwlW6o"
      },
      "source": [
        "### Upload the Images that are not annotated to the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gozhWa6Ahvxm",
        "outputId": "f73115aa-9519-491c-ac9d-8da8a6b8b70b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initializing dataset...\n",
            "Preloading all samples. This may take a while...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|\u001b[38;2;255;153;0m██████████\u001b[0m| 10/10 [00:01<00:00,  7.02it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initialized dataset with 10 images.\n"
          ]
        }
      ],
      "source": [
        "test_dataset_instance = SegmentsDataset(test_release)\n",
        "\n",
        "for sample in test_dataset_instance:\n",
        "    # Generate label predictions\n",
        "    image = np.array(sample[\"image\"])\n",
        "    segmentation_bitmap, annotations = model.predict_image(image)\n",
        "    segmentsai_handler.upload_annotation_for_sample(sample['uuid'], segmentation_bitmap, annotations)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Delete the dataset - ONLY IF YOU WANT TO DELETE THE DATASET!!!\n",
        "DELETE_DATASET_NAME = \"etaylor/cannabis_patches_week9_15_06_2023_3x_regular_IMG_2155\"\n",
        "segmentsai_handler.client.delete_dataset(DELETE_DATASET_NAME)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
