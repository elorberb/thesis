{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Wnygc-uoVLfx"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/etaylor/.conda/envs/detectron/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "from src.annotation_handling.segmentsai_handler import SegmentsAIHandler\n",
        "from src.pipelines import model_assist_label_pipeline as pipe \n",
        "from src.segmentation.framework_handlers.detectron2_handler import Detectron2Handler\n",
        "import config\n",
        "\n",
        "from segments import SegmentsDataset\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "segmentsai_handler = SegmentsAIHandler()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4bPRHcMrLm7l"
      },
      "source": [
        "#### 1. Upload your images and label a small subset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20NDp5ubdoX5"
      },
      "source": [
        "##### Vizualize dataset images with masks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "FhD9WUM0Vv40",
        "outputId": "d76e231a-e4df-4e0e-b63d-6eed4dfc7f8c"
      },
      "outputs": [],
      "source": [
        "# Visualize the dataset\n",
        "# segmentsai_handler.visualize_dataset(TRAIN_DATASET_NAME)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rotyn89DLm7m"
      },
      "source": [
        "#### 2. Train a segmentation model on the labeled images\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RWWJKe0YfarR",
        "outputId": "0bc3cbea-c69c-4fc0-9c25-b6293ae5f760"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initializing dataset...\n",
            "Preloading all samples. This may take a while...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|\u001b[38;2;255;153;0m██████████\u001b[0m| 40/40 [00:00<00:00, 333.98it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initialized dataset with 40 images.\n",
            "Exporting dataset. This may take a while...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|\u001b[38;2;255;153;0m██████████\u001b[0m| 40/40 [00:01<00:00, 29.68it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exported to checkpoints/detectron2/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x/01-12-2023_21-07-24/export_coco-instance_etaylor_all_cannabis_patches_multi_class_v0.1.json. Images in segments/etaylor_all_cannabis_patches_multi_class/v0.1\n",
            "Dataset registration failed: Dataset 'etaylor/all_cannabis_patches_multi_class' is already registered!\n",
            "Metadata(name='etaylor/all_cannabis_patches_multi_class', json_file='checkpoints/detectron2/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x/01-12-2023_21-04-55/export_coco-instance_etaylor_all_cannabis_patches_multi_class_v0.1.json', image_root='segments/etaylor_all_cannabis_patches_multi_class/v0.1', evaluator_type='coco', thing_classes=['trichome', 'clear', 'cloudy', 'amber'])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "TRAIN_DATASET_NAME = 'etaylor/all_cannabis_patches_multi_class'\n",
        "\n",
        "# Setup config for detectron2 model\n",
        "model_config = {\n",
        "'task_type': 'COCO-InstanceSegmentation',\n",
        "'model_type': 'mask_rcnn_R_50_FPN_3x',\n",
        "'dataset_name': TRAIN_DATASET_NAME,\n",
        "'release_version': \"v0.1\",\n",
        "'export_format': \"coco-instance\",\n",
        "'model_device': \"cuda\",\n",
        "}\n",
        "\n",
        "model = Detectron2Handler(**model_config)\n",
        "\n",
        "model.setup_training(\n",
        "    score_thresh_test=0.7,\n",
        "    num_workers=2,\n",
        "    ims_per_batch=4,\n",
        "    base_lr=0.00025,\n",
        "    max_iter=500,\n",
        "    batch_size_per_image=128,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32m[12/01 20:50:59 d2.engine.defaults]: \u001b[0mModel:\n",
            "GeneralizedRCNN(\n",
            "  (backbone): FPN(\n",
            "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (top_block): LastLevelMaxPool()\n",
            "    (bottom_up): ResNet(\n",
            "      (stem): BasicStem(\n",
            "        (conv1): Conv2d(\n",
            "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (res2): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res3): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res4): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (4): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (5): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res5): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (proposal_generator): RPN(\n",
            "    (rpn_head): StandardRPNHead(\n",
            "      (conv): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "    (anchor_generator): DefaultAnchorGenerator(\n",
            "      (cell_anchors): BufferList()\n",
            "    )\n",
            "  )\n",
            "  (roi_heads): StandardROIHeads(\n",
            "    (box_pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
            "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
            "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (box_head): FastRCNNConvFCHead(\n",
            "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
            "      (fc_relu1): ReLU()\n",
            "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "      (fc_relu2): ReLU()\n",
            "    )\n",
            "    (box_predictor): FastRCNNOutputLayers(\n",
            "      (cls_score): Linear(in_features=1024, out_features=5, bias=True)\n",
            "      (bbox_pred): Linear(in_features=1024, out_features=16, bias=True)\n",
            "    )\n",
            "    (mask_pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
            "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
            "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (mask_head): MaskRCNNConvUpsampleHead(\n",
            "      (mask_fcn1): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (mask_fcn2): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (mask_fcn3): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (mask_fcn4): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
            "      (deconv_relu): ReLU()\n",
            "      (predictor): Conv2d(256, 4, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "  )\n",
            ")\n",
            "\u001b[32m[12/01 20:50:59 d2.data.datasets.coco]: \u001b[0mLoaded 40 images in COCO format from checkpoints/detectron2/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x/01-12-2023_18-08-13/export_coco-instance_etaylor_all_cannabis_patches_multi_class_v0.1.json\n",
            "\u001b[32m[12/01 20:50:59 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 40 images left.\n",
            "\u001b[32m[12/01 20:50:59 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
            "\u001b[32m[12/01 20:50:59 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
            "\u001b[32m[12/01 20:50:59 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
            "\u001b[32m[12/01 20:50:59 d2.data.common]: \u001b[0mSerializing 40 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[12/01 20:50:59 d2.data.common]: \u001b[0mSerialized dataset takes 0.11 MiB\n",
            "\u001b[32m[12/01 20:50:59 d2.data.build]: \u001b[0mMaking batched data loader with batch_size=4\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/01 20:50:59 d2.solver.build]: \u001b[0mSOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n",
            "\u001b[32m[12/01 20:50:59 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from https://dl.fbaipublicfiles.com/detectron2/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x/137849600/model_final_f10217.pkl ...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (5, 1024) in the model! You might want to double check if this is expected.\n",
            "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (5,) in the model! You might want to double check if this is expected.\n",
            "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (16, 1024) in the model! You might want to double check if this is expected.\n",
            "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (16,) in the model! You might want to double check if this is expected.\n",
            "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (4, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
            "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (4,) in the model! You might want to double check if this is expected.\n",
            "Some model parameters or buffers are not found in the checkpoint:\n",
            "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
            "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n",
            "\u001b[34mroi_heads.mask_head.predictor.{bias, weight}\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32m[12/01 20:51:00 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/etaylor/.conda/envs/detectron/lib/python3.9/site-packages/detectron2/data/detection_utils.py:446: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:180.)\n",
            "  torch.stack([torch.from_numpy(np.ascontiguousarray(x)) for x in masks])\n",
            "/home/etaylor/.conda/envs/detectron/lib/python3.9/site-packages/detectron2/data/detection_utils.py:446: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:180.)\n",
            "  torch.stack([torch.from_numpy(np.ascontiguousarray(x)) for x in masks])\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32m[12/01 20:51:13 d2.utils.events]: \u001b[0m eta: 0:05:19  iter: 19  total_loss: 4.187  loss_cls: 1.465  loss_box_reg: 0.6303  loss_mask: 0.6926  loss_rpn_cls: 1.316  loss_rpn_loc: 0.1265    time: 0.6727  last_time: 0.7174  data_time: 0.0247  last_data_time: 0.0104   lr: 9.7405e-06  max_mem: 3369M\n",
            "\u001b[32m[12/01 20:51:27 d2.utils.events]: \u001b[0m eta: 0:05:06  iter: 39  total_loss: 3.234  loss_cls: 1.296  loss_box_reg: 0.6888  loss_mask: 0.6843  loss_rpn_cls: 0.4488  loss_rpn_loc: 0.09995    time: 0.6755  last_time: 0.6324  data_time: 0.0129  last_data_time: 0.0144   lr: 1.9731e-05  max_mem: 3369M\n",
            "\u001b[32m[12/01 20:51:41 d2.utils.events]: \u001b[0m eta: 0:04:56  iter: 59  total_loss: 2.697  loss_cls: 1.078  loss_box_reg: 0.7498  loss_mask: 0.6557  loss_rpn_cls: 0.1308  loss_rpn_loc: 0.08147    time: 0.6811  last_time: 0.6713  data_time: 0.0126  last_data_time: 0.0161   lr: 2.972e-05  max_mem: 3378M\n",
            "\u001b[32m[12/01 20:51:55 d2.utils.events]: \u001b[0m eta: 0:04:53  iter: 79  total_loss: 2.373  loss_cls: 0.8749  loss_box_reg: 0.7429  loss_mask: 0.6114  loss_rpn_cls: 0.08299  loss_rpn_loc: 0.07793    time: 0.6897  last_time: 0.7776  data_time: 0.0116  last_data_time: 0.0115   lr: 3.9711e-05  max_mem: 3399M\n",
            "\u001b[32m[12/01 20:52:10 d2.utils.events]: \u001b[0m eta: 0:04:44  iter: 99  total_loss: 2.221  loss_cls: 0.7587  loss_box_reg: 0.7551  loss_mask: 0.559  loss_rpn_cls: 0.06569  loss_rpn_loc: 0.07184    time: 0.7004  last_time: 0.7807  data_time: 0.0124  last_data_time: 0.0091   lr: 4.9701e-05  max_mem: 3399M\n",
            "\u001b[32m[12/01 20:52:25 d2.utils.events]: \u001b[0m eta: 0:04:32  iter: 119  total_loss: 2.084  loss_cls: 0.6897  loss_box_reg: 0.7739  loss_mask: 0.5005  loss_rpn_cls: 0.06486  loss_rpn_loc: 0.07051    time: 0.7085  last_time: 0.7675  data_time: 0.0127  last_data_time: 0.0099   lr: 5.9691e-05  max_mem: 3399M\n",
            "\u001b[32m[12/01 20:52:40 d2.utils.events]: \u001b[0m eta: 0:04:18  iter: 139  total_loss: 1.97  loss_cls: 0.6395  loss_box_reg: 0.7503  loss_mask: 0.4379  loss_rpn_cls: 0.05957  loss_rpn_loc: 0.06764    time: 0.7128  last_time: 0.7327  data_time: 0.0126  last_data_time: 0.0102   lr: 6.9681e-05  max_mem: 3399M\n",
            "\u001b[32m[12/01 20:52:55 d2.utils.events]: \u001b[0m eta: 0:04:05  iter: 159  total_loss: 1.899  loss_cls: 0.6115  loss_box_reg: 0.7364  loss_mask: 0.4054  loss_rpn_cls: 0.05295  loss_rpn_loc: 0.07079    time: 0.7201  last_time: 0.6429  data_time: 0.0126  last_data_time: 0.0142   lr: 7.9671e-05  max_mem: 3399M\n",
            "\u001b[32m[12/01 20:53:10 d2.utils.events]: \u001b[0m eta: 0:03:51  iter: 179  total_loss: 1.829  loss_cls: 0.5782  loss_box_reg: 0.7362  loss_mask: 0.3771  loss_rpn_cls: 0.04959  loss_rpn_loc: 0.06718    time: 0.7264  last_time: 0.7958  data_time: 0.0119  last_data_time: 0.0113   lr: 8.966e-05  max_mem: 3399M\n",
            "\u001b[32m[12/01 20:53:26 d2.utils.events]: \u001b[0m eta: 0:03:38  iter: 199  total_loss: 1.716  loss_cls: 0.5555  loss_box_reg: 0.6862  loss_mask: 0.3544  loss_rpn_cls: 0.05119  loss_rpn_loc: 0.06635    time: 0.7291  last_time: 0.7883  data_time: 0.0123  last_data_time: 0.0104   lr: 9.9651e-05  max_mem: 3399M\n",
            "\u001b[32m[12/01 20:53:41 d2.utils.events]: \u001b[0m eta: 0:03:24  iter: 219  total_loss: 1.609  loss_cls: 0.5271  loss_box_reg: 0.6638  loss_mask: 0.33  loss_rpn_cls: 0.04729  loss_rpn_loc: 0.07005    time: 0.7333  last_time: 0.7084  data_time: 0.0149  last_data_time: 0.0118   lr: 0.00010964  max_mem: 3399M\n",
            "\u001b[32m[12/01 20:53:57 d2.utils.events]: \u001b[0m eta: 0:03:10  iter: 239  total_loss: 1.5  loss_cls: 0.4866  loss_box_reg: 0.6115  loss_mask: 0.3119  loss_rpn_cls: 0.03668  loss_rpn_loc: 0.05937    time: 0.7370  last_time: 0.8167  data_time: 0.0143  last_data_time: 0.0166   lr: 0.00011963  max_mem: 3399M\n",
            "\u001b[32m[12/01 20:54:12 d2.utils.events]: \u001b[0m eta: 0:02:56  iter: 259  total_loss: 1.454  loss_cls: 0.4927  loss_box_reg: 0.5692  loss_mask: 0.2937  loss_rpn_cls: 0.04118  loss_rpn_loc: 0.0679    time: 0.7381  last_time: 0.8263  data_time: 0.0119  last_data_time: 0.0122   lr: 0.00012962  max_mem: 3399M\n",
            "\u001b[32m[12/01 20:54:27 d2.utils.events]: \u001b[0m eta: 0:02:42  iter: 279  total_loss: 1.359  loss_cls: 0.4758  loss_box_reg: 0.5325  loss_mask: 0.262  loss_rpn_cls: 0.03855  loss_rpn_loc: 0.06246    time: 0.7401  last_time: 0.7302  data_time: 0.0142  last_data_time: 0.0125   lr: 0.00013961  max_mem: 3399M\n",
            "\u001b[32m[12/01 20:54:42 d2.utils.events]: \u001b[0m eta: 0:02:27  iter: 299  total_loss: 1.208  loss_cls: 0.4317  loss_box_reg: 0.4616  loss_mask: 0.2343  loss_rpn_cls: 0.0319  loss_rpn_loc: 0.0586    time: 0.7404  last_time: 0.7484  data_time: 0.0121  last_data_time: 0.0119   lr: 0.0001496  max_mem: 3399M\n",
            "\u001b[32m[12/01 20:54:57 d2.utils.events]: \u001b[0m eta: 0:02:13  iter: 319  total_loss: 1.222  loss_cls: 0.452  loss_box_reg: 0.4411  loss_mask: 0.2316  loss_rpn_cls: 0.03806  loss_rpn_loc: 0.06301    time: 0.7419  last_time: 0.7331  data_time: 0.0122  last_data_time: 0.0109   lr: 0.00015959  max_mem: 3399M\n",
            "\u001b[32m[12/01 20:55:13 d2.utils.events]: \u001b[0m eta: 0:01:58  iter: 339  total_loss: 1.162  loss_cls: 0.4317  loss_box_reg: 0.4181  loss_mask: 0.2115  loss_rpn_cls: 0.03176  loss_rpn_loc: 0.06059    time: 0.7435  last_time: 0.6883  data_time: 0.0113  last_data_time: 0.0090   lr: 0.00016958  max_mem: 3399M\n",
            "\u001b[32m[12/01 20:55:28 d2.utils.events]: \u001b[0m eta: 0:01:44  iter: 359  total_loss: 1.133  loss_cls: 0.4278  loss_box_reg: 0.3864  loss_mask: 0.1994  loss_rpn_cls: 0.02954  loss_rpn_loc: 0.06001    time: 0.7443  last_time: 0.7035  data_time: 0.0125  last_data_time: 0.0137   lr: 0.00017957  max_mem: 3399M\n",
            "\u001b[32m[12/01 20:55:43 d2.utils.events]: \u001b[0m eta: 0:01:29  iter: 379  total_loss: 1.104  loss_cls: 0.4403  loss_box_reg: 0.371  loss_mask: 0.2009  loss_rpn_cls: 0.02264  loss_rpn_loc: 0.0554    time: 0.7451  last_time: 0.7891  data_time: 0.0119  last_data_time: 0.0134   lr: 0.00018956  max_mem: 3399M\n",
            "\u001b[32m[12/01 20:55:58 d2.utils.events]: \u001b[0m eta: 0:01:14  iter: 399  total_loss: 1.046  loss_cls: 0.4109  loss_box_reg: 0.349  loss_mask: 0.1971  loss_rpn_cls: 0.02086  loss_rpn_loc: 0.0516    time: 0.7449  last_time: 0.7368  data_time: 0.0118  last_data_time: 0.0158   lr: 0.00019955  max_mem: 3399M\n",
            "\u001b[32m[12/01 20:56:13 d2.utils.events]: \u001b[0m eta: 0:00:59  iter: 419  total_loss: 1.014  loss_cls: 0.4248  loss_box_reg: 0.3471  loss_mask: 0.1811  loss_rpn_cls: 0.02473  loss_rpn_loc: 0.05646    time: 0.7453  last_time: 0.6443  data_time: 0.0126  last_data_time: 0.0105   lr: 0.00020954  max_mem: 3399M\n",
            "\u001b[32m[12/01 20:56:28 d2.utils.events]: \u001b[0m eta: 0:00:44  iter: 439  total_loss: 1.009  loss_cls: 0.4138  loss_box_reg: 0.3238  loss_mask: 0.1841  loss_rpn_cls: 0.02105  loss_rpn_loc: 0.05398    time: 0.7454  last_time: 0.7249  data_time: 0.0121  last_data_time: 0.0098   lr: 0.00021953  max_mem: 3399M\n",
            "\u001b[32m[12/01 20:56:43 d2.utils.events]: \u001b[0m eta: 0:00:29  iter: 459  total_loss: 0.9677  loss_cls: 0.3865  loss_box_reg: 0.3288  loss_mask: 0.1905  loss_rpn_cls: 0.02371  loss_rpn_loc: 0.05389    time: 0.7457  last_time: 0.7940  data_time: 0.0128  last_data_time: 0.0109   lr: 0.00022952  max_mem: 3399M\n",
            "\u001b[32m[12/01 20:56:58 d2.utils.events]: \u001b[0m eta: 0:00:14  iter: 479  total_loss: 0.9323  loss_cls: 0.3726  loss_box_reg: 0.3038  loss_mask: 0.1811  loss_rpn_cls: 0.0197  loss_rpn_loc: 0.05571    time: 0.7460  last_time: 0.6430  data_time: 0.0120  last_data_time: 0.0114   lr: 0.00023951  max_mem: 3399M\n",
            "\u001b[32m[12/01 20:57:16 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 499  total_loss: 0.949  loss_cls: 0.3764  loss_box_reg: 0.3067  loss_mask: 0.1767  loss_rpn_cls: 0.01782  loss_rpn_loc: 0.05282    time: 0.7460  last_time: 0.6922  data_time: 0.0108  last_data_time: 0.0105   lr: 0.0002495  max_mem: 3412M\n",
            "\u001b[32m[12/01 20:57:16 d2.engine.hooks]: \u001b[0mOverall training speed: 498 iterations in 0:06:11 (0.7461 s / it)\n",
            "\u001b[32m[12/01 20:57:16 d2.engine.hooks]: \u001b[0mTotal training time: 0:06:15 (0:00:03 on hooks)\n",
            "\u001b[32m[12/01 20:57:17 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from checkpoints/detectron2/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x/01-12-2023_20-50-03/model_final.pth ...\n"
          ]
        }
      ],
      "source": [
        "# Train the model\n",
        "model.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8MsoYDLduR8"
      },
      "source": [
        "#### Create a new dataset and upload images to him"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pK8SfINidxzP",
        "outputId": "3438e95d-4c34-4fb5-e573-5069fd59d4bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "name='cannabis_patches_week8_07_06_2023_3x_regular_IMG_1875' full_name='etaylor/cannabis_patches_week8_07_06_2023_3x_regular_IMG_1875' cloned_from=None description='cannabis patches week=week8_07_06_2023 zoom_type=3x_regular of image=IMG_1875.' category='other' public=False owner=Owner(username='etaylor', created_at='2022-12-28T12:53:18Z', email=None) created_at='2023-12-01T19:14:16.920669Z' enable_ratings=False enable_skip_labeling=True enable_skip_reviewing=False enable_save_button=False enable_label_status_verified=False enable_same_dimensions_track_constraint=False enable_interpolation=True task_type='segmentation-bitmap' label_stats=LabelStats(REVIEWED=None, REVIEWING_IN_PROGRESS=None, LABELED=None, LABELING_IN_PROGRESS=None, REJECTED=None, PRELABELED=None, SKIPPED=None, VERIFIED=None, UNLABELED=None, TOTAL=None) labeling_inactivity_timeout_seconds=None samples_count=0 collaborators_count=None task_attributes=TaskAttributes(format_version='0.1', categories=[TaskAttributeCategory(name='trichome', id=1, color=(65, 117, 5), has_instances=None, attributes=None, dimensions=None), TaskAttributeCategory(name='clear', id=2, color=(155, 155, 155), has_instances=None, attributes=None, dimensions=None), TaskAttributeCategory(name='cloudy', id=3, color=(255, 255, 255), has_instances=None, attributes=None, dimensions=None), TaskAttributeCategory(name='amber', id=4, color=(245, 166, 35), has_instances=None, attributes=None, dimensions=None)], image_attributes=None) labelsets=None role=None readme='' metadata={} noncollaborator_can_label=False noncollaborator_can_review=False insights_urls=None embeddings_enabled=None\n",
            "Uploaded IMG_1875.JPG and added as sample: uuid='609118d9-c5a1-4757-ac46-0e27fcfacbd0' name='IMG_1875.JPG' attributes=ImageSampleAttributes(image=URL(url='https://segmentsai-prod.s3.eu-west-2.amazonaws.com/assets/etaylor/6859040f-3941-40a9-a11a-0201f53828f1.jpg')) metadata={} created_at='2023-12-01T19:14:18.534454Z' created_by='etaylor' assigned_labeler=None assigned_reviewer=None comments=[] priority=0.0 has_embedding=False label=None issues=None dataset_full_name=None\n",
            "Uploaded IMG_1875_p0.png and added as sample: uuid='1e187943-ea49-4479-a7e8-72e22b16c850' name='IMG_1875_p0.png' attributes=ImageSampleAttributes(image=URL(url='https://segmentsai-prod.s3.eu-west-2.amazonaws.com/assets/etaylor/05df7b0f-579c-408c-a3f1-4deab1228264.png')) metadata={} created_at='2023-12-01T19:14:19.024170Z' created_by='etaylor' assigned_labeler=None assigned_reviewer=None comments=[] priority=0.0 has_embedding=False label=None issues=None dataset_full_name=None\n",
            "Uploaded IMG_1875_p1.png and added as sample: uuid='619ee66b-bf29-4dd6-a350-f5a447e29a54' name='IMG_1875_p1.png' attributes=ImageSampleAttributes(image=URL(url='https://segmentsai-prod.s3.eu-west-2.amazonaws.com/assets/etaylor/6a6a5709-d57a-4574-98b8-487e7553aa49.png')) metadata={} created_at='2023-12-01T19:14:19.555976Z' created_by='etaylor' assigned_labeler=None assigned_reviewer=None comments=[] priority=0.0 has_embedding=False label=None issues=None dataset_full_name=None\n",
            "Uploaded IMG_1875_p2.png and added as sample: uuid='7cecd030-cf0e-442b-8b27-c864b9cdcc6a' name='IMG_1875_p2.png' attributes=ImageSampleAttributes(image=URL(url='https://segmentsai-prod.s3.eu-west-2.amazonaws.com/assets/etaylor/5f3ee946-5a62-4e01-824a-e6247d25b3b9.png')) metadata={} created_at='2023-12-01T19:14:20.074126Z' created_by='etaylor' assigned_labeler=None assigned_reviewer=None comments=[] priority=0.0 has_embedding=False label=None issues=None dataset_full_name=None\n",
            "Uploaded IMG_1875_p3.png and added as sample: uuid='503765f4-6973-4217-a36c-ee0f2079c76b' name='IMG_1875_p3.png' attributes=ImageSampleAttributes(image=URL(url='https://segmentsai-prod.s3.eu-west-2.amazonaws.com/assets/etaylor/e531139a-aeb2-49e2-9f7b-a4d3525bd75f.png')) metadata={} created_at='2023-12-01T19:14:20.747525Z' created_by='etaylor' assigned_labeler=None assigned_reviewer=None comments=[] priority=0.0 has_embedding=False label=None issues=None dataset_full_name=None\n",
            "Uploaded IMG_1875_p4.png and added as sample: uuid='93cdf387-eab9-4e2b-b81d-41d19c498092' name='IMG_1875_p4.png' attributes=ImageSampleAttributes(image=URL(url='https://segmentsai-prod.s3.eu-west-2.amazonaws.com/assets/etaylor/baa36a4a-97c4-4f3d-abd1-50e771be2169.png')) metadata={} created_at='2023-12-01T19:14:21.421635Z' created_by='etaylor' assigned_labeler=None assigned_reviewer=None comments=[] priority=0.0 has_embedding=False label=None issues=None dataset_full_name=None\n",
            "Uploaded IMG_1875_p5.png and added as sample: uuid='28e18194-6bb1-4c54-ada1-ff5c35d9ca5d' name='IMG_1875_p5.png' attributes=ImageSampleAttributes(image=URL(url='https://segmentsai-prod.s3.eu-west-2.amazonaws.com/assets/etaylor/23d8a7ef-7c0e-4a8f-afb5-e65a49c5fad7.png')) metadata={} created_at='2023-12-01T19:14:21.996058Z' created_by='etaylor' assigned_labeler=None assigned_reviewer=None comments=[] priority=0.0 has_embedding=False label=None issues=None dataset_full_name=None\n",
            "Uploaded IMG_1875_p6.png and added as sample: uuid='5012754e-948b-4c5b-89a2-f7ee18575cf6' name='IMG_1875_p6.png' attributes=ImageSampleAttributes(image=URL(url='https://segmentsai-prod.s3.eu-west-2.amazonaws.com/assets/etaylor/a415d9a1-5fec-456a-9ab3-b82df4bff41f.png')) metadata={} created_at='2023-12-01T19:14:22.718110Z' created_by='etaylor' assigned_labeler=None assigned_reviewer=None comments=[] priority=0.0 has_embedding=False label=None issues=None dataset_full_name=None\n",
            "Uploaded IMG_1875_p7.png and added as sample: uuid='ca38ab30-cead-460f-8520-d9acfef9884d' name='IMG_1875_p7.png' attributes=ImageSampleAttributes(image=URL(url='https://segmentsai-prod.s3.eu-west-2.amazonaws.com/assets/etaylor/ddc0d337-0e92-4d96-815a-1cd771559df4.png')) metadata={} created_at='2023-12-01T19:14:23.347713Z' created_by='etaylor' assigned_labeler=None assigned_reviewer=None comments=[] priority=0.0 has_embedding=False label=None issues=None dataset_full_name=None\n",
            "Uploaded IMG_1875_p8.png and added as sample: uuid='99640182-7f24-4a58-b8d1-6375683f9322' name='IMG_1875_p8.png' attributes=ImageSampleAttributes(image=URL(url='https://segmentsai-prod.s3.eu-west-2.amazonaws.com/assets/etaylor/6e6ac2e6-042c-439f-bd8f-ffe05c5538e3.png')) metadata={} created_at='2023-12-01T19:14:23.895929Z' created_by='etaylor' assigned_labeler=None assigned_reviewer=None comments=[] priority=0.0 has_embedding=False label=None issues=None dataset_full_name=None\n",
            "Uploaded IMG_1875_p9.png and added as sample: uuid='02e693a2-64d0-4c48-8e43-8b53143a7423' name='IMG_1875_p9.png' attributes=ImageSampleAttributes(image=URL(url='https://segmentsai-prod.s3.eu-west-2.amazonaws.com/assets/etaylor/4d69dac2-f90a-457f-a263-8b5f9daad7ae.png')) metadata={} created_at='2023-12-01T19:14:24.519990Z' created_by='etaylor' assigned_labeler=None assigned_reviewer=None comments=[] priority=0.0 has_embedding=False label=None issues=None dataset_full_name=None\n",
            "Uploaded IMG_1875_p10.png and added as sample: uuid='cdda00b9-4083-4311-8e1d-028735b466d5' name='IMG_1875_p10.png' attributes=ImageSampleAttributes(image=URL(url='https://segmentsai-prod.s3.eu-west-2.amazonaws.com/assets/etaylor/7aa8e3df-efda-4b96-808b-48409cb6c67e.png')) metadata={} created_at='2023-12-01T19:14:25.116314Z' created_by='etaylor' assigned_labeler=None assigned_reviewer=None comments=[] priority=0.0 has_embedding=False label=None issues=None dataset_full_name=None\n",
            "Uploaded IMG_1875_p11.png and added as sample: uuid='58646b76-a4d0-4bde-8127-adfd6ff1fd8d' name='IMG_1875_p11.png' attributes=ImageSampleAttributes(image=URL(url='https://segmentsai-prod.s3.eu-west-2.amazonaws.com/assets/etaylor/3830c213-2a7b-4c54-8887-dbad63c8bd59.png')) metadata={} created_at='2023-12-01T19:14:25.702256Z' created_by='etaylor' assigned_labeler=None assigned_reviewer=None comments=[] priority=0.0 has_embedding=False label=None issues=None dataset_full_name=None\n"
          ]
        }
      ],
      "source": [
        "# New dataset to upload variables\n",
        "image_name = \"IMG_1875\"\n",
        "week = 'week8'\n",
        "zoom_type = '3xr'\n",
        "\n",
        "# Create a new test dataset for the specified image, week, and zoom type\n",
        "test_dataset = pipe.create_new_test_dataset(image_name, config.WEEKS_DIR[week], config.ZOOM_TYPES_DIR[zoom_type], single_category=False)\n",
        "# # Get the absolute path to the processed image\n",
        "abs_images_path = f\"{config.get_processed_cannabis_image_path(week, zoom_type)}/{image_name}\"\n",
        "raw_images_path = f\"{config.get_raw_image_path(week, zoom_type)}/{image_name}.JPG\"\n",
        "\n",
        "# Upload the images that are not annotated to the dataset\n",
        "segmentsai_handler.upload_single_image(test_dataset, raw_images_path) # upload the raw image path\n",
        "segmentsai_handler.upload_images(test_dataset, abs_images_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Waiting 5 seconds that the release is created...\n",
            "uuid='b360eea5-ad87-43ca-8117-dad19297b105' name='v0.1' description='upload predictions to dataset.' release_type='JSON' attributes=URL(url='https://segmentsai-prod.s3.amazonaws.com/releases/b360eea5-ad87-43ca-8117-dad19297b105.json?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIA5RYRXRX22Y5Q2VMR%2F20231201%2Feu-west-2%2Fs3%2Faws4_request&X-Amz-Date=20231201T191434Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=17f8c21f2177b27c5bcaba2d9af4d1b99a04439da17140f9def7a506014cedf4') status='SUCCEEDED' created_at='2023-12-01T19:14:29.181235Z' samples_count=13\n"
          ]
        }
      ],
      "source": [
        "release_name = \"v0.1\"\n",
        "description = \"upload predictions to dataset.\"\n",
        "segmentsai_handler.client.add_release(test_dataset, release_name, description)\n",
        "print(\"Waiting 5 seconds that the release is created...\")\n",
        "time.sleep(5)\n",
        "test_release = segmentsai_handler.client.get_release(test_dataset, \"v0.1\")\n",
        "print(test_release)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Optional - Load a model checkpoint without training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "checkpoint_path = \"checkpoints/detectron2/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x/01-12-2023_20-50-03/model_final.pth\"\n",
        "model.load_checkpoint(checkpoint_path=checkpoint_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lpX-71UwlW6o"
      },
      "source": [
        "### Upload the Images that are not annotated to the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gozhWa6Ahvxm",
        "outputId": "f73115aa-9519-491c-ac9d-8da8a6b8b70b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initializing dataset...\n",
            "Preloading all samples. This may take a while...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|\u001b[38;2;255;153;0m██████████\u001b[0m| 13/13 [00:00<00:00, 259.36it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initialized dataset with 13 images.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "test_dataset_instance = SegmentsDataset(test_release)\n",
        "\n",
        "for sample in test_dataset_instance:\n",
        "    # Generate label predictions\n",
        "    image = np.array(sample[\"image\"])\n",
        "    segmentation_bitmap, annotations = model.predict_image(image)\n",
        "    segmentsai_handler.upload_annotation_for_sample(sample['uuid'], segmentation_bitmap, annotations)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Delete the dataset - ONLY IF YOU WANT TO DELETE THE DATASET!!!\n",
        "DELETE_DATASET_NAME = \"\"\n",
        "segmentsai_handler.client.delete_dataset(DELETE_DATASET_NAME)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
